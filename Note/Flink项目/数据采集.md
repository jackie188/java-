
<!-- TOC -->

- [实时数仓分层介绍](#实时数仓分层介绍)
  - [普通实时计算与实时数仓比较](#普通实时计算与实时数仓比较)
  - [实时数仓分层介绍](#实时数仓分层介绍-1)
  - [离线计算与实时计算的比较](#离线计算与实时计算的比较)
  - [架构分析](#架构分析)

<!-- /TOC -->


## 实时数仓分层介绍

### 普通实时计算与实时数仓比较

**普通数仓**

普通的实时计算优先考虑**时效性**，所以从数据源采集经过实时计算直接得到结果。如此做时效性更好，但是弊端是由于计算过程中的中间结果没有沉淀下来，所以当面对大量实时需求的时候，计算的**复用性较差**，开发成本随着需求增加直线上升。

![20211127170548](https://vscodepic.oss-cn-beijing.aliyuncs.com/pic/20211127170548.png)

> 什么意思呢：就是从数据源获取的数据，如果有几条计算流程，那么就分几次计算，但是有个问题，这几条计算流程中，可能存在很多的重复计算，这也是传统的计算存在的缺点，因为考虑了实时性，必然需要牺牲复用性。

**实时数仓**

实时数仓基于一定的数据仓库理念，对数据处理流程进行规划、分层，目的是提高数据的**复用性**。

下面这张图是实时数仓，最重要的一个概念是分层，不仅是数据的分层，那么在计算层面，也进行分层操作，提取出共有的计算操作，然后独立出不同的计算部分，这样可以减少很多的重复计算量。最大的好处是**提高复用性**。但是随之带来的缺点是影响时效性。

为什么会影响时效性，因为在a计算完成后，需要把结果进行保存，然后供计算流程b和c共同使用，之所以需要缓存数据，所以时效性不好。

![20211127170815](https://vscodepic.oss-cn-beijing.aliyuncs.com/pic/20211127170815.png)

### 实时数仓分层介绍

**ODS：**

原始数据，日志和业务数据，这些数据是存放在kafka中，因为实时数据需要低延迟，应对实时的业务，在离线数仓中，我们存在hive中。

我们一般将**日志数据和业务数据的实时表**存放在DWD层，这个数据我们是存放在kafka中。

> dwd和dim是同一层，只不过存储的位置不一样

**DWD**：

根据数据对象为单位进行分流，比如订单、页面访问等等，在Flink中，我们是根据测输出流进行分流处理。我们把事实表存放在DWD层。

我们为什么没有把维度数据存放在kafka中，有两个原因：

1. 因为当一条数据来了之后，我们需要使用实时表中的数据去关联维度表，然后在补充实时表，但是kafka中的数据存放时间有时限，是7天，会定期进行删除，但是我们的维度表数据不能进行删除，所以我们选择将维度表数据存放在Hbase中。

2. 第二个原因是根据ID去kafka中查找数据，很困难，所以并不能将数据存放在kafka中。

**DIM：**

维度数据

>dwd和dim是属于同一层的，只是存储的位置和内容不一样，dwd层存储的是事实表，存储在kafka，dim层存储维度表数据，存储在Hbase。

**DWM：**

对于部分数据对象进行进一步加工，比如独立访问、跳出行为，也可以和维度进行关联，形成宽表，依旧是明细数据。

对dwd和DIM过程中形成的通用的数据抽取出来，形成DWM层。存储在KAFKA中。因为其还要进行加工形成dws层，有些dwd,dim数据也可以直接形成dws层数据。

**DWS：**

根据某个主题将多个事实数据轻度聚合，形成主题宽表。这部分数据是需要最终的查询，所以放在cH数据库中。

**ADS：**

把ClickHouse中的数据根据可视化需进行筛选聚合，这一部分是实时数据，不进行落盘，主要是对数据进行聚合操作。

### 离线计算与实时计算的比较

**离线计算：**

就是在计算开始前已知所有输入数据，输入数据不会产生变化，一般计算量级较大，计算时间也较长。例如今天早上一点，把昨天累积的日志，计算出所需结果。最经典的就是 Hadoop 的 MapReduce 方式；

一般是根据前一日的数据生成报表，虽然统计指标、报表繁多，但是对时效性不敏感。

从技术操作的角度，这部分属于批处理的操作。即根据确定范围的数据一次性计算。

**实时计算：**

输入数据是可以以序列化的方式一个个输入并进行处理的，也就是说在开始的时候并不需要知道所有的输入数据。与离线计算相比，运行时间短，计算量级相对较小。

强调计算过程的时间要短，即所查当下给出结果。

主要侧重于对当日数据的实时监控，通常业务逻辑相对离线需求简单一下，统计指标也少一些，但是更注重数据的时效性，以及用户的交互性。从技术操作的角度，这部分属于流处理的操作。根据数据源源不断地到达进行实时的运算。

**即席查询**

强调查询的临时性，需求的临时性。

presto:当场计算，基于内存速度快。

kylin:预计算，提前计算好。做多维度分析(hive with cube),数据有多种维度，那么kylin会把所有的维度组合全部计算好。需要的时候直接拿去即可。


### 架构分析

**离线架构**

![20211127180021](https://vscodepic.oss-cn-beijing.aliyuncs.com/pic/20211127180021.png)

Niginx可以将我们的web页面产生的数据进行负载均衡，如果是日志数据，那么就传输到日志服务器，如果是埋点数据，那么就存储到业务服务器。

对于日志数据，日志服务器会进行落盘处理，，那么对于业务数据，我们一般会写在mysql数据库中。

mysql数据借助sqoop导入到HDFS上面，一般有**增量，全量，新增及变化和特殊**等同步方式。我们一般是通过where条件后面添加日期来判断数据的类型，然后进行数据的导入。
- 增量，创建时间==今天时间
- 全量数据：where 1==1
- 新增以及变化：data==今天 or 修改时间 == 今天
- 对于特殊数据，一般导入一次即可，后续不需要导入。

使用flume在导入数据的时候，有source、channel，没有使用sink,因为我们直接将数据传输到kafka中

**flume:**

- TailDirSource:
  - 优点：断点续传，监控多目录，多文件，实时监控
  - 缺点：当文件更换名字之后，可能会重新读取文件，所以会造成数据的重复，是整个数据文件的重复。因为是按照inode+文件全路径名判断是否是新的文件，所以文件名变化，会认为是一个新的文件。
  - **解决方法：**
    - 所以在使用的时候，需要使用不更名的打印日志框架（logback)
    - 修改源码：让TailDirSource判断文件的时候，只看inode值。
- kafkachannel:将数据直接传入kafka，省了一层sink。
- 在kafka中即相当于生产者，有相当于消费者。
- 用法：
  - Source-kafkaChannel-Sink
  - Source-kafkaChannel
  - kafkaChannel-Sink


**第二个Flume**

- kafkaSource
- FileChannle
- HdfsSink

hdfs如何防止小文件的产生：

滚动文件，按照时间，事件和文件大小这三个参数，还可以启动压缩。

**实时架构**

![20211127184453](https://vscodepic.oss-cn-beijing.aliyuncs.com/pic/20211127184453.png)

业务数据导入kafka不能使用sqoop，因为sqoop原理是mr，延迟很高，不适合实时计算，所以我们使用Flink CDC实时读取数据。

将数据通过Flink CDC发送到kafka，此时kafka代表我们的ods层。

离线数仓中将日志文件通过Flume导入kafka中，但是在实时数仓中我们从日志服务器直接发送数据到kafka，这样做时效性很高，减少磁盘io,很快，但是也有缺点，耦合性高，两个系统相互影响，日志服务器出现问题，会影响后面大数据部分kafak的数据读取，不能够对数据进行过滤。在离线数仓中，可以过滤掉非json数据，但是在实时数仓中，传输数据时候不能进行过滤。

ods层：

此时，业务数据，日志数据全部存储在kafka中，也就是ods层，在ods层只有两个主题的数据，**行为数据，也就是日志数据，业务主题，也就是业务数据**，在这一部分会使用Flink中的测输出流，将数据分到不同的主题当中。

在dwd层

对于业务数据，实时表我们存放在kafka中，而维度表存放在HBASE中。

> 小结：离线架构和实时架构是一套，只不过在实时架构中，采集日志数据部分没有使用flume，在采集业务数据的时候，没有使用flink cdc。

两个架构的优缺点：

**离线架构**
 
 优点：耦合性低，解耦，稳定性高。

 缺点：时效性差。

说明：考虑到需求的数据量很大，所以优先的考虑系统的稳定性，耦合性方面原因，考虑未来的发展，数据零肯定变大，所以选定离线架构。

 **实时架构**

优点：时效性高。

缺点：耦合高，稳定性低。

说明：kafka是高可用集群，很不容易挂掉，挂少数机器没有问题。目前数据量小，所有机器在一个机房，数据传输没有问题，挂掉可能性小。


