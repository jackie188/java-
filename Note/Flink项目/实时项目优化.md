## 实时项目优化

所有的优化，优先级最高的当然是资源的配置，资源配置调优永远放在第一位。

在Flink程序中，资源配置就是在Source,transform,sink并行度的设置，一个并行度需要一个slot,而一个slot内存的数量往往在TaskManager刚开始启动的时候，已经确定。当然也可以进行修改，比如在per-job模式中，任务来了才启动我们的taskManager，可以重新配置，在Session中不可以，因为任务来的时候，TaskManager已经启动好了。





## 消费资源配置调优

Flink 性能调优的第一步，就是为任务分配合适的资源，在一定范围内，增加资源的分配与性能的提升是成正比的，实现了最优的资源配置后，在此基础上再考虑进行后面论述的性能调优策略。

提交方式主要是 yarn-per-job，资源的分配在使用脚本提交 Flink 任务时进行指定。

标准的 Flink 任务提交脚本（Generic CLI 模式），从 1.11 开始，增加了通用客户端模式，参数使用-D <property=value>指定

> 如果有时候资源已经够了，但是人为添加超过需要的资源，这样不但不会提升性能，还有可能降低性能，比如map join中大表join小表的时候，小表默认使用的最大内存为25m，如果人为增大这个值，就可能降低性能。
>
> 1. 每一个map任务都会下载一份大表的数据，有网络io，浪费性能。
> 2. 申请资源非常的耗时，在使用yarn提交任务的时候，有一个资源的申请过程，如果分配资源太多，那么申请时间就很长。

~~~ java
bin/flink run \
-t yarn-per-job \
-d \
-p 5 \ 指定并行度
-Dyarn.application.queue=test \ 指定 yarn 队列
-Djobmanager.memory.process.size=1024mb \ 指定 JM 的总进程大小
-Dtaskmanager.memory.process.size=1024mb \ 指定每个 TM 的总进程大小
-Dtaskmanager.numberOfTaskSlots=2 \ 指定每个 TM 的 slot 数
-c com.atguigu.app.dwd.LogBaseApp \
/opt/module/gmall-flink/gmall-realtime-1.0-SNAPSHOT-jar-with-dependencies.jar
~~~

如果是yarn-session或者standalone模式，需要在配置文件中配置资源。

[参数列表](https://ci.apache.org/projects/flink/flink-docs-release-1.12/deployment/config.html)

### 内存设置

生产资源配置：

~~~ java
bin/flink run \
-t yarn-per-job \
-d \
-p 5 \ 指定并行度
-Dyarn.application.queue=test \ 指定 yarn 队列
-Djobmanager.memory.process.size=2048mb \ JM2~4G 足够
-Dtaskmanager.memory.process.size=6144mb \ 单个 TM2~8G 足够
-Dtaskmanager.numberOfTaskSlots=2 \ 与容器核数 1core：1slot 或 1core：2slot
-c com.atguigu.app.dwd.LogBaseApp \与容器核数 1core：1slot 或 1core：2slot
/opt/module/gmall-flink/gmall-realtime-1.0-SNAPSHOT-jar-with-dependencies.jar
~~~

Flink 是实时流处理，关键在于资源情况能不能抗住高峰时期每秒的数据量，通常用QPS/TPS 来描述数据情况。

对于JobManager通常2-4G已经足够。

单个TaskManager，配置2-8G左右，对于具体而言，需要根据我们的业务去测，也就是数据量达到高峰期时候的配置内存量。

那每一个TaskManager里面配置多少个slot呢？

yarn中一个container中默认资源最大是8G，那么我们通常配置与容器的核数有关，通常是`1core：1slot 或 1core：2slot`关系，也就是与容器的核数1：1或者1：2关系。

启动一个TaskManager需要一个Container，而Container最大是8G，所以TaskManager配置内存不能超过容器的内存，通常配置2-8G.如果超过8g,那么需要扩大Container的内存。

container的核心数也可以配置或者指定，我们配置container的核心数之后，每一个TaskManager的slot数量可以参考container的核心数量。如果资源够的情况下，配置1：1，不够情况下配置1：2.配置1：2的话那么一个cpu上需要运行两个任务，运行会慢一点。

> TaskManager和Slot的配置都和yarn 的container容量有关。

在生产中，我们一般不用内存及的状态后端，所以jobManager的内存使用量一般不会太大。

### 并行度设置

#### 最优并行度计算

开发完成后，先进行**压测**。任务并行度给 10 以下，测试单个并行度的处理上限。然后**总 QPS/单并行度的处理能力 = 并行度**。

不能只从 QPS 去得出并行度，因为有些字段少、逻辑简单的任务，单并行度一秒处理几万条数据。而有些数据字段多，处理逻辑复杂，单并行度一秒只能处理 1000 条数据。

最好根据高峰期的 QPS 压测，并行度*1.2 倍，富余一些资源。比如高峰期测出来是50m/s，10个并行度，那么我就一直使用50m/s，10个并行度，跑几个小时做压测，都没有问题，那么说明没问题。*`1.2`防止估算有误差或者数据量增加。

> 如何做压测，积压kafak的数据，然后对Flink程序做压测。

#### Source 端并 行 度的配置

数据源端是 Kafka，Source 的并行度设置为 Kafka 对应 Topic 的分区数。这种情况最好。

如果已经等于 Kafka 的分区数，消费速度仍跟不上数据生产速度，考虑下 Kafka 要扩大分区，同时调大并行度等于分区数。

Flink 的一个并行度可以处理一至多个分区的数据，如果并行度多于 Kafka 的分区数，那么就会造成有的并行度空闲，浪费资源。

> 但是这种方式一定需要在最后尝试，我们调优首先做的就是增加资源。kafka分区数量增加是一个不可逆操作，增加了分区，就不能减少。

#### Transform 端并行度的配置

**Keyby 之前的算子**

一般不会做太重的操作，都是比如 map、filter、flatmap 等处理较快的算子，并行度可以和 source 保持一致。

**Keyby 之后的算子**

如果并发较大，建议设置并行度为 2 的整数次幂，例如：128、256、512；

小并发任务的并行度不一定需要设置成 2 的整数次幂；

大并发任务如果没有 KeyBy，并行度也无需设置为 2 的整数次幂；

> 如果业务很复杂，就提高并行度。

#### Sink 端并 行 度的配置

Sink 端是数据流向下游的地方，可以根据 Sink 端的数据量及下游的服务抗压能力进行评估。

如果 Sink 端是 Kafka，可以设为 Kafka 对应 Topic 的分区数。

Sink 端的数据量小，比较常见的就是监控告警的场景，并行度可以设置的小一些。

Source 端的数据量是最小的，拿到 Source 端流过来的数据后做了细粒度的拆分，数据量不断的增加，到 Sink 端的数据量就非常大。那么在 Sink 到下游的存储中间件的时候就需要提高并行度。

另外 Sink 端要与下游的服务进行交互，并行度还得根据下游的服务抗压能力来设置，

如果在 Flink Sink 这端的数据量过大的话，且 Sink 处并行度也设置的很大，但下游的服务完全撑不住这么大的并发写入，可能会造成下游服务直接被写挂，所以最终还是要在 Sink处的并行度做一定的权衡。

sink端和外部系统交互也有延迟，所以也可以使用批量提交的方式。所以对于sink，一个是降低并行度，一个是批量写入。

> 并行度，是在高峰期做压测得到的。







## 反压处理

## 数据倾斜

数据倾斜也会引起反压，比如一个任务中有5个子任务，那么可能有某一个任务数据量太大产生反压，这种情况往往是数据倾斜导致的问题。

## KafkaSource调优

## FlinkSql调优



## 如何聊优化

做过哪些优化或者解决过什么问题，或者遇到什么问题？这些都是在问优化问题。

1. 第一步，说明**业务场景**，在做什么业务，或者执行什么sql的时候。
2. 第二步：**遇到了什么问题**，往往通过监控工具或者报警系统，发现了什么问题。
3. 第三步：**排查问题**，如果是反压，可能是数据量真的很大，之前还没有做过压测，导致现在所有的并行度全部出现了反压，高峰期扛不住，所以这种情况只能通过添加机器来解决。如果某一个并行度或者任务出现反压，那么可能出现了数据倾斜，我们针对数据倾斜，做了什么解决。如果是mr任务，那么可以通过日志查看，有一两个任务由于数据量大执行特别慢，而其他任务已经执行完成。少数任务卡在了99%.在Flink中是通过反压方式报警提醒。
4. 第四步：**解决问题**，说明解决问题，使用了什么方案解决。