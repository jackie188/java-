
<!-- TOC -->

- [Flink实时数据仓库项目总结](#flink实时数据仓库项目总结)
- [第一章总结](#第一章总结)
    - [普通的实时计算和实时数仓的比较](#普通的实时计算和实时数仓的比较)
  - [说说你对实时数仓的理解或者看法](#说说你对实时数仓的理解或者看法)
  - [介绍以下数仓分层](#介绍以下数仓分层)
    - [实时数仓](#实时数仓)
    - [离线数仓](#离线数仓)
  - [数据仓库为什么要分层？](#数据仓库为什么要分层)
  - [离线计算和实时计算的比较](#离线计算和实时计算的比较)
  - [实时架构和离线架构](#实时架构和离线架构)
    - [离线架构](#离线架构)
    - [实时架构](#实时架构)
  - [讲一下CDC和Flink CDC](#讲一下cdc和flink-cdc)
  - [讲一下Flink cdc,Maxwell和Canal](#讲一下flink-cdcmaxwell和canal)
  - [为什么采用Flink CDC](#为什么采用flink-cdc)
- [第二章总结](#第二章总结)
  - [在分类日志数据的时候，为什么采用测输出流，有没有其他的办法？](#在分类日志数据的时候为什么采用测输出流有没有其他的办法)
  - [为什么把维度数据存储在Rides?](#为什么把维度数据存储在rides)
  - [如何实现动态分流的功能？](#如何实现动态分流的功能)
  - [配置表如何确定](#配置表如何确定)
  - [配置流为什么使用map状态](#配置流为什么使用map状态)
  - [写入Hbase中采用什么方法，为什么？](#写入hbase中采用什么方法为什么)
  - [DWM层访客UV如何计算](#dwm层访客uv如何计算)
  - [DWM层跳出明细层如何计算](#dwm层跳出明细层如何计算)
  - [如何写Flink cep代码](#如何写flink-cep代码)

<!-- /TOC -->

## Flink实时数据仓库项目总结

## 第一章总结

#### 普通的实时计算和实时数仓的比较

这个题从**时效性**和**复用性**进行回答：

普通实时计算：时效性好，但是计算的复用性很差。没有保留中间结果。

实时数仓：时效性可能不是很好，但是中间的计算结果得到保留，数据的复用性很好。

### 说说你对实时数仓的理解或者看法

抓住分层这个概念，从分层引出，分两个部分：
- 数据分层
- 计算分层

### 介绍以下数仓分层

把离线数仓和实时数仓分开来说：

#### 实时数仓

实时数仓中，我们一般将数据分为五层：

ODS：数据原始层，存放行为数据(日志)和业务数据，那么在实时数仓中，通常将ods层的数据存储kafka的主题当中。

DWD：我们一般将业务数据的事实表数据存放在DWD层的kafka中，而将业务数据中的维度表数据存放在DIM层，通常存储在Hbase数据库中。

**问题：为什么没有把维度表数据存储在kafka的主题当中呢？**

两个原因
1. kafka中数据存放时间有限制
2. 根据id取Kafka中查询数据很困难。

DIM：DIM和DWD层其实是一层的，只不过存放的数据不一样，并且数据存放的位置也不一样。

DWM：DWM算是DWD层数据到DWS层数据的中间过渡数据，这一部分数据依然算是明细数据，将DWD和DIM层数据进行轻度的加工，形成一个宽表，但是本质上还是明细数据。

DWS：按照主题将事实表数据进行聚合操作，形成一个以主题为单位的宽表，为ods层的数据查询做准备。

ODS:这一层可以认为是我们的需求，直接根据需求取查询数据即可

#### 离线数仓

ODS(Operation Data Store)：原始数据层，存放原始数据，直接加载原始日志、数据，数据保持原貌不做处理，这部分数据一般存储在文件系统的HDFS中。

DWD(data warehouse detail)：对ODS层数据进行清洗（去除空值，脏数据，超过极限范围的数据）、脱敏等。保存业务事实明细，一行信息代表一次业务行为，例如一次下单。

DIM层，维度层，保存维度数据，主要是对业务事实的描述信息，例如何人，何时，何地等

DWS(data warehouse service):以DWD为基础，按天进行轻度汇总。一行信息代表一个主题对象一天的汇总行为，例如一个用户一天下单次数

DWT(data warehouse Topic):以DWS为基础，对数据进行累积汇总。一行信息代表一个主题对象的累积行为，例如一个用户从注册那天开始至今一共下了多少次单

ADS(Application Data Store):为各种统计报表提供数据

**为什么实时数仓中没有DWT层？**

因为实时数仓是来一条数据处理一条数据，不需要宝轮历史数据。

### 数据仓库为什么要分层？

1. **复杂的问题简单化**

将复杂的任务分解成多层来完成，每一层只处理简单的任务，方便定位问题。

2. **减少重复开发**

规范数据分层，通过的中间层数据，能够减少极大的重复计算，增加一次计算结果的复用性。

3. **隔离原始数据**

不论是数据的异常还是数据的敏感性，使真实数据与统计数据解耦开。

![20211205181322](https://vscodepic.oss-cn-beijing.aliyuncs.com/pic/20211205181322.png)

### 离线计算和实时计算的比较

**离线计算**

数据输入确定，计算数据量较大，时间长，统计的指标较多，从技术角度来说，属于批处理计算。

**实时计算**

输入数据不确定的，计算数据量相对小，计算时间短，更加注重用户的体验，以及用户的交互性，从技术角度来说，属于流处理。

**即席查询**

强调查询的临时性，需求的临时性。

presto:当场计算，基于内存速度快。

kylin:预计算，提前计算好。做多维度分析(hive with cube),数据有多种维度，那么kylin会把所有的维度组合全部计算好。需要的时候直接拿去即可。


### 实时架构和离线架构

#### 离线架构

日志：使用flume+kafka+flume--->hdfs

业务数据：sqoop--->hdfs

 优点：耦合性低，解耦，稳定性高。

 缺点：时效性差。

说明：考虑到需求的数据量很大，所以优先的考虑系统的稳定性，耦合性方面原因，考虑未来的发展，数据零肯定变大，所以选定离线架构。

#### 实时架构

日志：日志服务器--->kafka

业务数据：mysql+Flink CDC--->kafka

优点：时效性高。

缺点：耦合高，稳定性低。

说明：kafka是高可用集群，很不容易挂掉，挂少数机器没有问题。目前数据量小，所有机器在一个机房，数据传输没有问题，挂掉可能性小。

### 讲一下CDC和Flink CDC

CDC的种类：
- 基于查询的CDC
- 基于Binlog的CDC

![20211128125235](https://vscodepic.oss-cn-beijing.aliyuncs.com/pic/20211128125235.png)

基于查询的Sqoop，我们是通过where查询语句实现不同数据的导入。而基于BinLgog cdc是不需要读取数据，他读取的是mysql的操作日志，典型的产品如上图所示。

**是否捕获所有变化：**

基于sqoop导入数据的时候，是每一天某个时间进行集中的数据导入。而基于Binlog方式，是基于流的模式，每一次发生变化，都可以监控到数据的变化。

**延迟性**

基于查询的方式，可能会丢失数据，查询的是快照，最后的结果，也就是导入的是最终的数据，中间的过程数据是无法导入的。一条数据发生多次变化，只能拿到最后一次的数据，Binlog可以捕获所有数据，每变化一次，就加载一次。

**是否产生压力**

是否增加数据库压力，基于查询使用的是select语句，所以是一次查询，但是基于Binliog，读取的是一个磁盘文件，不会堆服务器产生太大压力。

Flink 社区开发了 flink-cdc-connectors 组件，这是一个可以直接从 MySQL、PostgreSQL等数据库直接读取**全量数据和增量变更数据**的 source 组件

### 讲一下Flink cdc,Maxwell和Canal

Maxwell与Canal工具对比

1. Maxwell 没有 Canal 那种 server+client 模式，只有一个 server 把数据发送到消息队列或 redis。
2. Maxwell 有一个亮点功能，就是 Canal 只能抓取最新数据，对已存在的历史数据没有办法处理。而 Maxwell 有一个 bootstrap 功能，可以直接引导出完整的历史数据用于初始化，非常好用。
3. Maxwell 不能直接支持 HA，但是它**支持断点还原**，即错误解决后重启继续上次点儿读取数据。
4. Maxwell 只支持 json 格式，而 Canal 如果用 Server+client 模式的话，可以自定义格式。
5. Maxwell 比 Canal 更加轻量级。

### 为什么采用Flink CDC

1. 对于插入，删除和更新数据而言，他们三者返回的数据格式是有很大的区别的，相比较而言，Flink cdc返回的结果更加好处理。
2. flink cdc可以做初始化，maxwell也可以做，但是canal不可以做。
3. 断点续传：三者都可以做，flink cdc是checkpoint保存，maxwell是保存在mysql数据库，而canal是保存在本地磁盘。
4. 数据封装格式，flink cdc和canal可以自定义，maxwell使用的是json格式。
5. 高可用：flink cdc支持，canal支持，maxwell支持。

综上几点说明，flink cdc更适合我们。

## 第二章总结

### 在分类日志数据的时候，为什么采用测输出流，有没有其他的办法？

如果是在spark Streaming中，我们可以使用Filter进行过滤操作，但是在Flink中，我们有测输出流，所以使用测输出流代替了Filter过滤操作。


### 为什么把维度数据存储在Rides?

- **在这里为什么没有选择Rides,因为维度数据数据量很大，特别是user维度，数据很大，所以选择使用HBase.也可以用户维度使用Hbase存储，其他的使用Rides，但是这样就复杂了。**
- **为什么没有放在Mysql数据库，并发压力大，生产环境中，mysql是和后台打交道，用户的请求都来自mysql，mysql是相应用户的请求，如果我们这个时候去访问mysql，访问压力很大。**

### 如何实现动态分流的功能？

### 配置表如何确定

### 配置流为什么使用map状态

### 写入Hbase中采用什么方法，为什么？

### DWM层访客UV如何计算

1. 我们根据日志中的last_page_id判断，如果该字段是null，那么说明是今天第一次登录该页面，否则不空，也就是说不是第一次。这个字段代表上一跳的地址，为null说明没有上一跳。
2. 由于访客可以在一天中多次进入应用，所以我们要在一天的范围内进行去重，因为用户每一次访问页面，都会产生一个访问日志。

> 1. 状态中保存的是时间，我们判断的是某一天，所以将时间戳保存为状态。
> 2. 因为状态主要用来保存用户今天是否访问过，所以过了今天之后就没用了，要定期清除状态，所以给状态设置过期时间24h.


### DWM层跳出明细层如何计算

首先说明思路：

判断用户跳出某一个页面，有两个步骤：
1. 该页面是用户近期访问的第一个页面，这个可以通过该页面是否有上一个页面（last_page_id）来判断，如果这个表示为空，就说明这是这个访客这次访问的第一个页面。
2. 首次访问之后很长一段时间（自己设定），用户没继续再有其他页面的访问。如果有会话id的话，我们可以使用会话id方便的解决。

**思路一**

使用会话id,根据会话id来判断，多次进入页面，有多个会话id。但是在现有条件下，我们没有会话id。引出思路二：

**思路二**

在Flink，会话窗口的应用场景是，当我们需要根据会话id取计算窗口的某一些指标的时候，但是没有会话id情况下，我们可以使用会话窗口代替，如果两个事件中间的时间间隔在一个很小的范围内，我们就认为是一次会话。

但是，这种情况也存在一些问题，就是数据丢失问题，说一说如何会发生数据的丢失，然后引出cep解决方案，复杂事件处理：

**思路三**

1. 该页面是用户近期访问的第一个页面，这个可以通过该页面是否有上一个页面（last_page_id）来判断，如果这个表示为空，就说明这是这个访客这次访问的第一个页面。
2. 首次访问之后很长一段时间（自己设定），用户没继续再有其他页面的访问。如果有会话id的话，我们可以使用会话id方便的解决。如果使用cep，那么就是下一个条件也为null即可。

flink cep可以解决从复杂的事件流中匹配出符合条件的事件，通过上面两个步骤，很明显我们只需要定义两个简单条件即可。通过定义两个条件，可以匹配出我们需要的事件。


其实本质上，**用户跳出行为是一个条件事件加一个超时事件的组合**，既然要超时，所以数据肯定存在延迟，所以我们需要使用watermark机制。

### 如何写Flink cep代码

1. 首先我们需要定义模式序列，模式序列可以是简单的，组合或者复杂的模式。
2. 将定义好的模式序列应用到我们的事件流中。
3. 提取匹配上的超时事件。




