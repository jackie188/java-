## 容错机制

state状态一般存储在内存中，而checkpoint一般存储在磁盘中。

CheckPoint和State的关系

![1623388709313](https://tprzfbucket.oss-cn-beijing.aliyuncs.com/hadoop/202106/11/131831-48171.png)

### 状态一致性

当在分布式系统中引入状态时，自然也引入了一致性问题。一致性实际上是"正确性级别"的另一种说法， 也就是说在成功处理故障并恢复之后得到的结果，与没有发生任何故障时得到的结果相比，前者到底有多正确？举例来说，假设要对最近一小时登录的用户计数。在系统经历故障之后，计数结果是多少？ 如果有偏差，是有漏掉的计数还是重复计数？ 

#### 什么是状态一致性

- 有状态的流处理，内部每个算子任务都可以有自己的状态
- 对于流处理器内部来说，所谓的状态一致性，其实就是我们所说的计算结果要保证准确。
- 一条数据不应该丢失，也不应该重复计算
- 在遇到故障时可以恢复状态，恢复以后的重新计算，结果应该也是完全正确的。

#### 一致性级别

在流处理中，一致性可以分为 3 个级别：

- at-most-once: 这其实是没有正确性保障的委婉说法——故障发生之后，计数结果可能丢失。同样的还有 udp。当任务故障时，**最简单的做法是什么都不干，既不恢复丢失的状态，也不重播丢失的数据**。At-most-once语义的含义是最多处理一次事件。保证处理速度很快，性能达到最优，但是缺点就是会发生丢失数据。
- at-least-once: 这表示计数结果可能大于正确值，但绝不会小于正确值。也就是说，计数程序在发生故障后可能多算，但是绝不会少算。在大多数的真实应用场景，我们希望不丢失事件。这种类型的保障称为at-least-once，意思是所有的事件都得到了处理，而一些事件还可能被处理多次。
- exactly-once: 这指的是系统保证在发生故障后得到的计数结果与正确值一致。恰好处理一次是最严格的保证，也是最难实现的。恰好处理一次语义不仅仅意味着没有事件丢失，还意味着针对每一个数据，内部状态仅仅更新一次。 

**一致性检查点（Checkpoints）**

- Flink使用了一种轻量级快照机制——检查点（checkpoint）来保证exactly-once语义，这个快照选取的是刚好所有的数据都处理完成后的那个时间点保存快照，另外在source端还要保存检查点数据的偏移量信息。
- 有状态流应用的一致检查点，其实就是：所有任务的状态，在某个时间点的一份拷贝（一份快照）。而这个时间点，应该是所有任务都恰好处理完一个相同的输入数据的时候。
- 应用状态的一致检查点，是Flink故障恢复机制的核心

![1616373943517](C:\Users\MrR\AppData\Roaming\Typora\typora-user-images\1616373943517.png)

曾经， at-least-once 非常流行。第一代流处理器(如 Storm 和 Samza)刚问世时只保证 at-least-once，原因有二。 

- 保证 exactly-once 的系统实现起来更复杂。这在基础架构层(决定什么代表正确，以及 exactly-once 的范围是什么)和实现层都很有挑战性。
- 流处理系统的早期用户愿意接受框架的局限性，并在应用层想办法弥补(例如使应用程序具有幂等性，或者用批量计算层再做一遍计算)。 

最先保证 exactly-once 的系统(Storm Trident 和 Spark Streaming)在性能和表现力这两个方面付出了很大的代价。为了保证 exactly-once，这些系统无法单独地对每条记录运用应用逻辑，而是同时处理多条(一批)记录，保证对每一批的处理要么全部成功，要么全部失败。这就导致在得到结果前，必须等待一批记录处理结束。因此，用户经常不得不使用两个流处理框架(一个用来保证 exactly-once，另一个用来对每个元素做低延迟处理)，结果使基础设施更加复杂。曾经，用户不得不在保证exactly-once 与获得低延迟和效率之间权衡利弊。 Flink 避免了这种权衡。 

Flink 的一个重大价值在于， 它既保证了 exactly-once，也具有低延迟和高吞吐的处理能力 

从根本上说， Flink 通过使自身满足所有需求来避免权衡，它是业界的一次意义重大的技术飞跃。尽管这在外行看来很神奇，但是一旦了解，就会恍然大悟。 

#### 端到端（end-to-end）状态一致性 

目前我们看到的一致性保证都是由流处理器实现的，也就是说都是在 Flink 流处理器内部保证的；而在真实应用中，流处理应用除了流处理器以外还包含了数据源（例如 Kafka）和输出到持久化系统。 

端到端的一致性保证，意味着结果的正确性贯穿了整个流处理应用的始终；每一个组件都保证了它自己的一致性， 整个端到端的一致性级别取决于所有组件中一致性最弱的组件。具体可以划分如下： 

- 内部保证 —— 依赖 checkpoint
- source 端 —— 需要外部源可重设数据的读取位置
- sink 端 —— 需要保证从故障恢复时，数据不会重复写入外部系统 
  - 而对于 sink 端，又有两种具体的实现方式：幂等（ Idempotent）写入和事务性（ Transactional）写入。 

**幂等写入**
所谓幂等操作，是说一个操作，可以重复执行很多次，但只导致一次结果更改，也就是说，后面再重复执行就不起作用了。 幂等写入可能存在数据的重复写入，因为是进行追加操作，会重复写入检查点之后的数据。有短暂的数据不一致，这里的写入指的是写入外部系统。

可以想象为集合中的hashmap

![1616374043747](https://tprzfbucket.oss-cn-beijing.aliyuncs.com/hadoop/202103/22/084726-924873.png)

**事务写入**

事务（Transaction）

- 应用程序中一系列严密的操作，所有操作必须成功完成，否则在每个操作中所作的所有更改都会被撤消
- 具有原子性：一个事务中的一系列的操作要么全部成功，要么一个都不做

需要构建事务来写入外部系统，构建的事务对应着 checkpoint，等到 checkpoint真正完成的时候，才把所有对应的结果写入 sink 系统中。 （和外部系统构建一个事务，提交的时候是基于事务的提交）

对于事务性写入，具体又有两种实现方式：预写日志（ WAL）和两阶段提交（ 2PC）。 DataStream API 提供了 GenericWriteAheadSink 模板类和TwoPhaseCommitSinkFunction 接口，可以方便地实现这两种方式的事务性写入。 

- 预写日志（Write-Ahead-Log，WAL）
  - 把结果数据先当成状态保存，然后在收到checkpoint完成的通知时，一次性写入sink系统
  - 简单易于实现，由于数据提前在状态后端中做了缓存，所以无论什么sink系统，都能用这种方式一批搞定，这样写入的时候就是批处理，会有延迟时间。但是也有问题，如果写入数据的时候，只能写入一半的话，那么就会发生故障，所以不能严格意义上说是流处理。
  - DataStreamAPI提供了一个模板类：GenericWriteAheadSink，来实现这种事务性sink
- 两阶段提交（Two-Phase-Commit，2PC）
  - 对于每个checkpoint，sink任务会启动一个事务，并将接下来所有接收的数据添加到事务里
  - 然后将这些数据写入外部sink系统，但不提交它们——这时只是“预提交”
  - 当它收到checkpoint完成的通知时，它才正式提交事务，实现结果的真正写入
  - 这种方式真正实现了exactly-once，它需要一个提供事务支持的外部sink系统。Flink提供了TwoPhaseCommitSinkFunction接口。
  - 简单来说实现精确一次端到端的传输是用：checkpoint和事务的提交结合
- 2PC对外部sink系统的要求
  - 外部sink系统必须提供事务支持，或者sink任务必须能够模拟外部系统上的事务
  - 在checkpoint的间隔期间里，必须能够开启一个事务并接受数据写入
  - 在收到checkpoint完成的通知之前，事务必须是“等待提交”的状态。
  - 在故障恢复的情况下，这可能需要一些时间。如果这个时候sink系统关闭事务（例如超时了），那么未提交的数据就会丢失
  - sink任务必须能够在进程失败后恢复事务
  - 提交事务必须是幂等操作

不同 Source 和 Sink 的一致性保证可以用下表说明： 

如果source端不可以重置数据的偏移量，那么后面就会丢失数据，

如果source端可以重置数据的偏移量，那么至少可以保证at-least-once

![1616301435004](https://tprzfbucket.oss-cn-beijing.aliyuncs.com/hadoop/202103/22/081650-483061.png)

#### Flink+Kafka端到端状态一致性的保证

- Flink内部——利用checkpoint机制，把状态存盘，发生故障的时候可以恢复，保证内部的状态一致性。
- source——kafka consumer作为source，可以将偏移量保存下来，如果后续任务出现了故障，恢复的时候可以由连接器重置偏移量，重新消费数据，保证一致性
- sink——kafka producer作为sink，采用两阶段提交sink，需要实现一个TwoPhaseCommitSinkFunction

**Exactly-once两阶段提交**

![1616376244725](https://tprzfbucket.oss-cn-beijing.aliyuncs.com/hadoop/202106/14/201912-125712.png)

- JobManager协调各个TaskManager进行checkpoint存储
- checkpoint保存在StateBackend中，默认StateBackend是内存级的，也可以改为文件级的进行持久化保存

![1616376310417](C:\Users\MrR\AppData\Roaming\Typora\typora-user-images\1616376310417.png)

- 当checkpoint启动时，JobManager会将检查点分界线（barrier）注入数据流
- 当每一个算子接收到数据流中的barrier的时候，会进行checkpoint处理，保存当前算子的数据状态。
- barrier会在算子间传递下去

![1616376350174](C:\Users\MrR\AppData\Roaming\Typora\typora-user-images\1616376350174.png)

- 每个算子会对当前的状态做个快照，保存到状态后端
- checkpoint机制可以保证内部的状态一致性

![1616376396040](C:\Users\MrR\AppData\Roaming\Typora\typora-user-images\1616376396040.png)

- 每个内部的transform任务遇到barrier时，都会把状态存到checkpoint里
- 什么时候开启一个新的事务？当sink端接受到barrier数据的时候，第一件做的事情是sink执行checkpoint操作，就是保存自己的数据，但是此时整个checkpoint并没有完成，可能还有其他的算子checkpoint没有执行完毕，而sink这个时候会开启一个新的事务，因为barrier是一个分界线，以barrier为界限，之前的数据和之后的数据分别属于不同的checkpoint，在做两阶段提交的时候，要把事务和checkpoint绑定在一起，所以barrier之后带来的数据状态的改变，不应该在前一个checkpoint里面，后面数据状态的改变，应该在下一个checkpoint和事务中。当所有的算子的checkpoint全部完成的时候，向jobmanager报告checkpoint完成，此时jobmanager通知sink正式提交前一个事务，写入数据。
- sink任务首先把数据写入外部kafka，这些数据都属于预提交的事务；遇到barrier时，把状态保存到状态后端，并开启新的预提交事务

![1616376443799](C:\Users\MrR\AppData\Roaming\Typora\typora-user-images\1616376443799.png)

- 当所有算子任务的快照完成，也就是这次的checkpoint完成时，JobManager会向所有任务发通知，确认这次checkpoint完成
- sink任务收到确认通知，正式提交之前的事务，kafka中未确认数据改为“已确认”

**Exactly-once两阶段提交步骤**

- 第一条数据来了之后，开启一个kafka的事务（transaction），正常写入kafka分区日志但标记为未提交，这就是“预提交”
- jobmanager触发checkpoint操作，barrier从source开始向下传递，遇到barrier的算子将状态存入状态后端，并通知jobmanager
- sink连接器收到barrier，保存当前状态，存入checkpoint，通知jobmanager，并开启下一阶段的事务，用于提交下个检查点的数据
- jobmanager收到所有任务的通知，发出确认信息，表示checkpoint完成
- sink任务收到jobmanager的确认信息，正式提交这段时间的数据
- 外部kafka关闭事务，提交的数据可以正常消费了。

#### 状态的恢复和重启策略

![1623392860474](https://tprzfbucket.oss-cn-beijing.aliyuncs.com/hadoop/202106/11/142743-100875.png)

##### 默认的重启策略：

当程序出现异常的时候，不会抛出异常，而是执行重启程序。默认重启策略可以无限重启。

- 在配置了checkpoint的情况下，不做任何配置，默认是无限重启自动恢复。可以解决小异常，但是可能隐藏真正的错误。
- 如果配置了Checkpoint,而没有配置重启策略,那么代码中出现了非致命错误时,程序会无限重启

##### 单独配置无重启策略

```java
//Job直接失败，不会尝试进行重启
 //设置方式1:
 restart-strategy: none
 
 //设置方式2:
 //无重启策略也可以在程序中设置
 val env = ExecutionEnvironment.getExecutionEnvironment()
 env.setRestartStrategy(RestartStrategies.noRestart())
```

#### 固定延迟重启策略--开发中使用

```java
设置方式1:
 重启策略可以配置flink-conf.yaml的下面配置参数来启用，作为默认的重启策略:
 例子:
 restart-strategy: fixed-delay
 restart-strategy.fixed-delay.attempts: 3
 restart-strategy.fixed-delay.delay: 10 s
 
 设置方式2:
 也可以在程序中设置:
 val env = ExecutionEnvironment.getExecutionEnvironment()
 env.setRestartStrategy(RestartStrategies.fixedDelayRestart(
   3, // 最多重启3次数
   Time.of(10, TimeUnit.SECONDS) // 重启时间间隔
 ))
 上面的设置表示:如果job失败,重启3次, 每次间隔10

```

#### 失败率重启策略--开发偶尔使用

```java
设置方式1:
 失败率重启策略可以在flink-conf.yaml中设置下面的配置参数来启用:
 例子:
 restart-strategy:failure-rate
 restart-strategy.failure-rate.max-failures-per-interval: 3
 restart-strategy.failure-rate.failure-rate-interval: 5 min
 restart-strategy.failure-rate.delay: 10 s
 
 设置方式2:
 失败率重启策略也可以在程序中设置:
 val env = ExecutionEnvironment.getExecutionEnvironment()
 env.setRestartStrategy(RestartStrategies.failureRateRestart(
   3, // 每个测量时间间隔最大失败次数
   Time.of(5, TimeUnit.MINUTES), //失败率测量的时间间隔
   Time.of(10, TimeUnit.SECONDS) // 两次连续重启的时间间隔
 ))
//上面的设置表示:如果5分钟内job失败不超过三次,自动重启, 每次间隔10s (如果5分钟内程序失败超过3次,则程序退出)
```

### 检查点（ checkpoint）

Flink 具体如何保证 exactly-once 呢? 它使用一种被称为"检查点"（ checkpoint）的特性，在出现故障时将系统重置回正确状态。下面通过简单的类比来解释检查点的作用。 

假设你和两位朋友正在数项链上有多少颗珠子，如下图所示。你捏住珠子，边数边拨，每拨过一颗珠子就给总数加一。你的朋友也这样数他们手中的珠子。当你分神忘记数到哪里时，怎么办呢? 如果项链上有很多珠子，你显然不想从头再数一遍，尤其是当三人的速度不一样却又试图合作的时候，更是如此(比如想记录前一分钟三人一共数了多少颗珠子，回想一下一分钟滚动窗口)。 

![1616301615060](C:\Users\MrR\AppData\Roaming\Typora\typora-user-images\1616301615060.png)

于是，你想了一个更好的办法: 在项链上每隔一段就松松地系上一根有色皮筋，将珠子分隔开; 当珠子被拨动的时候，皮筋也可以被拨动; 然后，你安排一个助手，让他在你和朋友拨到皮筋时记录总数。用这种方法，当有人数错时，就不必从头开始数。相反，你向其他人发出错误警示，然后你们都从上一根皮筋处开始重数，助
手则会告诉每个人重数时的起始数值，例如在粉色皮筋处的数值是多少。 

Flink 检查点的作用就类似于皮筋标记。数珠子这个类比的关键点是: 对于指定的皮筋而言，珠子的相对位置是确定的; 这让皮筋成为重新计数的参考点。总状态(珠子的总数)在每颗珠子被拨动之后更新一次，助手则会保存与每根皮筋对应的检查点状态，如当遇到粉色皮筋时一共数了多少珠子，当遇到橙色皮筋时又是多少。当问题出现时，这种方法使得重新计数变得简单。 

#### Flink 的检查点算法 

```java
val stream: DataStream[(String, Int)] = ...
val counts: DataStream[(String, Int)] = stream
.keyBy(record => record._1)
.mapWithState( (in: (String, Int), state: Option[Int]) =>
              state match {
case Some(c) => ( (in._1, c + in._2), Some(c + in._2) )
case None => ( (in._1, in._2), Some(in._2) )
})
```

该程序有两个算子: keyBy 算子用来将记录按照第一个元素(一个字符串)进行分组，根据该 key 将数据进行重新分区，然后将记录再发送给下一个算子: 有状态的map 算子(mapWithState)。 map 算子在接收到每个元素后，将输入记录的第二个字段的数据加到现有总数中，再将更新过的元素发射出去。下图表示程序的初始状态: 输入流中的 6 条记录被检查点分割线(checkpoint barrier)隔开，所有的 map 算子状态均为 0(计数还未开始)。所有 key 为 a 的记录将被顶层的 map 算子处理，所有 key 为 b的记录将被中间层的 map 算子处理，所有 key 为 c 的记录则将被底层的 map 算子处理。 

![1616302124351](C:\Users\MrR\AppData\Roaming\Typora\typora-user-images\1616302124351.png)

上图是程序的初始状态。注意， a、 b、 c 三组的初始计数状态都是 0，即三个圆柱上的值。 ckpt 表示检查点分割线（ checkpoint barriers） 。每条记录在处理顺序上严格地遵守在检查点之前或之后的规定，例如["b",2]在检查点之前被处理， ["a",2]则在检查点之后被处理。 

当该程序处理输入流中的 6 条记录时，涉及的操作遍布 3 个并行实例(节点、 CPU内核等)。那么，检查点该如何保证 exactly-once 呢? 

检查点分割线和普通数据记录类似。它们由算子处理，但并不参与计算，而是会触发与检查点相关的行为。当读取输入流的数据源(在本例中与 keyBy 算子内联)遇到检查点屏障时，它将其在输入流中的位置保存到持久化存储中。如果输入流来自消息传输系统(Kafka)，这个位置就是偏移量。 Flink 的存储机制是插件化的，持久
化存储可以是分布式文件系统，如 HDFS。下图展示了这个过程 

![1616302376919](https://tprzfbucket.oss-cn-beijing.aliyuncs.com/hadoop/202103/21/125258-782428.png)

当 Flink 数据源(在本例中与 keyBy 算子内联)遇到检查点分界线（ barrier） 时，它会将其在输入流中的位置保存到持久化存储中。这让 Flink 可以根据该位置重启。 

检查点像普通数据记录一样在算子之间流动。当 map 算子处理完前 3 条数据并收到检查点分界线时，它们会将状态以异步的方式写入持久化存储，如下图所示。 

![1616302487062](C:\Users\MrR\AppData\Roaming\Typora\typora-user-images\1616302487062.png)

位于检查点之前的所有记录(["b",2]、 ["b",3]和["c",1])被 map 算子处理之后的情况。此时，持久化存储已经备份了检查点分界线在输入流中的位置(备份操作发生在barrier 被输入算子处理的时候)。 map 算子接着开始处理检查点分界线，并触发将状态异步备份到稳定存储中这个动作。 

当 map 算子的状态备份和检查点分界线的位置备份被确认之后，该检查点操作就可以被标记为完成，如下图所示。我们在无须停止或者阻断计算的条件下，在一个逻辑时间点(对应检查点屏障在输入流中的位置)为计算状态拍了快照。通过确保备份的状态和位置指向同一个逻辑时间点，后文将解释如何基于备份恢复计算，从而保证 exactly-once。值得注意的是，当没有出现故障时， Flink 检查点的开销极小，检查点操作的速度由持久化存储的可用带宽决定。回顾数珠子的例子: 除了因为数错而需要用到皮筋之外，皮筋会被很快地拨过。 

![1616302642963](C:\Users\MrR\AppData\Roaming\Typora\typora-user-images\1616302642963.png)

检查点操作完成，状态和位置均已备份到稳定存储中。输入流中的所有数据记录都已处理完成。值得注意的是，备份的状态值与实际的状态值是不同的。备份反映的是检查点的状态。 

如果检查点操作失败， Flink 可以丢弃该检查点并继续正常执行，因为之后的某一个检查点可能会成功。虽然恢复时间可能更长，但是对于状态的保证依旧很有力。只有在一系列连续的检查点操作失败之后， Flink 才会抛出错误，因为这通常预示着发生了严重且持久的错误 

现在来看看下图所示的情况: 检查点操作已经完成，但故障紧随其后。 

![1616302748623](C:\Users\MrR\AppData\Roaming\Typora\typora-user-images\1616302748623.png)

在这种情况下， Flink 会重新拓扑(可能会获取新的执行资源)，将输入流倒回到上一个检查点，然后恢复状态值并从该处开始继续计算。在本例中， ["a",2]、 ["a",2]和["c",2]这几条记录将被重播。

下图展示了这一重新处理过程。从上一个检查点开始重新计算，可以保证在剩下的记录被处理之后，得到的 map 算子的状态值与没有发生故障时的状态值一致。 

 ![1616302900084](https://tprzfbucket.oss-cn-beijing.aliyuncs.com/hadoop/202103/21/130141-647076.png)

Flink 将输入流倒回到上一个检查点屏障的位置，同时恢复 map 算子的状态值。然后， Flink 从此处开始重新处理。这样做保证了在记录被处理之后， map 算子的状态值与没有发生故障时的一致。 

Flink 检查点算法的正式名称是异步分界线快照(asynchronous barrier snapshotting)。该算法大致基于 Chandy-Lamport 分布式快照算法。
检查点是 Flink 最有价值的创新之一，因为它使 Flink 可以保证 exactly-once，并且不需要牺牲性能。 

#### 一致性检查点

![1616309570252](https://tprzfbucket.oss-cn-beijing.aliyuncs.com/hadoop/202106/11/131309-394748.png)

- Flink故障恢复机制的核心，就是应用状态的一致性检查点
- 有状态流应用的一致检查点，其实就是所有任务的状态，在某个时间点的一份拷贝（一份快照）；这个时间点，应该是所有任务都恰好处理完一个相同的输入数据的时候

#### 从检查点中恢复

- 在执行流应用程序期间，Flink会定期保存状态的一致检查点
- 如果发生故障，Flink将会使用最近的检查点来一致恢复应用程序的状态，并重新启动处理流程

![1616309793406](https://tprzfbucket.oss-cn-beijing.aliyuncs.com/hadoop/202103/21/145636-187637.png)

遇到故障之后，第一步就是重启应用

![1616309846884](C:\Users\MrR\AppData\Roaming\Typora\typora-user-images\1616309846884.png)

第二步是从checkpoint中读取状态，将状态重置
从检查点重新启动应用程序后，其内部状态与检查点完成时的状态完全相同

![1616309885786](C:\Users\MrR\AppData\Roaming\Typora\typora-user-images\1616309885786.png)

第三步：开始消费并处理检查点到发生故障之间的所有数据
这种检查点的保存和恢复机制可以为应用程序状态提供“精确一次”（exactly-once）的一致性，因为所有算子都会保存检查点并恢复其所有状态，这样一来所有的输入流就都会被重置到检查点完成时的位置

#### 检查点算法的实现

- 一种简单的想法
  - ——暂停应用，保存状态到检查点，再重新恢复应用
    •Flink的改进实现
- 基于Chandy-Lamport算法的分布式快照
  - 将检查点的保存和数据处理分离开，不暂停整个应用

#### Flink检查点算法

**Checkpoint过程**

![1623388870170](https://tprzfbucket.oss-cn-beijing.aliyuncs.com/hadoop/202106/11/132216-647596.png)

![1623388940699](https://tprzfbucket.oss-cn-beijing.aliyuncs.com/hadoop/202106/11/132223-943696.png)

![1623389107026](https://tprzfbucket.oss-cn-beijing.aliyuncs.com/hadoop/202106/11/132509-633562.png)

在进行写快照的过程中是异步执行的。简单来说checkpoint就是按照固定的时间间隔把state中的状态进行持久化处理。

**原理**

Flink的检查点算怯中会用到一类名为检查点分隔符 (checkpoint barrier) 的特殊记录。和水位线类似，这些检查点分隔符会通过数据源算子注入到常规的记录流中。相对其他记录，它们在流中的位置无怯提前或延后。为了标识所属的检查点，每个检查点分隔符都会带有一个检查点编号，这样就把一条数据流从逻辑上分成了两个部分。所有先于分隔符的记录所引起的状态更改都会被包含在分隔符所对应的检查点之中;而所有晚于分隔符的记录所引起的状态更改者H会被纳入之后的检查点中。 

barrier代表的数据就是把一条数据流分隔开。检查点存储的是数据的偏移量

![1616310125285](https://tprzfbucket.oss-cn-beijing.aliyuncs.com/hadoop/202103/21/150224-406403.png)

现在是一个有两个输入流的应用程序，用并行的两个Source任务来读取

JobManager会向每个source任务发送一条带有新检查点ID的消息，通过这种方式来启动检查点

![1616310546745](https://tprzfbucket.oss-cn-beijing.aliyuncs.com/hadoop/202103/21/150932-895539.png)

当 一个数据源任务收到消息后，会暂停发出记录 ， 利用状态后端触发生成本 地状态的检查点，并把该检查点分隔符连同检查点编号广播至所有传出的数据流分区。状态后端会在状态存为检查点完成后通知任务，随后任务会给jobManager发送确认消息，在将所有分隔符发出后，数据源将恢复正常工作。 通过向输出流中注入分隔符，数据源函数定义了需要在流中哪些位置生成检 查点 。 下图展示了流式应用为数据源任务的本地状态生成检查点并且发出检查分隔符。 

![1616310510607](https://tprzfbucket.oss-cn-beijing.aliyuncs.com/hadoop/202103/21/150901-244841.png)

每一个算子会等到他的上游所有发送的barrier都到齐后然后在执行check point工作。

数据源任务发出的检查点分隔符会传输到与之相连的任务 。 和水位线类似，检查点分隔符总是以广播形式发送 ，从而可以确保每个任务能从它们 的每个 输入都收到一个分隔符。当任务收到一个新检查点的分隔符时，会继续等待所有其他输入分区也发来这个检查点的分隔符。在等待过程中，它会继续处理那些从还未提供分隔符的分区发来的数据。对于已经提供分隔符的分区，它们新到来的记录会被缓冲起来，不能处理。这个等待所有分隔符到达的过程称为分隔符对齐，

![1616311171773](https://tprzfbucket.oss-cn-beijing.aliyuncs.com/hadoop/202103/21/151946-831349.png)

- 分界线对齐：barrier向下游传递，sum任务会等待所有输入分区的barrier到达
- 对于barrier已经到达的分区，继续到达的数据会被缓存
- 而barrier尚未到达的分区，数据会被正常处理 

![1616311234484](C:\Users\MrR\AppData\Roaming\Typora\typora-user-images\1616311234484.png)

当收到所有输入分区的barrier时，任务就将其状态保存到状态后端的检查点中，然后将barrier继续向下游转发

![1616311309579](C:\Users\MrR\AppData\Roaming\Typora\typora-user-images\1616311309579.png)

向下游转发检查点barrier后，任务继续正常的数据处理

![1616311344797](C:\Users\MrR\AppData\Roaming\Typora\typora-user-images\1616311344797.png)

Sink任务向JobManager确认状态保存到checkpoint完毕

当所有任务都确认已成功将状态保存到检查点时，检查点就真正完成了

#### 保存点（Savepoints）

savepoint其实就是手动的checkpoint 。

![1623394260702](https://tprzfbucket.oss-cn-beijing.aliyuncs.com/hadoop/202106/11/145146-795710.png)

- Flink还提供了可以自定义的镜像保存功能，就是保存点（savepoints）
- 原则上，创建保存点使用的算法与检查点完全相同，因此保存点可以认为就是具有一些额外元数据的检查点
- Flink不会自动创建保存点，因此用户（或者外部调度程序）必须明确地触发创建操作
- 保存点是一个强大的功能。除了故障恢复外，保存点可以用于：有计划的手动备份，更新应用程序，版本迁移，暂停和重启应用，等等

#### savepoint和checkpoint

![1623394409089](https://tprzfbucket.oss-cn-beijing.aliyuncs.com/hadoop/202111/05/145106-291216.png)

