
<!-- TOC -->

    - [计算机网络(二)](#计算机网络二)
- [TCP 三次握手和四次挥手(面试常客)](#tcp-三次握手和四次挥手面试常客)
  - [2.1 TCP 三次握手图解](#21-tcp-三次握手图解)
  - [2.2 为什么要三次握手](#22-为什么要三次握手)
  - [2.3 第 2 次握手传回了 ACK，为什么还要传回 SYN？](#23-第-2-次握手传回了-ack为什么还要传回-syn)
  - [2.5 为什么要四次挥手](#25-为什么要四次挥手)
- [三 TCP,UDP 协议的区别](#三-tcpudp-协议的区别)
- [四 TCP 协议如何保证可靠传输](#四-tcp-协议如何保证可靠传输)
  - [4.1 ARQ 协议](#41-arq-协议)
    - [停止等待 ARQ 协议](#停止等待-arq-协议)
    - [连续 ARQ 协议](#连续-arq-协议)
  - [4.2 滑动窗口和流量控制](#42-滑动窗口和流量控制)
  - [4.3 拥塞控制](#43-拥塞控制)
- [五 在浏览器中输入 url 地址 ->> 显示主页的过程(面试常客)](#五-在浏览器中输入-url-地址---显示主页的过程面试常客)
- [六 状态码](#六-状态码)
- [七 各种协议与 HTTP 协议之间的关系](#七-各种协议与-http-协议之间的关系)
- [八 HTTP 长连接,短连接](#八-http-长连接短连接)
- [九 HTTP 是不保存状态的协议,如何保存用户状态?](#九-http-是不保存状态的协议如何保存用户状态)
- [十 Cookie 的作用是什么?和 Session 有什么区别？](#十-cookie-的作用是什么和-session-有什么区别)
- [十一 HTTP 1.0 和 HTTP 1.1 的主要区别是什么?](#十一-http-10-和-http-11-的主要区别是什么)
- [十二 URI 和 URL 的区别是什么?](#十二-uri-和-url-的区别是什么)
- [十三 HTTP 和 HTTPS 的区别？](#十三-http-和-https-的区别)
- [HTTPS工作流程](#https工作流程)
- [HTTP 与 HTTPS 的区别](#http-与-https-的区别)
- [建议](#建议)
- [参考](#参考)
- [易错点](#易错点)
  - [差错检验](#差错检验)
  - [每一层的功能总结](#每一层的功能总结)
- [面试题总结](#面试题总结)

<!-- /TOC -->

### 计算机网络(二)

上面我们对计算机网络的五层体系结构有了初步的了解，下面附送一张七层体系结构图总结一下（图片来源于网络）。

![七层体系结构图](https://tprzfbucket.oss-cn-beijing.aliyuncs.com/hadoop/202109/06/194608-675257.png)

## TCP 三次握手和四次挥手(面试常客)

为了准确无误地把数据送达目标处，TCP 协议采用了三次握手策略。

### 2.1 TCP 三次握手图解

**简单示意图：**
![1631253394739](https://tprzfbucket.oss-cn-beijing.aliyuncs.com/hadoop/202109/10/135635-548441.png)

- 客户端–发送带有 SYN 标志的数据包–一次握手–服务端
- 服务端–发送带有 SYN/ACK 标志的数据包–二次握手–客户端
- 客户端–发送带有带有 ACK 标志的数据包–三次握手–服务端

**详细示意图（图片来源不详）**

![1631253415673](https://tprzfbucket.oss-cn-beijing.aliyuncs.com/hadoop/202109/10/135656-527432.png)

### 2.2 为什么要三次握手

**三次握手的目的是建立可靠的通信信道，说到通讯，简单来说就是数据的发送与接收，而三次握手最主要的目的就是双方确认自己与对方的发送与接收是正常的。**

第一次握手：Client 什么都不能确认；Server 确认了对方发送正常，自己接收正常

第二次握手：Client 确认了：自己发送、接收正常，对方发送、接收正常；Server 确认了：对方发送正常，自己接收正常

第三次握手：Client 确认了：自己发送、接收正常，对方发送、接收正常；Server 确认了：自己发送、接收正常，对方发送、接收正常

所以三次握手就能确认双发收发功能都正常，缺一不可。

### 2.3 第 2 次握手传回了 ACK，为什么还要传回 SYN？

接收端传回发送端所发送的 ACK 是为了告诉客户端，我接收到的信息确实就是你所发送的信号了，这表明从客户端到服务端的通信是正常的。而回传 SYN 则是为了建立并确认从服务端到客户端的通信。”

> SYN 同步序列编号(Synchronize Sequence Numbers) 是 TCP/IP 建立连接时使用的握手信号。在客户机和服务器之间建立正常的 TCP 网络连接时，客户机首先发出一个 SYN 消息，服务器使用 SYN-ACK 应答表示接收到了这个消息，最后客户机再以 ACK(Acknowledgement）消息响应。这样在客户机和服务器之间才能建立起可靠的 TCP 连接，数据才可以在客户机和服务器之间传递。

### 2.5 为什么要四次挥手

![1631253702002](https://tprzfbucket.oss-cn-beijing.aliyuncs.com/hadoop/202109/10/140143-674775.png)

断开一个 TCP 连接则需要“四次挥手”：

- 客户端-发送一个 FIN，用来关闭客户端到服务器的数据传送
- 服务器-收到这个 FIN，它发回一 个 ACK，确认序号为收到的序号加 1 。和 SYN 一样，一个 FIN 将占用一个序号
- 服务器-关闭与客户端的连接，发送一个 FIN 给客户端
- 客户端-发回 ACK 报文确认，并将确认序号设置为收到序号加 1

任何一方都可以在数据传送结束后发出连接释放的通知，待对方确认后进入半关闭状态。当另一方也没有数据再发送的时候，则发出连接释放通知，对方确认后就完全关闭了 TCP 连接。

举个例子：A 和 B 打电话，通话即将结束后，A 说“我没啥要说的了”，B 回答“我知道了”，但是 B 可能还会有要说的话，A 不能要求 B 跟着自己的节奏结束通话，于是 B 可能又巴拉巴拉说了一通，最后 B 说“我说完了”，A 回答“知道了”，这样通话才算结束。

上面讲的比较概括，推荐一篇讲的比较细致的文章：[https://blog.csdn.net/qzcsu/article/details/72861891](https://blog.csdn.net/qzcsu/article/details/72861891)

## 三 TCP,UDP 协议的区别

![TCP、UDP协议的区别](https://my-blog-to-use.oss-cn-beijing.aliyuncs.com/2019-11/tcp-vs-udp.jpg)

UDP 在传送数据之前不需要先建立连接，远地主机在收到 UDP 报文后，不需要给出任何确认。虽然 UDP 不提供可靠交付，但在某些情况下 UDP 却是一种最有效的工作方式（一般用于即时通信），比如： QQ 语音、 QQ 视频 、直播等等

TCP 提供面向连接的服务。在传送数据之前必须先建立连接，数据传送结束后要释放连接。 TCP 不提供广播或多播服务。由于 TCP 要提供可靠的，面向连接的传输服务（TCP 的可靠体现在 TCP 在传递数据之前，会有三次握手来建立连接，而且在数据传递时，有确认、窗口、重传、拥塞控制机制，在数据传完后，还会断开连接用来节约系统资源），这一难以避免增加了许多开销，如确认，流量控制，计时器以及连接管理等。这不仅使协议数据单元的首部增大很多，还要占用许多处理机资源。TCP 一般用于文件传输、发送和接收邮件、远程登录等场景。

## 四 TCP 协议如何保证可靠传输

1. 应用数据被分割成 TCP 认为最适合发送的数据块。
2. TCP 给发送的每一个包进行编号，接收方对数据包进行排序，把有序数据传送给应用层。
3. **校验和：** TCP 将保持它首部和数据的检验和。这是一个端到端的检验和，目的是检测数据在传输过程中的任何变化。如果收到段的检验和有差错，TCP 将丢弃这个报文段和不确认收到此报文段。
4. TCP 的接收端会丢弃重复的数据。
5. **流量控制：** TCP 连接的每一方都有固定大小的缓冲空间，TCP 的接收端只允许发送端发送接收端缓冲区能接纳的数据。当接收方来不及处理发送方的数据，能提示发送方降低发送的速率，防止包丢失。TCP 使用的流量控制协议是可变大小的滑动窗口协议。 （TCP 利用滑动窗口实现流量控制）
6. **拥塞控制：** 当网络拥塞时，减少数据的发送。
7. **ARQ 协议：** 也是为了实现可靠传输的，它的基本原理就是每发完一个分组就停止发送，等待对方确认。在收到确认后再发下一个分组。
8. **超时重传：** 当 TCP 发出一个段后，它启动一个定时器，等待目的端确认收到这个报文段。如果不能及时收到一个确认，将重发这个报文段。

### 4.1 ARQ 协议

**自动重传请求**（Automatic Repeat-reQuest，ARQ）是 OSI 模型中数据链路层和传输层的错误纠正协议之一。它通过使用确认和超时这两个机制，在不可靠服务的基础上实现可靠的信息传输。如果发送方在发送后一段时间之内没有收到确认帧，它通常会重新发送。**ARQ 包括停止等待 ARQ 协议和连续 ARQ 协议。**

#### 停止等待 ARQ 协议

停止等待协议是为了实现可靠传输的，它的基本原理就是每发完一个分组就停止发送，等待对方确认（回复 ACK）。如果过了一段时间（超时时间后），还是没有收到 ACK 确认，说明没有发送成功，需要重新发送，直到收到确认后再发下一个分组。

在停止等待协议中，若接收方收到重复分组，就丢弃该分组，但同时还要发送确认。

**优缺点：**

- **优点：** 简单
- **缺点：** 信道利用率低，等待时间长

**1) 无差错情况:**

发送方发送分组,接收方在规定时间内收到,并且回复确认.发送方再次发送。

**2) 出现差错情况（超时重传）:**

停止等待协议中超时重传是指只要超过一段时间仍然没有收到确认，就重传前面发送过的分组（认为刚才发送过的分组丢失了）。因此每发送完一个分组需要设置一个超时计时器，其重传时间应比数据在分组传输的平均往返时间更长一些。这种自动重传方式常称为 **自动重传请求 ARQ** 。另外在停止等待协议中若收到重复分组，就丢弃该分组，但同时还要发送确认。**连续 ARQ 协议** 可提高信道利用率。发送维持一个发送窗口，凡位于发送窗口内的分组可连续发送出去，而不需要等待对方确认。接收方一般采用累积确认，对按序到达的最后一个分组发送确认，表明到这个分组位置的所有分组都已经正确收到了。

**3) 确认丢失和确认迟到**

- **确认丢失** ：确认消息在传输过程丢失。当 A 发送 M1 消息，B 收到后，B 向 A 发送了一个 M1 确认消息，但却在传输过程中丢失。而 A 并不知道，在超时计时过后，A 重传 M1 消息，B 再次收到该消息后采取以下两点措施：1. 丢弃这个重复的 M1 消息，不向上层交付。 2. 向 A 发送确认消息。（不会认为已经发送过了，就不再发送。A 能重传，就证明 B 的确认消息丢失）。
- **确认迟到** ：确认消息在传输过程中迟到。A 发送 M1 消息，B 收到并发送确认。在超时时间内没有收到确认消息，A 重传 M1 消息，B 仍然收到并继续发送确认消息（B 收到了 2 份 M1）。此时 A 收到了 B 第二次发送的确认消息。接着发送其他数据。过了一会，A 收到了 B 第一次发送的对 M1 的确认消息（A 也收到了 2 份确认消息）。处理如下：1. A 收到重复的确认后，直接丢弃。2. B 收到重复的 M1 后，也直接丢弃重复的 M1。

#### 连续 ARQ 协议

连续 ARQ 协议可提高信道利用率。发送方维持一个发送窗口，凡位于发送窗口内的分组可以连续发送出去，而不需要等待对方确认。接收方一般采用累计确认，对按序到达的最后一个分组发送确认，表明到这个分组为止的所有分组都已经正确收到了。

**优缺点：**

- **优点：** 信道利用率高，容易实现，即使确认丢失，也不必重传。
- **缺点：** 不能向发送方反映出接收方已经正确收到的所有分组的信息。 比如：发送方发送了 5 条 消息，中间第三条丢失（3 号），这时接收方只能对前两个发送确认。发送方无法知道后三个分组的下落，而只好把后三个全部重传一次。这也叫 Go-Back-N（回退 N），表示需要退回来重传已经发送过的 N 个消息。

### 4.2 滑动窗口和流量控制

**TCP 利用滑动窗口实现流量控制。流量控制是为了控制发送方发送速率，保证接收方来得及接收。** 接收方发送的确认报文中的窗口字段可以用来控制发送方窗口大小，从而影响发送方的发送速率。将窗口字段设置为 0，则发送方不能发送数据。

### 4.3 拥塞控制

在某段时间，若对网络中某一资源的需求超过了该资源所能提供的可用部分，网络的性能就要变坏。这种情况就叫拥塞。拥塞控制就是为了防止过多的数据注入到网络中，这样就可以使网络中的路由器或链路不致过载。拥塞控制所要做的都有一个前提，就是网络能够承受现有的网络负荷。**拥塞控制是一个全局性的过程**，涉及到所有的主机，所有的路由器，以及与降低网络传输性能有关的所有因素。相反，流量控制往往是点对点通信量的控制，是个端到端的问题。流量控制所要做到的就是抑制发送端发送数据的速率，以便使接收端来得及接收。

为了进行拥塞控制，TCP 发送方要维持一个 **拥塞窗口(cwnd)** 的状态变量。拥塞控制窗口的大小取决于网络的拥塞程度，并且动态变化。**发送方让自己的发送窗口取为拥塞窗口和接收方的接受窗口中较小的一个。**

TCP 的拥塞控制采用了四种算法，即 **慢开始** 、 **拥塞避免** 、**快重传** 和 **快恢复**。在网络层也可以使路由器采用适当的分组丢弃策略（如主动队列管理 AQM），以减少网络拥塞的发生。

- **慢开始：** 慢开始算法的思路是当主机开始发送数据时，如果立即把大量数据字节注入到网络，那么可能会引起网络阻塞，因为现在还不知道网络的符合情况。经验表明，较好的方法是先探测一下，即由小到大逐渐增大发送窗口，也就是由小到大逐渐增大拥塞窗口数值。cwnd 初始值为 1，每经过一个传播轮次，cwnd 加倍。
- **拥塞避免：** 拥塞避免算法的思路是让拥塞窗口 cwnd 缓慢增大，即每经过一个往返时间 RTT 就把发送放的 cwnd 加 1.
- **快重传与快恢复：**
  在 TCP/IP 中，快速重传和恢复（fast retransmit and recovery，FRR）是一种拥塞控制算法，它能快速恢复丢失的数据包。没有 FRR，如果数据包丢失了，TCP 将会使用定时器来要求传输暂停。在暂停的这段时间内，没有新的或复制的数据包被发送。有了 FRR，如果接收机接收到一个不按顺序的数据段，它会立即给发送机发送一个重复确认。如果发送机接收到三个重复确认，它会假定确认件指出的数据段丢失了，并立即重传这些丢失的数据段。有了 FRR，就不会因为重传时要求的暂停被耽误。 　当有单独的数据包丢失时，快速重传和恢复（FRR）能最有效地工作。当有多个数据信息包在某一段很短的时间内丢失时，它则不能很有效地工作。

## 五 在浏览器中输入 url 地址 ->> 显示主页的过程(面试常客)

百度好像最喜欢问这个问题。

> 打开一个网页，整个过程会使用哪些协议？

图解（图片来源：《图解 HTTP》）：

![1631260834637](https://tprzfbucket.oss-cn-beijing.aliyuncs.com/hadoop/202111/25/120557-348326.png)

> 上图有一个错误，请注意，是 OSPF 不是 OPSF。 OSPF（Open Shortest Path First，ospf）开放最短路径优先协议,是由 Internet 工程任务组开发的路由选择协议

总体来说分为以下几个过程:

1. DNS 解析
2. TCP 连接
3. 发送 HTTP 请求
4. 服务器处理请求并返回 HTTP 报文
5. 浏览器解析渲染页面
6. 连接结束

具体可以参考下面这篇文章：

- [https://segmentfault.com/a/1190000006879700](https://segmentfault.com/a/1190000006879700)

## 六 状态码

![1631260911564](https://tprzfbucket.oss-cn-beijing.aliyuncs.com/hadoop/202109/10/160216-346253.png)

## 七 各种协议与 HTTP 协议之间的关系

一般面试官会通过这样的问题来考察你对计算机网络知识体系的理解。

图片来源：《图解 HTTP》

![1631261069923](https://tprzfbucket.oss-cn-beijing.aliyuncs.com/hadoop/202109/10/160431-338595.png)

![1631261120963](https://tprzfbucket.oss-cn-beijing.aliyuncs.com/hadoop/202109/10/160522-920814.png)

## 八 HTTP 长连接,短连接

在 HTTP/1.0 中默认使用短连接。也就是说，客户端和服务器每进行一次 HTTP 操作，就建立一次连接，任务结束就中断连接。当客户端浏览器访问的某个 HTML 或其他类型的 Web 页中包含有其他的 Web 资源（如 JavaScript 文件、图像文件、CSS 文件等），每遇到这样一个 Web 资源，浏览器就会重新建立一个 HTTP 会话。

而从 HTTP/1.1 起，默认使用长连接，用以保持连接特性。使用长连接的 HTTP 协议，会在响应头加入这行代码：

```
Connection:keep-alive
```

在使用长连接的情况下，当一个网页打开完成后，客户端和服务器之间用于传输 HTTP 数据的 TCP 连接不会关闭，客户端再次访问这个服务器时，会继续使用这一条已经建立的连接。Keep-Alive 不会永久保持连接，它有一个保持时间，可以在不同的服务器软件（如 Apache）中设定这个时间。实现长连接需要客户端和服务端都支持长连接。

**HTTP 协议的长连接和短连接，实质上是 TCP 协议的长连接和短连接。**

—— [《HTTP 长连接、短连接究竟是什么？》](https://www.cnblogs.com/gotodsp/p/6366163.html)

## 九 HTTP 是不保存状态的协议,如何保存用户状态?

HTTP 是一种不保存状态，即无状态（stateless）协议。也就是说 HTTP 协议自身不对请求和响应之间的通信状态进行保存。那么我们保存用户状态呢？Session 机制的存在就是为了解决这个问题，Session 的主要作用就是通过服务端记录用户的状态。典型的场景是购物车，当你要添加商品到购物车的时候，系统不知道是哪个用户操作的，因为 HTTP 协议是无状态的。服务端给特定的用户创建特定的 Session 之后就可以标识这个用户并且跟踪这个用户了（一般情况下，服务器会在一定时间内保存这个 Session，过了时间限制，就会销毁这个 Session）。

在服务端保存 Session 的方法很多，最常用的就是内存和数据库(比如是使用内存数据库 redis 保存)。既然 Session 存放在服务器端，那么我们如何实现 Session 跟踪呢？大部分情况下，我们都是通过在 Cookie 中附加一个 Session ID 来方式来跟踪。

**Cookie 被禁用怎么办?**

最常用的就是利用 URL 重写把 Session ID 直接附加在 URL 路径的后面。

![HTTP是无状态协议](https://my-blog-to-use.oss-cn-beijing.aliyuncs.com/2019-6/HTTP是无状态的.png)

## 十 Cookie 的作用是什么?和 Session 有什么区别？

Cookie 和 Session 都是用来跟踪浏览器**用户身份的会话方式**，但是两者的应用场景不太一样。

**Cookie 一般用来保存用户信息** 比如 ① 我们在 Cookie 中保存已经登录过得用户信息，下次访问网站的时候页面可以自动帮你登录的一些基本信息给填了；② 一般的网站都会有保持登录也就是说下次你再访问网站的时候就不需要重新登录了，这是因为用户登录的时候我们可以存放了一个 Token 在 Cookie 中，下次登录的时候只需要根据 Token 值来查找用户即可(为了安全考虑，重新登录一般要将 Token 重写)；③ 登录一次网站后访问网站其他页面不需要重新登录。**Session 的主要作用就是通过服务端记录用户的状态。** 典型的场景是购物车，当你要添加商品到购物车的时候，系统不知道是哪个用户操作的，因为 HTTP 协议是无状态的。服务端给特定的用户创建特定的 Session 之后就可以标识这个用户并且跟踪这个用户了。

**Cookie 数据保存在客户端(浏览器端)，Session 数据保存在服务器端。**

Cookie 存储在客户端中，而 Session 存储在服务器上，相对来说 Session 安全性更高。如果要在 Cookie 中存储一些敏感信息，不要直接写入 Cookie 中，最好能将 Cookie 信息加密然后使用到的时候再去服务器端解密。

## 十一 HTTP 1.0 和 HTTP 1.1 的主要区别是什么?

> 这部分回答引用这篇文章 <https://mp.weixin.qq.com/s/GICbiyJpINrHZ41u_4zT-A?> 的一些内容。

HTTP1.0 最早在网页中使用是在 1996 年，那个时候只是使用一些较为简单的网页上和网络请求上，而 HTTP1.1 则在 1999 年才开始广泛应用于现在的各大浏览器网络请求中，同时 HTTP1.1 也是当前使用最为广泛的 HTTP 协议。 主要区别主要体现在：

1. **长连接** : **在 HTTP/1.0 中，默认使用的是短连接**，也就是说每次请求都要重新建立一次连接。HTTP 是基于 TCP/IP 协议的,每一次建立或者断开连接都需要三次握手四次挥手的开销，如果每次请求都要这样的话，开销会比较大。因此最好能维持一个长连接，可以用个长连接来发多个请求。**HTTP 1.1 起，默认使用长连接** ,默认开启 Connection： keep-alive。 **HTTP/1.1 的持续连接有非流水线方式和流水线方式** 。流水线方式是客户在收到 HTTP 的响应报文之前就能接着发送新的请求报文。与之相对应的非流水线方式是客户在收到前一个响应后才能发送下一个请求。
2. **错误状态响应码** :在 HTTP1.1 中新增了 24 个错误状态响应码，如 409（Conflict）表示请求的资源与资源的当前状态发生冲突；410（Gone）表示服务器上的某个资源被永久性的删除。
3. **缓存处理** :在 HTTP1.0 中主要使用 header 里的 If-Modified-Since,Expires 来做为缓存判断的标准，HTTP1.1 则引入了更多的缓存控制策略例如 Entity tag，If-Unmodified-Since, If-Match, If-None-Match 等更多可供选择的缓存头来控制缓存策略。
4. **带宽优化及网络连接的使用** :HTTP1.0 中，存在一些浪费带宽的现象，例如客户端只是需要某个对象的一部分，而服务器却将整个对象送过来了，并且不支持断点续传功能，HTTP1.1 则在请求头引入了 range 头域，它允许只请求资源的某个部分，即返回码是 206（Partial Content），这样就方便了开发者自由的选择以便于充分利用带宽和连接。

## 十二 URI 和 URL 的区别是什么?

- URI(Uniform Resource Identifier) 是统一资源标志符，**可以唯一标识一个资源**。
- URL(Uniform Resource Locator) 是统一资源定位符，**可以提供该资源的路径**。它是一种具体的 URI，即 URL 可以用来标识一个资源，而且还指明了如何 locate 这个资源。

URI 的作用像身份证号一样，URL 的作用更像家庭住址一样。URL 是一种具体的 URI，它不仅唯一标识资源，而且还提供了定位该资源的信息。

## 十三 HTTP 和 HTTPS 的区别？

1. **端口** ：HTTP 的 URL 由“http://”起始且默认使用端口80，而HTTPS的URL由“https://”起始且默认使用端口443。
2. **安全性和资源消耗：** HTTP 协议运行在 TCP 之上，所有传输的内容都是明文，客户端和服务器端都无法验证对方的身份。HTTPS 是运行在 SSL/TLS 之上的 HTTP 协议，SSL/TLS 运行在 TCP 之上。所有传输的内容都经过加密，加密采用对称加密，但对称加密的密钥用服务器方的证书进行了非对称加密。所以说，HTTP 安全性没有 HTTPS 高，但是 HTTPS 比 HTTP 耗费更多服务器资源。
   - 对称加密：密钥只有一个，加密解密为同一个密码，且加解密速度快，典型的对称加密算法有 DES、AES 等；
   - 非对称加密：密钥成对出现（且根据公钥无法推知私钥，根据私钥也无法推知公钥），加密解密使用不同密钥（公钥加密需要私钥解密，私钥加密需要公钥解密），相对对称加密速度较慢，典型的非对称加密算法有 RSA、DSA 等。

## HTTPS工作流程

![1637835618779](https://tprzfbucket.oss-cn-beijing.aliyuncs.com/hadoop/202201/28/111707-746089.png)

1.Client发起一个HTTPS（比如`https://juejin.im/user/5a9a9cdcf265da238b7d771c`）的请求，根据RFC2818的规定，Client知道需要连接Server的443（默认）端口。

2.Server把事先配置好的公钥证书（public key certificate）返回给客户端。

3.Client验证公钥证书：比如是否在有效期内，证书的用途是不是匹配Client请求的站点，是不是在CRL吊销列表里面，它的上一级证书是否有效，这是一个递归的过程，直到验证到根证书（操作系统内置的Root证书或者Client内置的Root证书）。如果验证通过则继续，不通过则显示警告信息。

4.Client使用伪随机数生成器生成加密所使用的对称密钥，然后用证书的公钥加密这个对称密钥，发给Server。

5.Server使用自己的私钥（private key）解密这个消息，得到对称密钥。至此，Client和Server双方都持有了相同的对称密钥。

6.Server使用对称密钥加密“明文内容A”，发送给Client。

7.Client使用对称密钥解密响应的密文，得到“明文内容A”。

8.Client再次发起HTTPS的请求，使用对称密钥加密请求的“明文内容B”，然后Server使用对称密钥解密密文，得到“明文内容B”。

## HTTP 与 HTTPS 的区别

- HTTP 是明文传输协议，HTTPS 协议是由 SSL+HTTP 协议构建的可进行加密传输、身份认证的网络协议，比 HTTP 协议安全。

![1637835656539](https://tprzfbucket.oss-cn-beijing.aliyuncs.com/hadoop/202111/25/182058-880344.png)

关于安全性，用最简单的比喻形容两者的关系就是卡车运货，HTTP下的运货车是敞篷的，货物都是暴露的。而https则是封闭集装箱车，安全性自然提升不少。

- HTTPS比HTTP更加安全，对搜索引擎更友好，利于SEO,谷歌、百度优先索引HTTPS网页;
- HTTPS需要用到SSL证书，而HTTP不用;
- HTTPS标准端口443，HTTP标准端口80;
- HTTPS基于传输层，HTTP基于应用层;
- HTTPS在浏览器显示绿色安全锁，HTTP没有显示;

## 建议

非常推荐大家看一下 《图解 HTTP》 这本书，这本书页数不多，但是内容很是充实，不管是用来系统的掌握网络方面的一些知识还是说纯粹为了应付面试都有很大帮助。下面的一些文章只是参考。大二学习这门课程的时候，我们使用的教材是 《计算机网络第七版》（谢希仁编著），不推荐大家看这本教材，书非常厚而且知识偏理论，不确定大家能不能心平气和的读完。

## 参考

- [https://blog.csdn.net/qq_16209077/article/details/52718250](https://blog.csdn.net/qq_16209077/article/details/52718250)
- [https://blog.csdn.net/zixiaomuwu/article/details/60965466](https://blog.csdn.net/zixiaomuwu/article/details/60965466)
- [https://blog.csdn.net/turn\_\_back/article/details/73743641](https://blog.csdn.net/turn__back/article/details/73743641)
- <https://mp.weixin.qq.com/s/GICbiyJpINrHZ41u_4zT-A?>

## 易错点

### 差错检验

1. 数据链路层的差错控制

   - 由于信道噪声等各种原因，帧在传输过程中可能会出现错误。用以使发送方确定接收方是否正确收到了由它发送的数据的方法称为差错控制。通常，这些错误可分为位错和帧错误。
   - 位错指帧中某些位出现了差错。通常采用循环冗余校验(C RC) 方式发现位错，通过自动重传请求(Automatic Repeat reQuest, ARQ ) 方式来重传出错的帧.具体做法是:让发送方将要发送的数据帧附加一定的CRC 冗余检错码一并发迭，接收方则根据检错码对数据帧进行错误检测，若发现错误， 则丢弃， 发送方超时重传该数据帧.这种差错控制方法就称为ARQ 法， ARQ 法仅返回很少的控制信息，便可有效地确认所发数据帧是否被正确接收.
   - 帧错误是指帧的丢失，重复或失序等错误。在数据链路层引入定时器和编号机制，可以保证每一帧最终都能有且仅有一次正确地交付给目的结点。

2. 传输层的UDP校验

   1. 在计算校验和时，要在UDP 数据报之前增加12个字节的伪首部，伪收部并不是UDP 真正的首部。只是在计算校验和时，临时添加在UDP 数据报的前面，得到一个临时的UDP 数据报。校验和就是按照这个临时的U DP 数据报计算的. 伪首部既不向下传送也不向上递交，而仅仅是为了计算校验和.这样的校验和，既检查了UDP 数据报， 又对IP 数据报的源IP 地址和目的IP地址进行了检验。
   2. UD P 校验和的计算方法和TCP 数据报首部校验和的计算方法相似，都使用二进制反码运算求和再取反。**但不同的是:lP 数据报的校验和只检验lP 数据报的首郁， 但UDP 的校验和是把首部和数据部分一起都检验。**
   3. 在发送方，首先是把全零放入校验和字段并且添加伪首部。然后，把UDP 数据报看成是由许多1 6 位的字串连接起来。若UDP 数据报的数据部分不是偶数个字节，则要在数据部分末尾增加一个全零字节(但此字节不发送〉。接下来就按二进制反码计算出这些16 位字的和.将此和的二进制反码写入校验和字段。在接收方，把收到的UDP 数据报加上伪首部(如果不为偶数个字第节，还需要补上全零字节〉后，按二进制反码计算出这些16 位字的和. 当无差错时其结果应全为1， 否则就表明有差错出现，接收方就应该丢弃这个UDP 数据报。

3. 传输层的TCP校验

   检验和字段检验的范围包括首部和数据这两部分。在计算检验和时，和UDP 一样，要在TCP 报文段的前面加 12 字节的伪首部〈只需将UDP 伪首部的第4 个字段，即协议字段的1 7 改成6 ，其他的和UDP 一样)。

- **在这里注意吧，不管是UDP还是TCP,检验的部分都包括首部和数据部分。**

### 每一层的功能总结

1. 物理层：该层包括物理连接媒介，是计算机联网的基础，进行转发比特流。（任何一种调制解调器）
2. 数据链路层：在不可靠的物理线路上进行可靠的数据传递。（ALOHA,PPP,CSMA,CSMA/CD,CDMA）
3. 网络层：实际上是完成主机到主机之间的通信服务，（IP,ARP,RARP,ICMP,OSPF,BGP）
4. 传输层：提供的是端到端的数据通信服务，（TCP,UDP）
5. 会话层：负责在网络中的两个节点之间建立和维持通信。
6. 表示层：为不同终端的上层用户提供数据和信息的格式化标示方法（数据加密解密,XML,HTML）
7. 应用层：负责对软件提供接口以使程序能够使用网络的服务，（注意：不是运行着的那些程序，而是对应用程序提供接口或服务）FTP,HTTP,DNS。

## 面试题总结

1. 拥塞控制

   1. 慢开始
      - 发送方维持一个叫做拥塞窗口`cwnd（congestion window）`的状态变量。拥塞窗口的大小取决于网络的拥塞程度，并且动态地在变化。发送方让自己的发送窗口等于拥塞窗口，另外考虑到接受方的接收能力，发送窗口可能小于拥塞窗口。
      - 慢开始算法的思路就是，不要一开始就发送大量的数据，先探测一下网络的拥塞程度，也就是说由小到大逐渐增加拥塞窗口的大小。
      - 实时拥塞窗口大小是以字节为单位的。当然收到单个确认但此确认多个数据报的时候就加相应的数值。所以一次传输轮次之后拥塞窗口就加倍。这就是乘法增长，和后面的拥塞避免算法的加法增长比较。
      - 为了防止`cwnd `增长过大引起网络拥塞，还需设置一个慢开始门限`ssthresh `状态变量。`ssthresh` 的用法如下：
        - 当`cwnd<ssthresh `时，使用慢开始算法。
        - 当`cwnd>ssthresh` 时，改用拥塞避免算法。
        - 当`cwnd=ssthresh `时，慢开始与拥塞避免算法任意。
   2. 拥塞避免
      - 拥塞避免算法让拥塞窗缓慢增长，即每经过一个往返时间`RTT` 就把发送方的拥塞窗口`cwnd` 加1，而不是加倍。这样拥塞窗口按线性规律缓慢增长。
      - 无论是在慢开始阶段还是在拥塞避免阶段，只要发送方判断网络出现拥塞（其根据就是没有收到确认，虽然没有收到确认可能是其他原因的分组丢失，但是因为无法判定，所以都当做拥塞来处理），就把慢开始门限`ssthresh` 设置为出现拥塞时的发送窗口大小的一半。然后把拥塞窗口设置为1，执行慢开始算法。
   3. 快重传
      - 快重传要求接收方在收到一个失序的报文段后就立即发出重复确认（为的是使发送方及早知道有报文段没有到达对方）而不要等到自己发送数据时捎带确认。快重传算法规定，发送方只要一连收到三个重复确认就应当立即重传对方尚未收到的报文段，而不必继续等待设置的重传计时器时间到期。
   4. 快恢复
      - 当发送方连续收到三个重复确认时，就执行“乘法减小”算法，把`ssthresh `门限减半。但是接下去并不执行慢开始算法。
      - 考虑到如果网络出现拥塞的话就不会收到好几个重复的确认，所以发送方现在认为网络可能没有出现拥塞。所以此时不执行慢开始算法，而是将`cwnd` 设置为`ssthresh `的大小，然后执行拥塞避免算法。

2. 为什么建立连接协议是三次握手，而关闭连接却是四次握手呢？

   - 这是因为服务端的`LISTEN `状态下的`SOCKET `当收到`SYN` 报文的建连请求后，它可以把`ACK`和`SYN`（`ACK `起应答作用，而`SYN` 起同步作用）放在一个报文里来发送。但关闭连接时，当收到对方的`FIN` 报文通知时，它仅仅表示对方没有数据发送给你了；但未必你所有的数据都全部发送给对方了，所以你可以未必会马上会关闭`SOCKET`,也即你可能还需要发送一些数据给对方之后，再发送`FIN `报文给对方来表示你同意现在可以关闭连接了，所以它这里的`ACK `报文和`FIN `报文多数情况下都是分开发送的。

3. 第三次握手失败

   - 当客户端收到服务端的`SYN+ACK `应答后，其状态变为`ESTABLISHED`，并会发送`ACK `包给服务端，准备发送数据了。如果此时`ACK `在网络中丢失，过了超时计时器后，那么`Server`端会重新发送`SYN+ACK` 包，重传次数根据`/proc/sys/net/ipv4/tcp_synack_retries `来指定，默认是5 次。如果重传指定次数到了后，仍然未收到`ACK `应答，那么一段时间后，`Server` 自动关闭这个连接。但是`Client` 认为这个连接已经建立，如果`Client` 端向`Server` 写数据，`Server`端将以`RST`包响应，方能感知到`Server` 的错误。
   - 在`S erver`返回一个确认的`SYN-ACK` 包的时候，S 可能由于各种原因不会接到C 回应的ACK 包。这个也就是所谓的半开放连接，S 需要耗费一定的数量的系统内存来等待这个未决的连接，虽然这个数量是受限，但是恶意者可以通过创建很多的半开放式连接来发动SYN 洪水攻击。攻击者可以通过IP 欺骗发送SYN 包给受害者系统，这个看起来是合法的，但事实上所谓的C 根本不会进行ACK 回应服务端S 的SYN-ACK 报文，这意味着受害者将永远不会接到ACK报文。而此时，半开放连接将最终耗用受害者所有的系统资源（即使等待ACK 包有超时限制），受害者将不能再接收任何其他的请求。

4. 如何应对TCP SYN Flood

   - 第一个参数tcp_synack_retries = 0 是关键，表示回应第二个握手包（SYN+ACK 包）给客户端IP 后，如果收不到第三次握手包（ACK 包）后，不进行重试，加快回收“半连接”，不要耗光资源。
   - 修改这个参数为0 的副作用：网络状况很差时，如果对方没收到第二个握手包，可能连接服务器失败，但对于一般网站，用户刷新一次页面即可。这些可以在高峰期或网络状况不好时tcpdump 抓包验证下。
   - 之所以可以把tcp_synack_retries 改为0，因为客户端还有tcp_syn_retries 参数，默认是5，即使服务器端没有重发SYN+ACK 包，客户端也会重发SYN 握手包。
   - tcp_max_syn_backlog
     从字面上就可以推断出是什么意思。在内核里有个队列用来存放还没有确认ACK 的客户端
     请求，当等待的请求数大于tcp_max_syn_backlog 时，后面的会被丢弃。
   - 所以，适当增大这个值，可以在压力大的时候提高握手的成功率。手册里推荐大于1024。使用服务器的内存资源，换取更大的等待队列长度，让攻击数据包不至于占满所有连接而导致正常用户无法完成握手。
     当半连接的请求数量超过了tcp_max_syn_backlog 时，内核就会启用SYN cookie 机制，不再把半连接请求放到队列里，而是用SYN cookie 来检验。
   - 启用3
     启用之前，服务器在接到SYN 数据包后，立即分配存储空间，并随机化一个数字作为SYN号发送SYN+ACK 数据包。然后保存连接的状态信息等待客户端确认。启用SYN Cookie 之后，服务器不再分配存储空间，而且通过基于时间种子的随机数算法设置一个SYN 号，替代完全随机的SYN 号。发送完SYN+ACK 确认报文之后，清空资源不保存任何状态信息。直到服务器接到客户端的最终ACK 包，通过Cookie 检验算法鉴定是否与发出去的SYN+ACK报文序列号匹配，匹配则通过完成握手，失败则丢弃。当然，前文的高级攻击中有SYN 混合ACK 的攻击方法，则是对此种防御方法的反击，其中优劣由双方的硬件配置决定

5. 客户端收到一个窗口为0 的包怎么处理

   - TCP 长连接与短连接

     TCP 短连接的情况，client 向server 发起连接请求，server 接到请求，然后双方建立连接。client 向server 发送消息，server 回应client，然后一次读写就完成了，这时候双方任何一个都可以发起close 操作，不过一般都是client 先发起close 操作。为什么呢，一般的server不会回复完client 后立即关闭连接的，当然不排除有特殊的情况。从上面的描述看，短连接
     一般只会在client/server 间传递一次读写操作client 向server 发起连接，server 接受client 连接，双方建立连接。Client 与server 完成一次读写之后，它们之间的连接并不会主动关闭，后续的读写操作会继续使用这个连接。

6. 为什么要有time_wait

   1. 可靠的终止TCP 连接。

      可靠的终止TCP 连接，若处于time_wait 的client 发送给server 确认报文段丢失的话，server将在此又一次发送FIN 报文段，那么client 必须处于一个可接收的状态就是time_wait 而不是close 状态。

   2. 保证让迟来的TCP 报文段有足够的时间被识别并丢弃。

      保证迟来的TCP 报文段有足够的时间被识别并丢弃，linux 中一个TCPport 不能打开两次或两次以上。当client 处于time_wait 状态时我们将无法使用此port 建立新连接，假设不存在time_wait 状态，新连接可能会收到旧连接的数据。

   3. 可靠地实现TCP 全双工连接的终止

      TCP 协议在关闭连接的四次握手过程中，最终的ACK 是由主动关闭连接的一端（后面统称A端）发出的，如果这个ACK 丢失，对方（后面统称B 端）将重发出最终的FIN，因此A 端必须维护状态信息（TIME_WAIT）允许它重发最终的ACK。如果A 端不维持TIME_WAIT 状态，而是处于CLOSED 状态，那么A 端将响应RST 报文，B 端收到后将此报文解释成一个错误（在java 中会抛出connection reset 的SocketException)。
      因而，要实现TCP 全双工连接的正常终止，必须处理终止过程中四个报文任何一个报文的
      丢失情况，主动关闭连接的A 端必须维持TIME_WAIT 状态。

   4. 允许老的重复报文在网络中消逝

      TCP 报文可能由于路由器异常而“迷途”，在迷途期间，TCP 发送端可能因确认超时而重发这个报文，迷途的报文在路由器修复后也会被送到最终目的地，这个迟到的迷途报文到达时可能会引起问题。在关闭“前一个连接”之后，马上又重新建立起一个相同的IP 和端口之间的“新连接”，“前一个连接”的迷途重复分组在“前一个连接”终止后到达，而被“新连接”收到了。为了避免这个情况，TCP 协议不允许处于TIME_WAIT 状态的连接启动一个新的可用连接，因为TIME_WAIT 状态持续2MSL，就可以保证当成功建立一个新TCP 连接的时候，来自旧连接重复分组已经在网络中消逝。

7. 客户端和服务器都可能会进入time_wait

   - 高并发TCP 服务器中进行主动关闭的一方最好是客户端：因为对于高并发服务器来说文件描述符资源是很重要的资源，如果对于每一个连接都要经历TIME_WAIT 这个2MSL 的时长，势必造成资源不能立马复用的浪费。虽然对于客户端来说TIME_WAIT 状态会占用端口和句柄资源，但是客户端一般很少有并发资源限制，所以客户端执行主动关闭是比较合适的。

   - TIME_WAIT 状态到底会占用什么？

     被占用的是一个五元组：（协议，本地IP，本地端口，远程IP，远程端口）。对于Web 服务器，协议是TCP，本地IP 通常也只有一个，本地端口默认的80 或者443。只剩下远程IP 和远程端口可以变了。如果远程IP 是相同的话，就只有远程端口可以变了。这个只有几万个，所以当同一客户端向服务器建立了大量连接之后，会耗尽可用的五元组导致问题。

8. 客户端断开连接造成time_wait 影响

   - 客户端：
     客户端与服务端进行短连接的TCP 通信，如果在同一台机器上进行压力测试模拟上万的客户请求，并且循环与服务端进行短连接通信，那么这台机器将产生4000 个左右的TIME_WAITsocket，后续的短连接就会产生address already in use : connect 的异常。如果是客户端发起了连接，传输完数据然后主动关闭了连接，这时这个连接在客户端就会处于TIMEWAIT 状态，同时占用了一个本地端口。如果客户端使用短连接请求服务端的资源或者服务，客户端上将有大量的连接处于TIMEWAIT 状态，占用大量的本地端口。最坏的情况就是，本地端口都被用光了，这时将无法再建立新的连接。

9. 客户端断开连接造成time_wait 解决

   - 客户端：

   1. 使用长连接，如果是http，可以使用keepalive
   2. 增加本地端口可用的范围，比如Linux 中调整内核参数：net.ipv4.ip_local_port_range
   3. tcp_tw_reuse 参数用来设置是否可以在新的连接中重用TIME_WAIT 状态的套接字。注
      意，重用的是TIME_WAIT 套接字占用的端口号，而不是TIME_WAIT 套接字的内存等。这个
      参数对客户端有意义，在主动发起连接的时候会在调用的inet_hash_connect()中会检查是否
      可以重用TIME_WAIT 状态的套接字。如果你在服务器段设置这个参数的话，则没有什么作
      用，因为服务器端ESTABLISHED 状态的套接字和监听套接字的本地IP、端口号是相同的，
      没有重用的概念。但并不是说服务器端就没有TIME_WAIT 状态套接字。

   - 服务器：
     不像客户端有端口限制， 处理大量TIME_WAIT Linux 已经优化很好了， 每个处于
     TIME_WAIT 状态下连接内存消耗很少，
     而且也能通过tcp_max_tw_buckets = 262144 配置最大上限，现代机器一般也不缺这点内存。
     tcp_timestamps 参数用来设置是否启用时间戳选项，tcp_tw_recycle 参数用来启用快速回收
     TIME_WAIT 套接字。tcp_timestamps 参数会影响到tcp_tw_recycle 参数的效果。如果没有时
     间戳选项的话，tcp_tw_recycle 参数无效

10. 客户端收到ConnectionReset

    - server 端主动发起了断连
      导致“Connection reset”的原因是服务器端因为某种原因关闭了Connection，而客户端依然
      在读写数据， 此时服务器会返回复位标志“RST” ， 然后此时客户端就会提示
      “java.net.SocketException: Connection reset”。
      服务器返回了“RST”时，如果此时客户端正在从Socket 套接字的输出流中读数据则会提示
      Connection reset”；
      服务器返回了“RST”时，如果此时客户端正在往Socket 套接字的输入流中写数据则会提示
      “Connection reset by peer”。

11. UDP 可靠传输

    - 实现一个最基础的可靠udp 通讯协议，我们只需要提供一个重传机制即可。在这我实现了
      一个简单的可靠udp 协议，这个协议为每一个发送出去的udp 数据包分配一个包id，每次
      接收方收到一个数据包时，都要回应发送方一个ack 对应这个包id。协议通过这种确认机制
      来保证接收方能收到发送方发出的udp 数据包，在发出的时候，发送方应该设置一个计时
      器，超时的话会重传数据包。

    - 具体来说它没做这些事情：

      它没有保证包的有序性。发送方连续发送几个udp 数据包，接收方可以以任何顺序收到这
      几个数据包。如果想要做到有序性，必须由应用层来完成。
      它没做流量控制。发送方连续大量发送数据包会导致网络性能变差，丢包次数增大。
      它没对数据包大小做控制。为了避免IP 层对数据包进行分片，应用层应该要保证每个数据
      包的大小不超过MTU。如果这个数据包会经过广域网（一般情况下）这个值应该不超过576。
      考虑到IP 头的20 字节，udp 头的8 个字节，以及这个协议头的字节。最好每次发送的数据大小在512m以内。

12. socket 选项TCP_NODELAY在网络拥塞控制领域，有一个非常有名的算法叫做Nagle 算法（Nagle algorithm），这是
    使用它的发明人John Nagle 的名字来命名的，John Nagle 在1984 年首次用这个算法来尝
    试解决福特汽车公司的网络拥塞问题（RFC 896）。
    该问题的具体描述是：如果我们的应用程序一次产生1 个字节的数据，而这个1 个字节数
    据又以网络数据包的形式发送到远端服务器，那么就很容易导致网络由于太多的数据包而过
    载。比如，当用户使用Telnet 连接到远程服务器时，每一次击键操作就会产生1 个字节数
    据，进而发送出去一个数据包，所以，在典型情况下，传送一个只拥有1 个字节有效数据
    的数据包，却要发费40 个字节长包头（即ip 头20 字节+tcp 头20 字节）的额外开销，这
    种有效载荷（payload）利用率极其低下的情况被统称之为愚蠢窗口症候群（Silly Window
    Syndrome）。可以看到，这种情况对于轻负载的网络来说，可能还可以接受，但是对于重
    负载的网络而言，就极有可能承载不了而轻易的发生拥塞瘫痪。

    针对上面提到的这个状况，Nagle 算法的改进在于：如果发送端欲多次发送包含少量字符的
    数据包（一般情况下，后面统一称长度小于MSS 的数据包为小包，与此相对，称长度等于
    MSS 的数据包为大包，为了某些对比说明，还有中包，即长度比小包长，但又不足一个MSS
    的包），则发送端会先将第一个小包发送出去，而将后面到达的少量字符数据都缓存起来而
    不立即发送，直到收到接收端对前一个数据包报文段的ACK 确认、或当前字符属于紧急数
    据，或者积攒到了一定数量的数据（比如缓存的字符数据已经达到数据包报文段的最大长度）
    等多种情况才将其组成一个较大的数据包发送出去。
    设置NODELAY 会立即发送，不会延迟。

13. 如何解决tcp 粘包问题

    面向流的协议 
    1）数据包固定大小，每收到该大小字节视为一个包
    2）分隔符，比如\r\n
    3）自定义数据包，header 中指定body 的长度（最常使用）