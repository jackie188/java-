## 网络

### 什么是网络协议，为什么要对网络协议分层 

网络协议是计算机在通信过程中要遵循的一些约定好的规则。

网络分层的原因：

- 易于实现和维护，因为各层之间是独立的，层与层之间不会收到影响。
- 有利于标准化的制定 

### 计算机网络的各层协议及作用  

> 计算机网络体系可以大致分为一下三种，七层模型、五层模型和TCP/IP四层模型，一般面试能流畅回答出五层模型就可以了，表示层和会话层被问到的不多。 

![1631774040923](https://tprzfbucket.oss-cn-beijing.aliyuncs.com/hadoop/202109/16/143403-116784.png)

**应用层**

- 应用层的任务是通过应用进程之间的交互来完成特定的网络作用，常见的应用层协议有域名系统DNS，HTTP协议等。

**表示层**

- 表示层的主要作用是数据的表示、安全、压缩。可确保一个系统的应用层所发送的信息可以被另一个系统的应用层读取。

**会话层**

- 会话层的主要作用是建立通信链接，保持会话过程通信链接的畅通，同步两个节点之间的对话，决定通信是否被中断以及通信中断时决定从何处重新发送。

**传输层**

- 传输层的主要作用是负责向两台主机进程之间的通信提供数据传输服务。传输层的协议主要有传输控制协议TCP和用户数据协议UDP。

**网络层**

- 网络层的主要作用是选择合适的网间路由和交换结点，确保数据及时送达。常见的协议有IP协议。

**数据链路层**

- 数据链路层的作用是在物理层提供比特流服务的基础上，建立相邻结点之间的数据链路，通过差错控制提供数据帧（Frame）在信道上无差错的传输，并进行各电路上的动作系列。 常见的协议有SDLC、HDLC、PPP等。

**物理层**

- 物理层的主要作用是实现相邻计算机结点之间比特流的透明传输，并尽量屏蔽掉具体传输介质和物理设备的差异。 

### URI和URL的区别 

- URI(Uniform Resource Identifier)：中文全称为统一资源标志符，主要作用是唯一标识一个资源。
- URL(Uniform Resource Location)：中文全称为统一资源定位符，主要作用是提供资源的路径。

> 有个经典的比喻是URI像是身份证，可以唯一标识一个人，而URL更像一个住址，可以通过URL找到这个人 

### DNS的工作流程 

DNS的定义：DNS的全称是domain name system，即域名系统。DNS是因特网上作为域名和IP地址相互映射的一个分布式数据库，能够使用户更方便的去访问互联网而不用去记住能够被机器直接读取的IP地址。比如大家访问百度，更多地肯定是访问`www.baidu.com`，而不是访问112.80.248.74，因为这几乎无规则的IP地址实在太难记了。DNS要做的就是将`www.baidu.com`解析成112.80.248.74。 

**DNS是集群式的工作方式还是 单点式的，为什么？ **

是集群式的，是一个分布式的数据库系统，很容易想到的一个方案就是只用一个DNS服务器，包含了所有域名和IP地址的映射。尽管这种设计方式看起

来很简单，但是缺点显而易见，如果这个唯一的DNS服务器出了故障，那么就全完了，因特网就几乎崩了。为了避免这种情况出现，DNS系统采用的是

分布式的层次数据数据库模式，还有缓存的机制也能解决这种问题。 

**DNS的工作流程 **

主机向本地域名服务器的查询一般是采用递归查询，而本地域名服务器向根域名的查询一般是采用迭代查询。

递归查询：主机向本地域名发送查询请求报文，而本地域名服务器不知道该域名对应的IP地址时，本地域名会继续向根域名发送查询请求报文，不是通知主机自己向根域名发送查询请求报文。

迭代查询：本地域名服务器向根域名发出查询请求报文后，根域名不会继续向顶级域名服务器发送查询请求报文，而是通知本地域名服务器向顶级域名。

发送查询请求报文。

> 简单来说，递归查询就是，小明问了小红一个问题，小红不知道，但小红是个热心肠，小红就去问小王了，小王把答案告诉小红后，小红又去把答案告诉了小明。迭代查询就是，小明问了小红一个问题，小红也不知道，然后小红让小明去问小王，小明又去问小王了，小王把答案告诉了小明。 

**dns查询流程：**

1. 在浏览器中输入`www.baidu.com`域名，操作系统会先检查自己本地的hosts文件是否有这个域名的映射关系，如果有，就先调用这个IP地址映射，完成域名解析。
2. 如果hosts文件中没有，则查询本地DNS解析器缓存，如果有，则完成地址解析。
3. 如果本地DNS解析器缓存中没有，则去查找本地DNS服务器，如果查到，完成解析。
4. 如果没有，则本地服务器会向根域名服务器发起查询请求。根域名服务器会告诉本地域名服务器去查询哪个顶级域名服务器。
5. 本地域名服务器向顶级域名服务器发起查询请求，顶级域名服务器会告诉本地域名服务器去查找哪个权限域名服务器。
6. 本地域名服务器向权限域名服务器发起查询请求，权限域名服务器告诉本地域名服务器`www.baidu.com`所对应的IP地址。
7. 本地域名服务器告诉主机`www.baidu.com`所对应的IP地址。 

### 了解ARP协议吗? 

ARP协议属于网络层的协议，主要作用是实现从IP地址转换为MAC地址。在每个主机或者路由器中都建有一个ARP缓存表，表中有IP地址及IP地址对应的MAC地址。先来看一下什么时IP地址和MAC地址。

- IP地址：IP地址是指互联网协议地址，IP地址是IP协议提供的一种统一的地址格式，它为互联网上的每一个网络和每一台主机分配一个逻辑地址，以此来屏蔽物理地址的差异。
- MAC地址：MAC地址又称物理地址，由网络设备制造商生产时写在硬件内部，不可更改，并且每个以太网设备的MAC地址都是唯一的。 

数据在传输过程中，会先从高层传到底层，然后在通信链路上传输。从下图可以看到TCP报文在网络层会被封装成IP数据报，在数据链路层被封装成MAC帧，然后在通信链路中传输。在网络层使用的是IP地址，在数据据链路层使用的是MAC地址。MAC帧在传送时的源地址和目的地址使用的都是MAC地址，在通信链路上的主机或路由器也都是根据MAC帧首部的MAC地址接收MAC帧。并且在数据链路层是看不到IP地址的，只有当数据传到网络层时去掉MAC帧的首部和尾部时才能在IP数据报的首部中找到源IP地址和目的地址。 

![1631774611402](https://tprzfbucket.oss-cn-beijing.aliyuncs.com/hadoop/202109/16/144334-802940.png)

网络层实现的是主机之间的通信，而链路层实现的是链路之间的通信，所以从下图可以看出，在数据传输过程中，IP数据报的源地址(IP1)和目的地址(IP2)是一直不变的，而MAC地址(硬件地址)却一直随着链路的改变而改变 。

![1631774655585](https://tprzfbucket.oss-cn-beijing.aliyuncs.com/hadoop/202109/16/144436-3994.png)

ARP的工作流程(面试时问ARP协议主要说这个就可以了)：

1. 在局域网内，主机A要向主机B发送IP数据报时，首先会在主机A的ARP缓存表中查找是否有IP地址及其对应的MAC地址，如果有，则将MAC地址写入到MAC帧的首部，并通过局域网将该MAC帧发送到MAC地址所在的主机B。
2. 如果主机A的ARP缓存表中没有主机B的IP地址及所对应的MAC地址，主机A会在局域网内广播发送一个ARP请求分组。局域网内的所有主机都会收到这个ARP请求分组。
3. 主机B在看到主机A发送的ARP请求分组中有自己的IP地址，会像主机A以单播的方式发送一个带有自己MAC地址的响应分组。
4. 主机A收到主机B的ARP响应分组后，会在ARP缓存表中写入主机B的IP地址及其IP地址对应的MAC地址。
5. 如果主机A和主机B不在同一个局域网内，即使知道主机B的MAC地址也是不能直接通信的，必须通过路由器转发到主机B的局域网才可以通过主机B的MAC地址找到主机B。并且主机A和主机B已经可以通信的情况下，主机A的ARP缓存表中寸的并不是主机B的IP地址及主机B的MAC地址，而是主机B的IP地址及该通信链路上的下一跳路由器的MAC地址。这就是上图中的源IP地址和目的IP地址一直不变，而MAC地址却随着链路的不同而改变。
6. 如果主机A和主机B不在同一个局域网，参考上图中的主机H1和主机H2，这时主机H1需要先广播找到路由器R1的MAC地址，再由R1广播找到路由器R2的MAC地址，最后R2广播找到主机H2的MAC地址，建立起通信链路 。

### 有了IP地址，为什么还要用MAC地址？ 

- 简单来说，标识网络中的一台计算机，比较常用的就是IP地址和MAC地址，但计算机的IP地址可由用户自行更改，管理起来相对困难，而MAC地址不可更改，所以一般会把IP地址和MAC地址组合起来使用。具体是如何组合使用的在上面的ARP协议中已经讲的很清楚了。
- 那只用MAC地址不用IP地址可不可以呢？其实也是不行的，因为在最早就是MAC地址先出现的，并且当时并不用IP地址，只用MAC地址，后来随着网络中的设备越来越多，整个路由过程越来越复杂，便出现了子网的概念。对于目的地址在其他子网的数据包，路由只需要将数据包送到那个子网即可，这个过程就是上面说的ARP协议。
- 那为什么要用IP地址呢？是因为IP地址是和地域相关的，对于同一个子网上的设备，IP地址的前缀都是一样的，这样路由器通过IP地 址的前缀就知道设备在在哪个子网上了，而只用MAC地址的话，路由器则需要记住每个MAC地址在哪个子网，这需要路由器有极大的存储空间，是无法实现的。
- IP地址可以比作为地址，MAC地址为收件人，在一次通信过程中，两者是缺一不可的。 
- 在通信过程中，ip地址封装在帧中，是无法看到ip地址的，所以需要根据mac地址进行转发。

### 说一下ping的过程 

ping是ICMP(网际控制报文协议)中的一个重要应用，ICMP是网络层的协议。ping的作用是测试两个主机的连通性。

ping的工作过程：

1. 向目的主机发送多个ICMP回送请求报文
2. 根据目的主机返回的回送报文的时间和成功响应的次数估算出数据包往返时间及丢包率。 

### 路由器和交换机的区别？ 

![1631774959914](https://tprzfbucket.oss-cn-beijing.aliyuncs.com/hadoop/202109/16/144921-788749.png)

### TCP与UDP有什么区别 

![1631774988603](https://tprzfbucket.oss-cn-beijing.aliyuncs.com/hadoop/202109/16/144950-319839.png)

TCP首部(图片来源于网络)：

- 前20个字节是固定的，后面有4n个字节是根据需而增加的选项，所以TCP首部最小长度为20字节。 

![1631775029831](https://tprzfbucket.oss-cn-beijing.aliyuncs.com/hadoop/202109/16/145031-494243.png)

UDP首部(图片来源于网络)：

- UDP的首部只有8个字节，源端口号、目的端口号、长度和校验和各两个字节。 

![1631775057533](https://tprzfbucket.oss-cn-beijing.aliyuncs.com/hadoop/202109/16/145059-437600.png)

### TCP协议如何保证可靠传输 

> 主要有校验和、序列号、超时重传、流量控制及拥塞避免等几种方法 

- 校验和：在发送算和接收端分别计算数据的校验和，如果两者不一致，则说明数据在传输过程中出现了差错，TCP将丢弃和不确认此报文段。
- 序列号：TCP会对每一个发送的字节进行编号，接收方接到数据后，会对发送方发送确认应答(ACK报文)，并且这个ACK报文中带有相应的确认编号，告诉发送方，下一次发送的数据从编号多少开始发。如果发送方发送相同的数据，接收端也可以通过序列号判断出，直接将数据丢弃。

![1631775310795](https://tprzfbucket.oss-cn-beijing.aliyuncs.com/hadoop/202109/16/145512-63465.png)

- 超时重传：在上面说了序列号的作用，但如果发送方在发送数据后一段时间内（可以设置重传计时器规定这段时间）没有收到确认序号ACK，那么发送方就会重新发送数据。
  - 这里发送方没有收到ACK可以分两种情况，如果是发送方发送的数据包丢失了，接收方收到发送方重新发送的数据包后会马上给发送方发送ACK；如果是接收方之前接收到了发送方发送的数据包，而返回给发送方的ACK丢失了，这种情况，发送方重传后，接收方会直接丢弃发送重传的数据包，然后再次发送ACK响应报文。
  - 如果数据被重发之后还是没有收到接收方的确认应答，则进行再次发送。此时，等待确认应答的时间将会以2倍、4倍的指数函数延长，直到最后关闭连接。 
- 流量控制：如果发送端发送的数据太快，接收端来不及接收就会出现丢包问题。为了解决这个问题，TCP协议利用了滑动窗口进行了流量控制。在TCP首部有一个16位字段大小的窗口，窗口的大小就是接收端接收数据缓冲区的剩余大小。接收端会在收到数据包后发送ACK报文时，将自己的窗
  口大小填入ACK中，发送方会根据ACK报文中的窗口大小进而控制发送速度。如果窗口大小为零，发送方会停止发送数据。 
- 拥塞控制：如果网络出现拥塞，则会产生丢包等问题，这时发送方会将丢失的数据包继续重传，网络拥塞会更加严重，所以在网络出现拥塞时应注意控制发送方的发送数据，降低整个网络的拥塞程度。拥塞控制主要有四部分组成：慢开始、拥塞避免、快重传、快恢复，如下图(图片来源于网络) 

![1631775419280](https://tprzfbucket.oss-cn-beijing.aliyuncs.com/hadoop/202109/16/145700-721708.png)

这里的发送方会维护一个拥塞窗口的状态变量，它和流量控制的滑动窗口是不一样的，滑动窗口是根据接收方数据缓冲区大小确定的，而拥塞窗口是根据网络的拥塞情况动态确定的，一般来说发送方真实的发送窗口为滑动窗口和拥塞窗口中的最小值。

1. 慢开始：为了避免一开始发送大量的数据而产生网络阻塞，会先初始化cwnd为1，当收到ACK后到下一个传输轮次，cwnd为2，以此类推成指数形式增长。
2. 拥塞避免：因为cwnd的数量在慢开始是指数增长的，为了防止cwnd数量过大而导致网络阻塞，会设置一个慢开始的门限值ssthresh，当cwnd>=ssthresh时，进入到拥塞避免阶段，cwnd每个传输轮次加1。但网络出现超时，会将门限值ssthresh变为出现超时cwnd数值的一半，cwnd重新设置为1，如上图，在第12轮出现超时后，cwnd变为1，ssthresh变为12。
3. 快重传：在网络中如果出现超时或者阻塞，则按慢开始和拥塞避免算法进行调整。但如果只是丢失某一个报文段，如下图(图片来源于网络)，则使用快重传算法。 

![1631775482017](https://tprzfbucket.oss-cn-beijing.aliyuncs.com/hadoop/202109/16/145803-732452.png)

从上图可知，接收方正确地接收到M1和M2，而M3丢失，由于没有接收到M3，在接收方收到M5、M6和M7时，并不会进行确认，也就是不会发送ACK。这时根据前面说的保证TCP可靠性传输中的序列号的作用，接收方这时不会接收M5，M6，M7，接收方可以什么都不会，因为发送方长时间未收到M3的确认报文，会对M3进行重传。除了这样，接收方也可以重复发送M2的确认报文，这样发送端长时间未收到M3的确认报文也会继续发送M3报文。但是根据快重传算法，要求在这种情况下，需要快速向发送端发送M2的确认报文，在发送方收到三个M2的确认报文后，无需等待重传计时器所设置的时间，可直接进行M3的重传，这就是快重传。(面试时说这一句就够了，前面是帮助理解)

4. 快恢复：从上上图圈4可以看到，当发送收到三个重复的ACK，会进行快重传和快恢复。快恢复是指将ssthresh设置为发生快重传时的cwnd数量的一半，而cwnd不是设置为1而是设置为为门限值ssthresh，并开始拥塞避免阶段。 

### TCP的三次握手及四次挥手 

在介绍三次握手和四次挥手之前，先介绍一下TCP头部的一些常用字段。

- 序号：seq，占32位，用来标识从发送端到接收端发送的字节流。
- 确认号：ack，占32位，只有ACK标志位为1时，确认序号字段才有效，ack=seq+1。

**标志位：**

- SYN：发起一个新连接。
- FIN：释放一个连接。
- ACK：确认序号有效。 

#### 三次握手

三次握手的本质就是确定发送端和接收端具备收发信息的能力，在能流畅描述三次握手的流程及其中的字段含义作用的同时还需要记住每次握手时接收端和发送端的状态。这个比较容易忽略。 

先看一张很经典的图（图片来源于网络），发送端有CLOSED、SYN-SENT、ESTABLISHED三种状态，接收端有CLOSED、LISTEN、SYN-RCVD、ESTABLISHED四种状态。 

![1631775740170](https://tprzfbucket.oss-cn-beijing.aliyuncs.com/hadoop/202109/16/150221-102001.png)

假设发送端为客户端，接收端为服务端。开始时客户端和服务端的状态都是CLOSE。

- 第一次握手：客户端向服务端发起建立连接请求，客户端会随机生成一个起始序列号x，客户端向服务端发送的字段中包含标志位SYN=1，序列号seq=100。第一次握手前客户端的状态为CLOSE，第一次握手后客户端的状态为SYN-SENT。此时服务端的状态为LISTEN
- 第二次握手：服务端在收到客户端发来的报文后，会随机生成一个服务端的起始序列号y，然后给客户端回复一段报文，其中包括标志位SYN=1，ACK=1，序列号seq=y，确认号ack=x+1。第二次握手前服务端的状态为LISTEN，第二次握手后服务端的状态为SYN-RCVD，此时客户端的状态为SYN-SENT。（其中SYN=1表示要和客户端建立一个连接，ACK=1表示确认序号有效）
- 第三次握手：客户端收到服务端发来的报文后，会再向服务端发送报文，其中包含标志位ACK=1，序列号seq=x+1，确认号ack=y+1。第三次握手前客户端的状态为SYN-SENT，第三次握手后客户端和服务端的状态都为ESTABLISHED。 

> 需要注意的一点是，第一次握手，客户端向服务端发起建立连接报文，会占一个序列号。但是第三次握手，同样是客户端向服务端发送报文，这次却不占序列号，所以建立连接后，客户端向服务端发送的第一个数据的序列号为x+1。 

#### 四次挥手

和三次握手一样，先看一张非常经典的图（图片来源于网络），客户端在四次挥手过程中有ESTABLISHED、FIN-WAIT-1、FIN-WAIT-2、TIME-WAIT、CLOSED等五个状态，服务端有ESTABLISHED、CLOSE-WAIT、LAST-ACK、CLOSED等四种状态。最好记住每次挥手时服务端和客户端的状态。 

![1631778996334](https://tprzfbucket.oss-cn-beijing.aliyuncs.com/hadoop/202109/16/155637-840984.png)

假设客户端首先发起的断开连接请求

- 第一次挥手：客户端向服务端发送的数据完成后，向服务端发起释放连接报文，报文包含标志位FIN=1，序列号seq=u。此时客户端只能接收数据，不能向服务端发送数据。
- 第二次挥手：服务端收到客户端的释放连接报文后，向客户端发送确认报文，包含标志位ACK=1，序列号seq=v，确认号ack=u+1。此时客户端到服务端的连接已经释放掉，客户端不能像服务端发送数据，服务端也不能向客户端发送数据。但服务端到客户端的单向连接还能正常传输数据。
- 第三次挥手：服务端发送完数据后向客户端发出连接释放报文，报文包含标志位FIN=1，标志位ACK=1，序列号seq=w，确认号ack=u+1。
- 第四次挥手：客户端收到服务端发送的释放连接请求，向服务端发送确认报文，包含标志位ACK=1，序列号seq=u+1，确认号ack=w+1。 

#### 为什么TCP连接的时候是3次？两次是否可以？ 

不可以，主要从以下两方面考虑（假设客户端是首先发起连接请求）：

1. 假设建立TCP连接仅需要两次握手，那么如果第二次握手时，服务端返回给客户端的确认报文丢失了，客户端这边认为服务端没有和他建立连接，而服务端却以为已经和客户端建立了连接，并且可能向服务端已经开始向客户端发送数据，但客户端并不会接收这些数据，浪费了资源。如果是三次握手，不会出现双方连接还未完全建立成功就开始发送数据的情况。
2. 如果服务端接收到了一个早已失效的来自客户端的连接请求报文，会向客户端发送确认报文同意建立TCP连接。但因为客户端并不需要向服务端发送数据，所以此次TCP连接没有意义并且浪费了资源。 

#### 为什么TCP连接的时候是3次，关闭的时候却是4次？ 

因为需要确保通信双方都能通知对方释放连接，假设客服端发送完数据向服务端发送释放连接请求，当客服端并不知道，服务端是否已经发送完数据，所以此次断开的是客服端到服务端的单向连接，服务端返回给客户端确认报文后，服务端还能继续单向给客户端发送数据。当服务端发送完数据后还需要向客户端发送释放连接请求，客户端返回确认报文，TCP连接彻底关闭。所以断开TCP连接需要客户端和服务端分别通知对方并分别收到确认报文，一共需要四次。 

#### TIME_WAIT和CLOSE_WAIT的区别在哪? 

默认客户端首先发起断开连接请求

- 从上图可以看出，CLOSE_WAIT是被动关闭形成的，当客户端发送FIN报文，服务端返回ACK报文后进入CLOSE_WAIT。
- TIME_WAIT是主动关闭形成的，当第四次挥手完成后，客户端进入TIME_WAIT状态。 

#### 为什么客户端发出第四次挥手的确认报文后要等2MSL的时间才能释放TCP连接？ 

MSL的意思是报文的最长寿命，可以从两方面考虑：

1. 客户端发送第四次挥手中的报文后，再经过2MSL，可使本次TCP连接中的所有报文全部消失，不会出现在下一个TCP连接中。
2. 考虑丢包问题，如果第四挥手发送的报文在传输过程中丢失了，那么服务端没收到确认ack报文就会重发第三次挥手的报文。如果客户端发送完第四次挥手的确认报文后直接关闭，而这次报文又恰好丢失，则会造成服务端无法正常关闭。 

#### 如果已经建立了连接，但是客户端突然出现故障了怎么办？ 

- 如果TCP连接已经建立，在通信过程中，客户端突然故障，那么服务端不会一直等下去，过一段时间就关闭连接了。具体原理是TCP有一个保活机制，主要用在服务器端，用于检测已建立TCP链接的客户端的状态，防止因客户端崩溃或者客户端网络不可达，而服务器端一直保持该TCP链接，占用服务器端的大量资源(因为Linux系统中可以创建的总TCP链接数是有限制的)。
- 保活机制原理：设置TCP保活机制的保活时间keepIdle，即在TCP链接超过该时间没有任何数据交互时，发送保活探测报文；设置保活探测报文的发送时间间隔keepInterval；设置保活探测报文的总发送次数keepCount。如果在keepCount次的保活探测报文均没有收到客户端的回应，则服务器端即关闭与客户端的TCP链接。 

[TCP通信过程中异常情况整理]([TCP通信过程中异常情况整理_YYC的专栏-CSDN博客_tcp异常](https://blog.csdn.net/yyc1023/article/details/80242815))

### HTTP 与 HTTPS 的区别 

![1631779267626](https://tprzfbucket.oss-cn-beijing.aliyuncs.com/hadoop/202109/16/160110-8605.png)

### 什么是对称加密与非对称加密 

**对称加密**
对称加密指加密和解密使用同一密钥，优点是运算速度快，缺点是如何安全将密钥传输给另一方。常见的对称加密算法有DES、AES等等。

**非对称加密**
非对称加密指的是加密和解密使用不同的密钥，一把公开的公钥，一把私有的私钥。公钥加密的信息只有私钥才能解密，私钥加密的信息只有公钥才能解密。优点解决了对称加密中存在的问题。缺点是运算速度较慢。常见的非对称加密算法有RSA、DSA、ECC等等。

非对称加密的工作流程：A生成一对非堆成密钥，将公钥向所有人公开，B拿到A的公钥后使用A的公钥对信息加密后发送给A，经过加密的信息只有A手中的私钥能解密。这样B可以通过这种方式将自己的公钥加密后发送给A，两方建立起通信，可以通过对方的公钥加密要发送的信息，接收方用自己的私钥解密信息。 

### HTTPS的加密过程 

上面已经介绍了对称加密和非对称加密的优缺点，HTTPS是将两者结合起来，使用的对称加密和非对称加密的混合加密算法。具体做法就是使用非对称加密来传输对称密钥来保证安全性，使用对称加密来保证通信的效率。

简化的工作流程：服务端生成一对非对称密钥，将公钥发给客户端。客户端生成对称密钥，用服务端发来的公钥进行加密，加密后发给服务端。服务端收到后用私钥进行解密，得到客户端发送的对称密钥。通信双方就可以通过对称密钥进行高效地通信了。

但是仔细想想这其中存在一个很大地问题，就是客户端最开始如何判断收到的这个公钥就是来自服务端而不是其他人冒充的？

这就需要证书上场了，服务端会向一个权威机构申请一个证书来证明自己的身份，到时候将证书（证书中包含了公钥）发给客户端就可以了，客户端收到证书后既证明了服务端的身份又拿到了公钥就可以进行下一步操作了。 

HTTPS的加密过程：

1. 客户端向服务端发起第一次握手请求，告诉服务端客户端所支持的SSL的指定版本、加密算法及密钥长度等信息。
2. 服务端将自己的公钥发给数字证书认证机构，数字证书认证机构利用自己的私钥对服务器的公钥进行数字签名，并给服务器颁发公钥证书。
3. 服务端将证书发给客服端。
4. 客服端利用数字认证机构的公钥，向数字证书认证机构验证公钥证书上的数字签名，确认服务器公开密钥的真实性。
5. 客服端使用服务端的公开密钥加密自己生成的对称密钥，发给服务端。
6. 服务端收到后利用私钥解密信息，获得客户端发来的对称密钥。
7. 通信双方可用对称密钥来加密解密信息。

上述流程存在的一个问题是客户端哪里来的数字认证机构的公钥，其实，在很多浏览器开发时，会内置常用数字证书认证机构的公钥。

**流程图如下：**

![1631779443660](https://tprzfbucket.oss-cn-beijing.aliyuncs.com/hadoop/202109/16/160404-448223.png)

### 常用HTTP状态码 

![1631779477806](https://tprzfbucket.oss-cn-beijing.aliyuncs.com/hadoop/202109/16/160440-642074.png)

常见的HTTP状态码:
**1XX**

- 100 Continue：表示正常，客户端可以继续发送请求
- 101 Switching Protocols：切换协议，服务器根据客户端的请求切换协议。

**2XX**

- 200 OK：请求成功
- 201 Created：已创建，表示成功请求并创建了新的资源
- 202 Accepted：已接受，已接受请求，但未处理完成。
- 204 No Content：无内容，服务器成功处理，但未返回内容。
- 205 Reset Content：重置内容，服务器处理成功，客户端应重置文档视图。 
- 206 Partial Content：表示客户端进行了范围请求，响应报文应包含Content-Range指定范围的实体内容 

**3XX**

- zy Moved Permanently：永久性重定向
- 302 Found：临时重定向
- 303 See Other：和zy功能类似，但要求客户端采用get方法获取资源
- 304 Not Modified：所请求的资源未修改，服务器返回此状态码时，不会返回任何资源。
- 305 Use Proxy：所请求的资源必须通过代理访问
- 307 Temporary Redirect： 临时重定向，与302类似，要求使用get请求重定向。

**4XX**

- 400 Bad Request：客户端请求的语法错误，服务器无法理解。
- 401 Unauthorized：表示发送的请求需要有认证信息。
- 403 Forbidden：服务器理解用户的请求，但是拒绝执行该请求
- 404 Not Found：服务器无法根据客户端的请求找到资源。
- 405 Method Not Allowed：客户端请求中的方法被禁止
- 406 Not Acceptable：服务器无法根据客户端请求的内容特性完成请求
- 408 Request Time-out：服务器等待客户端发送的请求时间过长，超时

**5XX**

- 500 Internal Server Error：服务器内部错误，无法完成请求
- 501 Not Implemented：服务器不支持请求的功能，无法完成请求 

### 常见的HTTP方法 

![1631779657740](https://tprzfbucket.oss-cn-beijing.aliyuncs.com/hadoop/202109/16/160739-863031.png)

为了方便记忆，可以将PUT、DELETE、POST、GET理解为客户端对服务端的增删改查。

- PUT：上传文件，向服务器添加数据，可以看作增
- DELETE：删除文件
- POST：传输数据，向服务器提交数据，对服务器数据进行更新。
- GET：获取资源，查询服务器资源 

### GET和POST区别 

作用

- GET用于获取资源，POST用于传输实体主体

参数位置

- GET的参数放在URL中，POST的参数存储在实体主体中，并且GET方法提交的请求的URL中的数据做多是2048字节，POST请求没有大小限制。

安全性

- GET方法因为参数放在URL中，安全性相对于POST较差一些

幂等性

- GET方法是具有幂等性的，而POST方法不具有幂等性。这里幂等性指客户端连续发出多次请求，收到的结果都是一样的. 

### HTTP 1.0、HTTP 1.1及HTTP 2.0的主要区别是什么 

**HTTP 1.0和HTTP 1.1的区别**

- 长连接
  - HTTP 1.1支持长连接和请求的流水线操作。长连接是指不在需要每次请求都重新建立一次连接，
  - HTTP 1.0默认使用短连接，每次请求都要重新建立一次TCP连接，资源消耗较大。请求的流水线操作是指客户端在收到HTTP的响应报文之前可以先发送新的请求报文，不支持请求的流水线操作需要等到收到HTTP的响应报文后才能继续发送新的请求报文。
- 缓存处理
  - 在HTTP 1.0中主要使用header中的If-Modified-Since,Expires作为缓存判断的标准，
  - HTTP 1.1引入了Entity tag，If-Unmodified-Since, If-Match等更多可供选择的缓存头来控制缓存策略。
- 错误状态码
  - 在HTTP 1.1新增了24个错误状态响应码
- HOST域
  - 在HTTP 1.0 中认为每台服务器都会绑定唯一的IP地址，所以，请求中的URL并没有传递主机名。但后来一台服务器上可能存在多个虚拟机，它们共享一个IP地址，所以HTTP 1.1中请求消息和响应消息都应该支持Host域。
- 带宽优化及网络连接的使用
- 在HTTP 1.0中会存在浪费带宽的现象，主要是因为不支持断点续传功能，客户端只是需要某个对象的一部分，服务端却将整个对象都传了过来。
- 在HTTP 1.1中请求头引入了range头域，它支持只请求资源的某个部分，返回的状态码为206。

**HTTP 2.0的新特性**

- 新的二进制格式：HTTP 1.x的解析是基于文本，HTTP 2.0的解析采用二进制，实现方便，健壮性更好。
- 多路复用：每一个request对应一个id，一个连接上可以有多个request，每个连接的request可以随机混在一起，这样接收方可以根据request的id将request归属到各自不同的服务端请求里。
- header压缩：在HTTP 1.x中，header携带大量信息，并且每次都需要重新发送，HTTP 2.0采用编码的方式减小了header的大小，同时通信双方各自缓存一份header fields表，避免了header的重复传输。
- 服务端推送：客户端在请求一个资源时，会把相关资源一起发给客户端，这样客户端就不需要再次发起请求。 

### Session、Cookie和Token的主要区别 

HTTP协议是无状态的，即服务器无法判断用户身份。Session和Cookie可以用来进行身份辨认。 

**Cookie**
Cookie是保存在客户端一个小数据块，其中包含了用户信息。当客户端向服务端发起请求，服务端会像客户端浏览器发送一个Cookie，客户端会把Cookie存起来，当下次客户端再次请求服务端时，会携带上这个Cookie，服务端会通过这个Cookie来确定身份。 

**Session**
Session是通过Cookie实现的，和Cookie不同的是，Session是存在服务端的。当客户端浏览器第一次访问服务器时，服务器会为浏览器创建一个sessionid，将sessionid放到Cookie中，存在客户端浏览器。比如浏览器访问的是购物网站，将一本《图解HTTP》放到了购物车，当浏览器再次访问服务器时，服务器会取出Cookie中的sessionid，并根据sessionid获取会话中的存储的信息，确认浏览器的身份是上次将《图解HTTP》放入到购物车那个用户。 

**Token**
客户端在浏览器第一次访问服务端时，服务端生成的一串字符串作为Token发给客户端浏览器，下次浏览器在访问服务端时携带token即可无需验证用户名和密码，省下来大量的资源开销。看到这里很多人感觉这不是和sessionid作用一样吗？其实是不一样的，但是本文章主要针对面试，知识点很多，篇幅有限，几句话也解释不清楚，大家可以看看这篇文章，我觉得说的非常清楚了。 

[cookie、session与token的真正区别]([cookie、session与token的真正区别_一个假的程序员-CSDN博客_session和token的区别](https://blog.csdn.net/whl190412/article/details/90024671))

**小结：**

![1631780077302](https://tprzfbucket.oss-cn-beijing.aliyuncs.com/hadoop/202109/16/161439-896816.png)

### 如果客户端禁止 cookie 能实现 session 还能用吗？ 

可以，Session的作用是在服务端来保持状态，通过sessionid来进行确认身份，但sessionid一般是通过Cookie来进行传递的。如果Cooike被禁用了，可以通过在URL中传递sessionid。 

### 在浏览器中输⼊url地址到显示主⻚的过程 

> 面试超高频的一道题，一般能说清楚流程就可以。

1. 对输入到浏览器的url进行DNS解析，将域名转换为IP地址。
2. 和目的服务器建立TCP连接
3. 向目的服务器发送HTTP请求
4. 服务器处理请求并返回HTTP报文
5. 浏览器解析并渲染页面 

### 计算机网络(二)

上面我们对计算机网络的五层体系结构有了初步的了解，下面附送一张七层体系结构图总结一下（图片来源于网络）。

![七层体系结构图](https://tprzfbucket.oss-cn-beijing.aliyuncs.com/hadoop/202109/06/194608-675257.png)

## TCP 三次握手和四次挥手(面试常客)

为了准确无误地把数据送达目标处，TCP 协议采用了三次握手策略。

### 2.1 TCP 三次握手漫画图解

如下图所示，下面的两个机器人通过 3 次握手确定了对方能正确接收和发送消息(图片来源：《图解 HTTP》)。
![1630929872977](https://tprzfbucket.oss-cn-beijing.aliyuncs.com/hadoop/202109/06/200433-327882.png)

**简单示意图：**
![1631253394739](https://tprzfbucket.oss-cn-beijing.aliyuncs.com/hadoop/202109/10/135635-548441.png)

- 客户端–发送带有 SYN 标志的数据包–一次握手–服务端
- 服务端–发送带有 SYN/ACK 标志的数据包–二次握手–客户端
- 客户端–发送带有带有 ACK 标志的数据包–三次握手–服务端

**详细示意图（图片来源不详）**

![1631253415673](https://tprzfbucket.oss-cn-beijing.aliyuncs.com/hadoop/202109/10/135656-527432.png)

### 2.2 为什么要三次握手

**三次握手的目的是建立可靠的通信信道，说到通讯，简单来说就是数据的发送与接收，而三次握手最主要的目的就是双方确认自己与对方的发送与接收是正常的。**

第一次握手：Client 什么都不能确认；Server 确认了对方发送正常，自己接收正常

第二次握手：Client 确认了：自己发送、接收正常，对方发送、接收正常；Server 确认了：对方发送正常，自己接收正常

第三次握手：Client 确认了：自己发送、接收正常，对方发送、接收正常；Server 确认了：自己发送、接收正常，对方发送、接收正常

所以三次握手就能确认双发收发功能都正常，缺一不可。

### 2.3 第 2 次握手传回了 ACK，为什么还要传回 SYN？

接收端传回发送端所发送的 ACK 是为了告诉客户端，我接收到的信息确实就是你所发送的信号了，这表明从客户端到服务端的通信是正常的。而回传 SYN 则是为了建立并确认从服务端到客户端的通信。”

> SYN 同步序列编号(Synchronize Sequence Numbers) 是 TCP/IP 建立连接时使用的握手信号。在客户机和服务器之间建立正常的 TCP 网络连接时，客户机首先发出一个 SYN 消息，服务器使用 SYN-ACK 应答表示接收到了这个消息，最后客户机再以 ACK(Acknowledgement）消息响应。这样在客户机和服务器之间才能建立起可靠的 TCP 连接，数据才可以在客户机和服务器之间传递。

### 2.5 为什么要四次挥手

![1631253702002](https://tprzfbucket.oss-cn-beijing.aliyuncs.com/hadoop/202109/10/140143-674775.png)

断开一个 TCP 连接则需要“四次挥手”：

- 客户端-发送一个 FIN，用来关闭客户端到服务器的数据传送
- 服务器-收到这个 FIN，它发回一 个 ACK，确认序号为收到的序号加 1 。和 SYN 一样，一个 FIN 将占用一个序号
- 服务器-关闭与客户端的连接，发送一个 FIN 给客户端
- 客户端-发回 ACK 报文确认，并将确认序号设置为收到序号加 1

任何一方都可以在数据传送结束后发出连接释放的通知，待对方确认后进入半关闭状态。当另一方也没有数据再发送的时候，则发出连接释放通知，对方确认后就完全关闭了 TCP 连接。

举个例子：A 和 B 打电话，通话即将结束后，A 说“我没啥要说的了”，B 回答“我知道了”，但是 B 可能还会有要说的话，A 不能要求 B 跟着自己的节奏结束通话，于是 B 可能又巴拉巴拉说了一通，最后 B 说“我说完了”，A 回答“知道了”，这样通话才算结束。

上面讲的比较概括，推荐一篇讲的比较细致的文章：[https://blog.csdn.net/qzcsu/article/details/72861891](https://blog.csdn.net/qzcsu/article/details/72861891)

## 三 TCP,UDP 协议的区别

![TCP、UDP协议的区别](https://my-blog-to-use.oss-cn-beijing.aliyuncs.com/2019-11/tcp-vs-udp.jpg)

UDP 在传送数据之前不需要先建立连接，远地主机在收到 UDP 报文后，不需要给出任何确认。虽然 UDP 不提供可靠交付，但在某些情况下 UDP 却是一种最有效的工作方式（一般用于即时通信），比如： QQ 语音、 QQ 视频 、直播等等

TCP 提供面向连接的服务。在传送数据之前必须先建立连接，数据传送结束后要释放连接。 TCP 不提供广播或多播服务。由于 TCP 要提供可靠的，面向连接的传输服务（TCP 的可靠体现在 TCP 在传递数据之前，会有三次握手来建立连接，而且在数据传递时，有确认、窗口、重传、拥塞控制机制，在数据传完后，还会断开连接用来节约系统资源），这一难以避免增加了许多开销，如确认，流量控制，计时器以及连接管理等。这不仅使协议数据单元的首部增大很多，还要占用许多处理机资源。TCP 一般用于文件传输、发送和接收邮件、远程登录等场景。

## 四 TCP 协议如何保证可靠传输

1. 应用数据被分割成 TCP 认为最适合发送的数据块。
2. TCP 给发送的每一个包进行编号，接收方对数据包进行排序，把有序数据传送给应用层。
3. **校验和：** TCP 将保持它首部和数据的检验和。这是一个端到端的检验和，目的是检测数据在传输过程中的任何变化。如果收到段的检验和有差错，TCP 将丢弃这个报文段和不确认收到此报文段。
4. TCP 的接收端会丢弃重复的数据。
5. **流量控制：** TCP 连接的每一方都有固定大小的缓冲空间，TCP 的接收端只允许发送端发送接收端缓冲区能接纳的数据。当接收方来不及处理发送方的数据，能提示发送方降低发送的速率，防止包丢失。TCP 使用的流量控制协议是可变大小的滑动窗口协议。 （TCP 利用滑动窗口实现流量控制）
6. **拥塞控制：** 当网络拥塞时，减少数据的发送。
7. **ARQ 协议：** 也是为了实现可靠传输的，它的基本原理就是每发完一个分组就停止发送，等待对方确认。在收到确认后再发下一个分组。
8. **超时重传：** 当 TCP 发出一个段后，它启动一个定时器，等待目的端确认收到这个报文段。如果不能及时收到一个确认，将重发这个报文段。

### 4.1 ARQ 协议

**自动重传请求**（Automatic Repeat-reQuest，ARQ）是 OSI 模型中数据链路层和传输层的错误纠正协议之一。它通过使用确认和超时这两个机制，在不可靠服务的基础上实现可靠的信息传输。如果发送方在发送后一段时间之内没有收到确认帧，它通常会重新发送。**ARQ 包括停止等待 ARQ 协议和连续 ARQ 协议。**

#### 停止等待 ARQ 协议

停止等待协议是为了实现可靠传输的，它的基本原理就是每发完一个分组就停止发送，等待对方确认（回复 ACK）。如果过了一段时间（超时时间后），还是没有收到 ACK 确认，说明没有发送成功，需要重新发送，直到收到确认后再发下一个分组。

在停止等待协议中，若接收方收到重复分组，就丢弃该分组，但同时还要发送确认。

**优缺点：**

- **优点：** 简单
- **缺点：** 信道利用率低，等待时间长

**1) 无差错情况:**

发送方发送分组,接收方在规定时间内收到,并且回复确认.发送方再次发送。

**2) 出现差错情况（超时重传）:**

停止等待协议中超时重传是指只要超过一段时间仍然没有收到确认，就重传前面发送过的分组（认为刚才发送过的分组丢失了）。因此每发送完一个分组需要设置一个超时计时器，其重传时间应比数据在分组传输的平均往返时间更长一些。这种自动重传方式常称为 **自动重传请求 ARQ** 。另外在停止等待协议中若收到重复分组，就丢弃该分组，但同时还要发送确认。**连续 ARQ 协议** 可提高信道利用率。发送维持一个发送窗口，凡位于发送窗口内的分组可连续发送出去，而不需要等待对方确认。接收方一般采用累积确认，对按序到达的最后一个分组发送确认，表明到这个分组位置的所有分组都已经正确收到了。

**3) 确认丢失和确认迟到**

- **确认丢失** ：确认消息在传输过程丢失。当 A 发送 M1 消息，B 收到后，B 向 A 发送了一个 M1 确认消息，但却在传输过程中丢失。而 A 并不知道，在超时计时过后，A 重传 M1 消息，B 再次收到该消息后采取以下两点措施：1. 丢弃这个重复的 M1 消息，不向上层交付。 2. 向 A 发送确认消息。（不会认为已经发送过了，就不再发送。A 能重传，就证明 B 的确认消息丢失）。
- **确认迟到** ：确认消息在传输过程中迟到。A 发送 M1 消息，B 收到并发送确认。在超时时间内没有收到确认消息，A 重传 M1 消息，B 仍然收到并继续发送确认消息（B 收到了 2 份 M1）。此时 A 收到了 B 第二次发送的确认消息。接着发送其他数据。过了一会，A 收到了 B 第一次发送的对 M1 的确认消息（A 也收到了 2 份确认消息）。处理如下：1. A 收到重复的确认后，直接丢弃。2. B 收到重复的 M1 后，也直接丢弃重复的 M1。

#### 连续 ARQ 协议

连续 ARQ 协议可提高信道利用率。发送方维持一个发送窗口，凡位于发送窗口内的分组可以连续发送出去，而不需要等待对方确认。接收方一般采用累计确认，对按序到达的最后一个分组发送确认，表明到这个分组为止的所有分组都已经正确收到了。

**优缺点：**

- **优点：** 信道利用率高，容易实现，即使确认丢失，也不必重传。
- **缺点：** 不能向发送方反映出接收方已经正确收到的所有分组的信息。 比如：发送方发送了 5 条 消息，中间第三条丢失（3 号），这时接收方只能对前两个发送确认。发送方无法知道后三个分组的下落，而只好把后三个全部重传一次。这也叫 Go-Back-N（回退 N），表示需要退回来重传已经发送过的 N 个消息。

### 4.2 滑动窗口和流量控制

**TCP 利用滑动窗口实现流量控制。流量控制是为了控制发送方发送速率，保证接收方来得及接收。** 接收方发送的确认报文中的窗口字段可以用来控制发送方窗口大小，从而影响发送方的发送速率。将窗口字段设置为 0，则发送方不能发送数据。

### 4.3 拥塞控制

在某段时间，若对网络中某一资源的需求超过了该资源所能提供的可用部分，网络的性能就要变坏。这种情况就叫拥塞。拥塞控制就是为了防止过多的数据注入到网络中，这样就可以使网络中的路由器或链路不致过载。拥塞控制所要做的都有一个前提，就是网络能够承受现有的网络负荷。**拥塞控制是一个全局性的过程**，涉及到所有的主机，所有的路由器，以及与降低网络传输性能有关的所有因素。相反，流量控制往往是点对点通信量的控制，是个端到端的问题。流量控制所要做到的就是抑制发送端发送数据的速率，以便使接收端来得及接收。

为了进行拥塞控制，TCP 发送方要维持一个 **拥塞窗口(cwnd)** 的状态变量。拥塞控制窗口的大小取决于网络的拥塞程度，并且动态变化。**发送方让自己的发送窗口取为拥塞窗口和接收方的接受窗口中较小的一个。**

TCP 的拥塞控制采用了四种算法，即 **慢开始** 、 **拥塞避免** 、**快重传** 和 **快恢复**。在网络层也可以使路由器采用适当的分组丢弃策略（如主动队列管理 AQM），以减少网络拥塞的发生。

- **慢开始：** 慢开始算法的思路是当主机开始发送数据时，如果立即把大量数据字节注入到网络，那么可能会引起网络阻塞，因为现在还不知道网络的符合情况。经验表明，较好的方法是先探测一下，即由小到大逐渐增大发送窗口，也就是由小到大逐渐增大拥塞窗口数值。cwnd 初始值为 1，每经过一个传播轮次，cwnd 加倍。
- **拥塞避免：** 拥塞避免算法的思路是让拥塞窗口 cwnd 缓慢增大，即每经过一个往返时间 RTT 就把发送放的 cwnd 加 1.
- **快重传与快恢复：**
  在 TCP/IP 中，快速重传和恢复（fast retransmit and recovery，FRR）是一种拥塞控制算法，它能快速恢复丢失的数据包。没有 FRR，如果数据包丢失了，TCP 将会使用定时器来要求传输暂停。在暂停的这段时间内，没有新的或复制的数据包被发送。有了 FRR，如果接收机接收到一个不按顺序的数据段，它会立即给发送机发送一个重复确认。如果发送机接收到三个重复确认，它会假定确认件指出的数据段丢失了，并立即重传这些丢失的数据段。有了 FRR，就不会因为重传时要求的暂停被耽误。 　当有单独的数据包丢失时，快速重传和恢复（FRR）能最有效地工作。当有多个数据信息包在某一段很短的时间内丢失时，它则不能很有效地工作。

## 五 在浏览器中输入 url 地址 ->> 显示主页的过程(面试常客)

百度好像最喜欢问这个问题。

> 打开一个网页，整个过程会使用哪些协议？

图解（图片来源：《图解 HTTP》）：

![1631260834637](https://tprzfbucket.oss-cn-beijing.aliyuncs.com/hadoop/202111/25/120557-348326.png)

> 上图有一个错误，请注意，是 OSPF 不是 OPSF。 OSPF（Open Shortest Path First，ospf）开放最短路径优先协议,是由 Internet 工程任务组开发的路由选择协议

总体来说分为以下几个过程:

1. DNS 解析
2. TCP 连接
3. 发送 HTTP 请求
4. 服务器处理请求并返回 HTTP 报文
5. 浏览器解析渲染页面
6. 连接结束

具体可以参考下面这篇文章：

- [https://segmentfault.com/a/1190000006879700](https://segmentfault.com/a/1190000006879700)

## 六 状态码

![1631260911564](https://tprzfbucket.oss-cn-beijing.aliyuncs.com/hadoop/202109/10/160216-346253.png)

## 七 各种协议与 HTTP 协议之间的关系

一般面试官会通过这样的问题来考察你对计算机网络知识体系的理解。

图片来源：《图解 HTTP》

![1631261069923](https://tprzfbucket.oss-cn-beijing.aliyuncs.com/hadoop/202109/10/160431-338595.png)

![1631261120963](https://tprzfbucket.oss-cn-beijing.aliyuncs.com/hadoop/202109/10/160522-920814.png)

## 八 HTTP 长连接,短连接

在 HTTP/1.0 中默认使用短连接。也就是说，客户端和服务器每进行一次 HTTP 操作，就建立一次连接，任务结束就中断连接。当客户端浏览器访问的某个 HTML 或其他类型的 Web 页中包含有其他的 Web 资源（如 JavaScript 文件、图像文件、CSS 文件等），每遇到这样一个 Web 资源，浏览器就会重新建立一个 HTTP 会话。

而从 HTTP/1.1 起，默认使用长连接，用以保持连接特性。使用长连接的 HTTP 协议，会在响应头加入这行代码：

```
Connection:keep-alive
```

在使用长连接的情况下，当一个网页打开完成后，客户端和服务器之间用于传输 HTTP 数据的 TCP 连接不会关闭，客户端再次访问这个服务器时，会继续使用这一条已经建立的连接。Keep-Alive 不会永久保持连接，它有一个保持时间，可以在不同的服务器软件（如 Apache）中设定这个时间。实现长连接需要客户端和服务端都支持长连接。

**HTTP 协议的长连接和短连接，实质上是 TCP 协议的长连接和短连接。**

—— [《HTTP 长连接、短连接究竟是什么？》](https://www.cnblogs.com/gotodsp/p/6366163.html)

## 九 HTTP 是不保存状态的协议,如何保存用户状态?

HTTP 是一种不保存状态，即无状态（stateless）协议。也就是说 HTTP 协议自身不对请求和响应之间的通信状态进行保存。那么我们保存用户状态呢？Session 机制的存在就是为了解决这个问题，Session 的主要作用就是通过服务端记录用户的状态。典型的场景是购物车，当你要添加商品到购物车的时候，系统不知道是哪个用户操作的，因为 HTTP 协议是无状态的。服务端给特定的用户创建特定的 Session 之后就可以标识这个用户并且跟踪这个用户了（一般情况下，服务器会在一定时间内保存这个 Session，过了时间限制，就会销毁这个 Session）。

在服务端保存 Session 的方法很多，最常用的就是内存和数据库(比如是使用内存数据库 redis 保存)。既然 Session 存放在服务器端，那么我们如何实现 Session 跟踪呢？大部分情况下，我们都是通过在 Cookie 中附加一个 Session ID 来方式来跟踪。

**Cookie 被禁用怎么办?**

最常用的就是利用 URL 重写把 Session ID 直接附加在 URL 路径的后面。

![HTTP是无状态协议](https://my-blog-to-use.oss-cn-beijing.aliyuncs.com/2019-6/HTTP是无状态的.png)

## 十 Cookie 的作用是什么?和 Session 有什么区别？

Cookie 和 Session 都是用来跟踪浏览器**用户身份的会话方式**，但是两者的应用场景不太一样。

**Cookie 一般用来保存用户信息** 比如 ① 我们在 Cookie 中保存已经登录过得用户信息，下次访问网站的时候页面可以自动帮你登录的一些基本信息给填了；② 一般的网站都会有保持登录也就是说下次你再访问网站的时候就不需要重新登录了，这是因为用户登录的时候我们可以存放了一个 Token 在 Cookie 中，下次登录的时候只需要根据 Token 值来查找用户即可(为了安全考虑，重新登录一般要将 Token 重写)；③ 登录一次网站后访问网站其他页面不需要重新登录。**Session 的主要作用就是通过服务端记录用户的状态。** 典型的场景是购物车，当你要添加商品到购物车的时候，系统不知道是哪个用户操作的，因为 HTTP 协议是无状态的。服务端给特定的用户创建特定的 Session 之后就可以标识这个用户并且跟踪这个用户了。

**Cookie 数据保存在客户端(浏览器端)，Session 数据保存在服务器端。**

Cookie 存储在客户端中，而 Session 存储在服务器上，相对来说 Session 安全性更高。如果要在 Cookie 中存储一些敏感信息，不要直接写入 Cookie 中，最好能将 Cookie 信息加密然后使用到的时候再去服务器端解密。

## 十一 HTTP 1.0 和 HTTP 1.1 的主要区别是什么?

> 这部分回答引用这篇文章 <https://mp.weixin.qq.com/s/GICbiyJpINrHZ41u_4zT-A?> 的一些内容。

HTTP1.0 最早在网页中使用是在 1996 年，那个时候只是使用一些较为简单的网页上和网络请求上，而 HTTP1.1 则在 1999 年才开始广泛应用于现在的各大浏览器网络请求中，同时 HTTP1.1 也是当前使用最为广泛的 HTTP 协议。 主要区别主要体现在：

1. **长连接** : **在 HTTP/1.0 中，默认使用的是短连接**，也就是说每次请求都要重新建立一次连接。HTTP 是基于 TCP/IP 协议的,每一次建立或者断开连接都需要三次握手四次挥手的开销，如果每次请求都要这样的话，开销会比较大。因此最好能维持一个长连接，可以用个长连接来发多个请求。**HTTP 1.1 起，默认使用长连接** ,默认开启 Connection： keep-alive。 **HTTP/1.1 的持续连接有非流水线方式和流水线方式** 。流水线方式是客户在收到 HTTP 的响应报文之前就能接着发送新的请求报文。与之相对应的非流水线方式是客户在收到前一个响应后才能发送下一个请求。
2. **错误状态响应码** :在 HTTP1.1 中新增了 24 个错误状态响应码，如 409（Conflict）表示请求的资源与资源的当前状态发生冲突；410（Gone）表示服务器上的某个资源被永久性的删除。
3. **缓存处理** :在 HTTP1.0 中主要使用 header 里的 If-Modified-Since,Expires 来做为缓存判断的标准，HTTP1.1 则引入了更多的缓存控制策略例如 Entity tag，If-Unmodified-Since, If-Match, If-None-Match 等更多可供选择的缓存头来控制缓存策略。
4. **带宽优化及网络连接的使用** :HTTP1.0 中，存在一些浪费带宽的现象，例如客户端只是需要某个对象的一部分，而服务器却将整个对象送过来了，并且不支持断点续传功能，HTTP1.1 则在请求头引入了 range 头域，它允许只请求资源的某个部分，即返回码是 206（Partial Content），这样就方便了开发者自由的选择以便于充分利用带宽和连接。

## 十二 URI 和 URL 的区别是什么?

- URI(Uniform Resource Identifier) 是统一资源标志符，**可以唯一标识一个资源**。
- URL(Uniform Resource Locator) 是统一资源定位符，**可以提供该资源的路径**。它是一种具体的 URI，即 URL 可以用来标识一个资源，而且还指明了如何 locate 这个资源。

URI 的作用像身份证号一样，URL 的作用更像家庭住址一样。URL 是一种具体的 URI，它不仅唯一标识资源，而且还提供了定位该资源的信息。

## 十三 HTTP 和 HTTPS 的区别？

1. **端口** ：HTTP 的 URL 由“http://”起始且默认使用端口80，而HTTPS的URL由“https://”起始且默认使用端口443。
2. **安全性和资源消耗：** HTTP 协议运行在 TCP 之上，所有传输的内容都是明文，客户端和服务器端都无法验证对方的身份。HTTPS 是运行在 SSL/TLS 之上的 HTTP 协议，SSL/TLS 运行在 TCP 之上。所有传输的内容都经过加密，加密采用对称加密，但对称加密的密钥用服务器方的证书进行了非对称加密。所以说，HTTP 安全性没有 HTTPS 高，但是 HTTPS 比 HTTP 耗费更多服务器资源。
   - 对称加密：密钥只有一个，加密解密为同一个密码，且加解密速度快，典型的对称加密算法有 DES、AES 等；
   - 非对称加密：密钥成对出现（且根据公钥无法推知私钥，根据私钥也无法推知公钥），加密解密使用不同密钥（公钥加密需要私钥解密，私钥加密需要公钥解密），相对对称加密速度较慢，典型的非对称加密算法有 RSA、DSA 等。

## HTTPS工作流程

![1637835618779](C:\Users\MrR\AppData\Roaming\Typora\typora-user-images\1637835618779.png)

1.Client发起一个HTTPS（比如`https://juejin.im/user/5a9a9cdcf265da238b7d771c`）的请求，根据RFC2818的规定，Client知道需要连接Server的443（默认）端口。

2.Server把事先配置好的公钥证书（public key certificate）返回给客户端。

3.Client验证公钥证书：比如是否在有效期内，证书的用途是不是匹配Client请求的站点，是不是在CRL吊销列表里面，它的上一级证书是否有效，这是一个递归的过程，直到验证到根证书（操作系统内置的Root证书或者Client内置的Root证书）。如果验证通过则继续，不通过则显示警告信息。

4.Client使用伪随机数生成器生成加密所使用的对称密钥，然后用证书的公钥加密这个对称密钥，发给Server。

5.Server使用自己的私钥（private key）解密这个消息，得到对称密钥。至此，Client和Server双方都持有了相同的对称密钥。

6.Server使用对称密钥加密“明文内容A”，发送给Client。

7.Client使用对称密钥解密响应的密文，得到“明文内容A”。

8.Client再次发起HTTPS的请求，使用对称密钥加密请求的“明文内容B”，然后Server使用对称密钥解密密文，得到“明文内容B”。

## HTTP 与 HTTPS 的区别

- HTTP 是明文传输协议，HTTPS 协议是由 SSL+HTTP 协议构建的可进行加密传输、身份认证的网络协议，比 HTTP 协议安全。

![1637835656539](https://tprzfbucket.oss-cn-beijing.aliyuncs.com/hadoop/202111/25/182058-880344.png)

关于安全性，用最简单的比喻形容两者的关系就是卡车运货，HTTP下的运货车是敞篷的，货物都是暴露的。而https则是封闭集装箱车，安全性自然提升不少。

- HTTPS比HTTP更加安全，对搜索引擎更友好，利于SEO,谷歌、百度优先索引HTTPS网页;
- HTTPS需要用到SSL证书，而HTTP不用;
- HTTPS标准端口443，HTTP标准端口80;
- HTTPS基于传输层，HTTP基于应用层;
- HTTPS在浏览器显示绿色安全锁，HTTP没有显示;

## 建议

非常推荐大家看一下 《图解 HTTP》 这本书，这本书页数不多，但是内容很是充实，不管是用来系统的掌握网络方面的一些知识还是说纯粹为了应付面试都有很大帮助。下面的一些文章只是参考。大二学习这门课程的时候，我们使用的教材是 《计算机网络第七版》（谢希仁编著），不推荐大家看这本教材，书非常厚而且知识偏理论，不确定大家能不能心平气和的读完。

## 参考

- [https://blog.csdn.net/qq_16209077/article/details/52718250](https://blog.csdn.net/qq_16209077/article/details/52718250)
- [https://blog.csdn.net/zixiaomuwu/article/details/60965466](https://blog.csdn.net/zixiaomuwu/article/details/60965466)
- [https://blog.csdn.net/turn\_\_back/article/details/73743641](https://blog.csdn.net/turn__back/article/details/73743641)
- <https://mp.weixin.qq.com/s/GICbiyJpINrHZ41u_4zT-A?>

## 易错点

### 差错检验

1. 数据链路层的差错控制

   - 由于信道噪声等各种原因，帧在传输过程中可能会出现错误。用以使发送方确定接收方是否正确收到了由它发送的数据的方法称为差错控制。通常，这些错误可分为位错和帧错误。
   - 位错指帧中某些位出现了差错。通常采用循环冗余校验(C RC) 方式发现位错，通过自动重传请求(Automatic Repeat reQuest, ARQ ) 方式来重传出错的帧.具体做法是:让发送方将要发送的数据帧附加一定的CRC 冗余检错码一并发迭，接收方则根据检错码对数据帧进行错误检测，若发现错误， 则丢弃， 发送方超时重传该数据帧.这种差错控制方法就称为ARQ 法， ARQ 法仅返回很少的控制信息，便可有效地确认所发数据帧是否被正确接收.
   - 帧错误是指帧的丢失，重复或失序等错误。在数据链路层引入定时器和编号机制，可以保证每一帧最终都能有且仅有一次正确地交付给目的结点。

2. 传输层的UDP校验

   1. 在计算校验和时，要在UDP 数据报之前增加12个字节的伪首部，伪收部并不是UDP 真正的首部。只是在计算校验和时，临时添加在UDP 数据报的前面，得到一个临时的UDP 数据报。校验和就是按照这个临时的U DP 数据报计算的. 伪首部既不向下传送也不向上递交，而仅仅是为了计算校验和.这样的校验和，既检查了UDP 数据报， 又对IP 数据报的源IP 地址和目的IP地址进行了检验。
   2. UD P 校验和的计算方法和TCP 数据报首部校验和的计算方法相似，都使用二进制反码运算求和再取反。**但不同的是:lP 数据报的校验和只检验lP 数据报的首郁， 但UDP 的校验和是把首部和数据部分一起都检验。**
   3. 在发送方，首先是把全零放入校验和字段并且添加伪首部。然后，把UDP 数据报看成是由许多1 6 位的字串连接起来。若UDP 数据报的数据部分不是偶数个字节，则要在数据部分末尾增加一个全零字节(但此字节不发送〉。接下来就按二进制反码计算出这些16 位字的和.将此和的二进制反码写入校验和字段。在接收方，把收到的UDP 数据报加上伪首部(如果不为偶数个字第节，还需要补上全零字节〉后，按二进制反码计算出这些16 位字的和. 当无差错时其结果应全为1， 否则就表明有差错出现，接收方就应该丢弃这个UDP 数据报。

3. 传输层的TCP校验

   检验和字段检验的范围包括首部和数据这两部分。在计算检验和时，和UDP 一样，要在TCP 报文段的前面加 12 字节的伪首部〈只需将UDP 伪首部的第4 个字段，即协议字段的1 7 改成6 ，其他的和UDP 一样)。

- **在这里注意吧，不管是UDP还是TCP,检验的部分都包括首部和数据部分。**

### 每一层的功能总结

1. 物理层：该层包括物理连接媒介，是计算机联网的基础，进行转发比特流。（任何一种调制解调器）
2. 数据链路层：在不可靠的物理线路上进行可靠的数据传递。（ALOHA,PPP,CSMA,CSMA/CD,CDMA）
3. 网络层：实际上是完成主机到主机之间的通信服务，（IP,ARP,RARP,ICMP,OSPF,BGP）
4. 传输层：提供的是端到端的数据通信服务，（TCP,UDP）
5. 会话层：负责在网络中的两个节点之间建立和维持通信。
6. 表示层：为不同终端的上层用户提供数据和信息的格式化标示方法（数据加密解密,XML,HTML）
7. 应用层：负责对软件提供接口以使程序能够使用网络的服务，（注意：不是运行着的那些程序，而是对应用程序提供接口或服务）FTP,HTTP,DNS。

## 面试题总结

1. 拥塞控制

   1. 慢开始
      - 发送方维持一个叫做拥塞窗口`cwnd（congestion window）`的状态变量。拥塞窗口的大小取决于网络的拥塞程度，并且动态地在变化。发送方让自己的发送窗口等于拥塞窗口，另外考虑到接受方的接收能力，发送窗口可能小于拥塞窗口。
      - 慢开始算法的思路就是，不要一开始就发送大量的数据，先探测一下网络的拥塞程度，也就是说由小到大逐渐增加拥塞窗口的大小。
      - 实时拥塞窗口大小是以字节为单位的。当然收到单个确认但此确认多个数据报的时候就加相应的数值。所以一次传输轮次之后拥塞窗口就加倍。这就是乘法增长，和后面的拥塞避免算法的加法增长比较。
      - 为了防止`cwnd `增长过大引起网络拥塞，还需设置一个慢开始门限`ssthresh `状态变量。`ssthresh` 的用法如下：
        - 当`cwnd<ssthresh `时，使用慢开始算法。
        - 当`cwnd>ssthresh` 时，改用拥塞避免算法。
        - 当`cwnd=ssthresh `时，慢开始与拥塞避免算法任意。
   2. 拥塞避免
      - 拥塞避免算法让拥塞窗缓慢增长，即每经过一个往返时间`RTT` 就把发送方的拥塞窗口`cwnd` 加1，而不是加倍。这样拥塞窗口按线性规律缓慢增长。
      - 无论是在慢开始阶段还是在拥塞避免阶段，只要发送方判断网络出现拥塞（其根据就是没有收到确认，虽然没有收到确认可能是其他原因的分组丢失，但是因为无法判定，所以都当做拥塞来处理），就把慢开始门限`ssthresh` 设置为出现拥塞时的发送窗口大小的一半。然后把拥塞窗口设置为1，执行慢开始算法。
   3. 快重传
      - 快重传要求接收方在收到一个失序的报文段后就立即发出重复确认（为的是使发送方及早知道有报文段没有到达对方）而不要等到自己发送数据时捎带确认。快重传算法规定，发送方只要一连收到三个重复确认就应当立即重传对方尚未收到的报文段，而不必继续等待设置的重传计时器时间到期。
   4. 快恢复
      - 当发送方连续收到三个重复确认时，就执行“乘法减小”算法，把`ssthresh `门限减半。但是接下去并不执行慢开始算法。
      - 考虑到如果网络出现拥塞的话就不会收到好几个重复的确认，所以发送方现在认为网络可能没有出现拥塞。所以此时不执行慢开始算法，而是将`cwnd` 设置为`ssthresh `的大小，然后执行拥塞避免算法。

2. 为什么建立连接协议是三次握手，而关闭连接却是四次握手呢？

   - 这是因为服务端的`LISTEN `状态下的`SOCKET `当收到`SYN` 报文的建连请求后，它可以把`ACK`和`SYN`（`ACK `起应答作用，而`SYN` 起同步作用）放在一个报文里来发送。但关闭连接时，当收到对方的`FIN` 报文通知时，它仅仅表示对方没有数据发送给你了；但未必你所有的数据都全部发送给对方了，所以你可以未必会马上会关闭`SOCKET`,也即你可能还需要发送一些数据给对方之后，再发送`FIN `报文给对方来表示你同意现在可以关闭连接了，所以它这里的`ACK `报文和`FIN `报文多数情况下都是分开发送的。

3. 第三次握手失败

   - 当客户端收到服务端的`SYN+ACK `应答后，其状态变为`ESTABLISHED`，并会发送`ACK `包给服务端，准备发送数据了。如果此时`ACK `在网络中丢失，过了超时计时器后，那么`Server`端会重新发送`SYN+ACK` 包，重传次数根据`/proc/sys/net/ipv4/tcp_synack_retries `来指定，默认是5 次。如果重传指定次数到了后，仍然未收到`ACK `应答，那么一段时间后，`Server` 自动关闭这个连接。但是`Client` 认为这个连接已经建立，如果`Client` 端向`Server` 写数据，`Server`端将以`RST`包响应，方能感知到`Server` 的错误。
   - 在`S erver`返回一个确认的`SYN-ACK` 包的时候，S 可能由于各种原因不会接到C 回应的ACK 包。这个也就是所谓的半开放连接，S 需要耗费一定的数量的系统内存来等待这个未决的连接，虽然这个数量是受限，但是恶意者可以通过创建很多的半开放式连接来发动SYN 洪水攻击。攻击者可以通过IP 欺骗发送SYN 包给受害者系统，这个看起来是合法的，但事实上所谓的C 根本不会进行ACK 回应服务端S 的SYN-ACK 报文，这意味着受害者将永远不会接到ACK报文。而此时，半开放连接将最终耗用受害者所有的系统资源（即使等待ACK 包有超时限制），受害者将不能再接收任何其他的请求。

4. 如何应对TCP SYN Flood

   - 第一个参数tcp_synack_retries = 0 是关键，表示回应第二个握手包（SYN+ACK 包）给客户端IP 后，如果收不到第三次握手包（ACK 包）后，不进行重试，加快回收“半连接”，不要耗光资源。
   - 修改这个参数为0 的副作用：网络状况很差时，如果对方没收到第二个握手包，可能连接服务器失败，但对于一般网站，用户刷新一次页面即可。这些可以在高峰期或网络状况不好时tcpdump 抓包验证下。
   - 之所以可以把tcp_synack_retries 改为0，因为客户端还有tcp_syn_retries 参数，默认是5，即使服务器端没有重发SYN+ACK 包，客户端也会重发SYN 握手包。
   - tcp_max_syn_backlog
     从字面上就可以推断出是什么意思。在内核里有个队列用来存放还没有确认ACK 的客户端
     请求，当等待的请求数大于tcp_max_syn_backlog 时，后面的会被丢弃。
   - 所以，适当增大这个值，可以在压力大的时候提高握手的成功率。手册里推荐大于1024。使用服务器的内存资源，换取更大的等待队列长度，让攻击数据包不至于占满所有连接而导致正常用户无法完成握手。
     当半连接的请求数量超过了tcp_max_syn_backlog 时，内核就会启用SYN cookie 机制，不再把半连接请求放到队列里，而是用SYN cookie 来检验。
   - 启用3
     启用之前，服务器在接到SYN 数据包后，立即分配存储空间，并随机化一个数字作为SYN号发送SYN+ACK 数据包。然后保存连接的状态信息等待客户端确认。启用SYN Cookie 之后，服务器不再分配存储空间，而且通过基于时间种子的随机数算法设置一个SYN 号，替代完全随机的SYN 号。发送完SYN+ACK 确认报文之后，清空资源不保存任何状态信息。直到服务器接到客户端的最终ACK 包，通过Cookie 检验算法鉴定是否与发出去的SYN+ACK报文序列号匹配，匹配则通过完成握手，失败则丢弃。当然，前文的高级攻击中有SYN 混合ACK 的攻击方法，则是对此种防御方法的反击，其中优劣由双方的硬件配置决定

5. 客户端收到一个窗口为0 的包怎么处理

   - TCP 长连接与短连接

     TCP 短连接的情况，client 向server 发起连接请求，server 接到请求，然后双方建立连接。client 向server 发送消息，server 回应client，然后一次读写就完成了，这时候双方任何一个都可以发起close 操作，不过一般都是client 先发起close 操作。为什么呢，一般的server不会回复完client 后立即关闭连接的，当然不排除有特殊的情况。从上面的描述看，短连接
     一般只会在client/server 间传递一次读写操作client 向server 发起连接，server 接受client 连接，双方建立连接。Client 与server 完成一次读写之后，它们之间的连接并不会主动关闭，后续的读写操作会继续使用这个连接。

6. 为什么要有time_wait

   1. 可靠的终止TCP 连接。

      可靠的终止TCP 连接，若处于time_wait 的client 发送给server 确认报文段丢失的话，server将在此又一次发送FIN 报文段，那么client 必须处于一个可接收的状态就是time_wait 而不是close 状态。

   2. 保证让迟来的TCP 报文段有足够的时间被识别并丢弃。

      保证迟来的TCP 报文段有足够的时间被识别并丢弃，linux 中一个TCPport 不能打开两次或两次以上。当client 处于time_wait 状态时我们将无法使用此port 建立新连接，假设不存在time_wait 状态，新连接可能会收到旧连接的数据。

   3. 可靠地实现TCP 全双工连接的终止

      TCP 协议在关闭连接的四次握手过程中，最终的ACK 是由主动关闭连接的一端（后面统称A端）发出的，如果这个ACK 丢失，对方（后面统称B 端）将重发出最终的FIN，因此A 端必须维护状态信息（TIME_WAIT）允许它重发最终的ACK。如果A 端不维持TIME_WAIT 状态，而是处于CLOSED 状态，那么A 端将响应RST 报文，B 端收到后将此报文解释成一个错误（在java 中会抛出connection reset 的SocketException)。
      因而，要实现TCP 全双工连接的正常终止，必须处理终止过程中四个报文任何一个报文的
      丢失情况，主动关闭连接的A 端必须维持TIME_WAIT 状态。

   4. 允许老的重复报文在网络中消逝

      TCP 报文可能由于路由器异常而“迷途”，在迷途期间，TCP 发送端可能因确认超时而重发这个报文，迷途的报文在路由器修复后也会被送到最终目的地，这个迟到的迷途报文到达时可能会引起问题。在关闭“前一个连接”之后，马上又重新建立起一个相同的IP 和端口之间的“新连接”，“前一个连接”的迷途重复分组在“前一个连接”终止后到达，而被“新连接”收到了。为了避免这个情况，TCP 协议不允许处于TIME_WAIT 状态的连接启动一个新的可用连接，因为TIME_WAIT 状态持续2MSL，就可以保证当成功建立一个新TCP 连接的时候，来自旧连接重复分组已经在网络中消逝。

7. 客户端和服务器都可能会进入time_wait

   - 高并发TCP 服务器中进行主动关闭的一方最好是客户端：因为对于高并发服务器来说文件描述符资源是很重要的资源，如果对于每一个连接都要经历TIME_WAIT 这个2MSL 的时长，势必造成资源不能立马复用的浪费。虽然对于客户端来说TIME_WAIT 状态会占用端口和句柄资源，但是客户端一般很少有并发资源限制，所以客户端执行主动关闭是比较合适的。

   - TIME_WAIT 状态到底会占用什么？

     被占用的是一个五元组：（协议，本地IP，本地端口，远程IP，远程端口）。对于Web 服务器，协议是TCP，本地IP 通常也只有一个，本地端口默认的80 或者443。只剩下远程IP 和远程端口可以变了。如果远程IP 是相同的话，就只有远程端口可以变了。这个只有几万个，所以当同一客户端向服务器建立了大量连接之后，会耗尽可用的五元组导致问题。

8. 客户端断开连接造成time_wait 影响

   - 客户端：
     客户端与服务端进行短连接的TCP 通信，如果在同一台机器上进行压力测试模拟上万的客户请求，并且循环与服务端进行短连接通信，那么这台机器将产生4000 个左右的TIME_WAITsocket，后续的短连接就会产生address already in use : connect 的异常。如果是客户端发起了连接，传输完数据然后主动关闭了连接，这时这个连接在客户端就会处于TIMEWAIT 状态，同时占用了一个本地端口。如果客户端使用短连接请求服务端的资源或者服务，客户端上将有大量的连接处于TIMEWAIT 状态，占用大量的本地端口。最坏的情况就是，本地端口都被用光了，这时将无法再建立新的连接。

9. 客户端断开连接造成time_wait 解决

   - 客户端：

   1. 使用长连接，如果是http，可以使用keepalive
   2. 增加本地端口可用的范围，比如Linux 中调整内核参数：net.ipv4.ip_local_port_range
   3. tcp_tw_reuse 参数用来设置是否可以在新的连接中重用TIME_WAIT 状态的套接字。注
      意，重用的是TIME_WAIT 套接字占用的端口号，而不是TIME_WAIT 套接字的内存等。这个
      参数对客户端有意义，在主动发起连接的时候会在调用的inet_hash_connect()中会检查是否
      可以重用TIME_WAIT 状态的套接字。如果你在服务器段设置这个参数的话，则没有什么作
      用，因为服务器端ESTABLISHED 状态的套接字和监听套接字的本地IP、端口号是相同的，
      没有重用的概念。但并不是说服务器端就没有TIME_WAIT 状态套接字。

   - 服务器：
     不像客户端有端口限制， 处理大量TIME_WAIT Linux 已经优化很好了， 每个处于
     TIME_WAIT 状态下连接内存消耗很少，
     而且也能通过tcp_max_tw_buckets = 262144 配置最大上限，现代机器一般也不缺这点内存。
     tcp_timestamps 参数用来设置是否启用时间戳选项，tcp_tw_recycle 参数用来启用快速回收
     TIME_WAIT 套接字。tcp_timestamps 参数会影响到tcp_tw_recycle 参数的效果。如果没有时
     间戳选项的话，tcp_tw_recycle 参数无效

10. 客户端收到ConnectionReset

    - server 端主动发起了断连
      导致“Connection reset”的原因是服务器端因为某种原因关闭了Connection，而客户端依然
      在读写数据， 此时服务器会返回复位标志“RST” ， 然后此时客户端就会提示
      “java.net.SocketException: Connection reset”。
      服务器返回了“RST”时，如果此时客户端正在从Socket 套接字的输出流中读数据则会提示
      Connection reset”；
      服务器返回了“RST”时，如果此时客户端正在往Socket 套接字的输入流中写数据则会提示
      “Connection reset by peer”。

11. UDP 可靠传输

    - 实现一个最基础的可靠udp 通讯协议，我们只需要提供一个重传机制即可。在这我实现了
      一个简单的可靠udp 协议，这个协议为每一个发送出去的udp 数据包分配一个包id，每次
      接收方收到一个数据包时，都要回应发送方一个ack 对应这个包id。协议通过这种确认机制
      来保证接收方能收到发送方发出的udp 数据包，在发出的时候，发送方应该设置一个计时
      器，超时的话会重传数据包。

    - 具体来说它没做这些事情：

      它没有保证包的有序性。发送方连续发送几个udp 数据包，接收方可以以任何顺序收到这
      几个数据包。如果想要做到有序性，必须由应用层来完成。
      它没做流量控制。发送方连续大量发送数据包会导致网络性能变差，丢包次数增大。
      它没对数据包大小做控制。为了避免IP 层对数据包进行分片，应用层应该要保证每个数据
      包的大小不超过MTU。如果这个数据包会经过广域网（一般情况下）这个值应该不超过576。
      考虑到IP 头的20 字节，udp 头的8 个字节，以及这个协议头的字节。最好每次发送的数据大小在512m以内。

12. socket 选项TCP_NODELAY在网络拥塞控制领域，有一个非常有名的算法叫做Nagle 算法（Nagle algorithm），这是
    使用它的发明人John Nagle 的名字来命名的，John Nagle 在1984 年首次用这个算法来尝
    试解决福特汽车公司的网络拥塞问题（RFC 896）。
    该问题的具体描述是：如果我们的应用程序一次产生1 个字节的数据，而这个1 个字节数
    据又以网络数据包的形式发送到远端服务器，那么就很容易导致网络由于太多的数据包而过
    载。比如，当用户使用Telnet 连接到远程服务器时，每一次击键操作就会产生1 个字节数
    据，进而发送出去一个数据包，所以，在典型情况下，传送一个只拥有1 个字节有效数据
    的数据包，却要发费40 个字节长包头（即ip 头20 字节+tcp 头20 字节）的额外开销，这
    种有效载荷（payload）利用率极其低下的情况被统称之为愚蠢窗口症候群（Silly Window
    Syndrome）。可以看到，这种情况对于轻负载的网络来说，可能还可以接受，但是对于重
    负载的网络而言，就极有可能承载不了而轻易的发生拥塞瘫痪。

    针对上面提到的这个状况，Nagle 算法的改进在于：如果发送端欲多次发送包含少量字符的
    数据包（一般情况下，后面统一称长度小于MSS 的数据包为小包，与此相对，称长度等于
    MSS 的数据包为大包，为了某些对比说明，还有中包，即长度比小包长，但又不足一个MSS
    的包），则发送端会先将第一个小包发送出去，而将后面到达的少量字符数据都缓存起来而
    不立即发送，直到收到接收端对前一个数据包报文段的ACK 确认、或当前字符属于紧急数
    据，或者积攒到了一定数量的数据（比如缓存的字符数据已经达到数据包报文段的最大长度）
    等多种情况才将其组成一个较大的数据包发送出去。
    设置NODELAY 会立即发送，不会延迟。

13. 如何解决tcp 粘包问题

    面向流的协议 
    1）数据包固定大小，每收到该大小字节视为一个包
    2）分隔符，比如\r\n
    3）自定义数据包，header 中指定body 的长度（最常使用）