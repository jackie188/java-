
<!-- TOC -->

- [计算机网络](#计算机网络)
  - [计算机网络概述](#计算机网络概述)
    - [ISP](#isp)
    - [时延](#时延)
  - [OSI 与 TCP/IP 各层的结构与功能,都有哪些协议?](#osi-与-tcpip-各层的结构与功能都有哪些协议)
    - [应用层](#应用层)
      - [主机之间的通信方式（网络应用模型）](#主机之间的通信方式网络应用模型)
        - [客户-服务器（C/S）：客户是服务的请求方，服务器是服务的提供方。](#客户-服务器cs客户是服务的请求方服务器是服务的提供方)
        - [对等（P2P）：不区分客户和服务器。](#对等p2p不区分客户和服务器)
      - [DNS域名系统](#dns域名系统)
        - [层次域名空间](#层次域名空间)
        - [域名服务器](#域名服务器)
        - [域名解析过程](#域名解析过程)
      - [文件传输协议](#文件传输协议)
        - [工作原理](#工作原理)
        - [控制连接与数据连接](#控制连接与数据连接)
      - [动态主机配置协议](#动态主机配置协议)
      - [远程登录协议](#远程登录协议)
      - [电子邮件协议](#电子邮件协议)
        - [SMTP（发送协议）](#smtp发送协议)
        - [POP3（读取协议）](#pop3读取协议)
        - [IMAP（读取协议）](#imap读取协议)
      - [万维网WWW](#万维网www)
        - [WWW 的概念与组成结构](#www-的概念与组成结构)
        - [超文本传输协议HTTP](#超文本传输协议http)
      - [WEB页面请求过程](#web页面请求过程)
      - [常用端口号](#常用端口号)
    - [运输层](#运输层)
      - [传输层的功能](#传输层的功能)
      - [传输层的寻址和端口](#传输层的寻址和端口)
      - [TCP和UDP的特点](#tcp和udp的特点)
      - [UDP协议](#udp协议)
        - [UDP协议的特点：](#udp协议的特点)
        - [UDP首部格式](#udp首部格式)
      - [TCP协议](#tcp协议)
        - [TCP协议特点](#tcp协议特点)
        - [TCP首部格式](#tcp首部格式)
        - [TCP链接管理](#tcp链接管理)
          - [TCP三次握手](#tcp三次握手)
          - [TCP四次挥手](#tcp四次挥手)
        - [TCP可靠传输](#tcp可靠传输)
        - [TCP滑动窗口](#tcp滑动窗口)
        - [TCP流量控制](#tcp流量控制)
        - [TCP拥塞控制](#tcp拥塞控制)
    - [网络层](#网络层)
      - [网络层的功能](#网络层的功能)
      - [拥塞控制和路由转发](#拥塞控制和路由转发)
      - [IP数据报格式](#ip数据报格式)
      - [IP地址编码方式](#ip地址编码方式)
          - [分类](#分类)
          - [子网划分](#子网划分)
          - [无分类](#无分类)
      - [地址解析协议 ARP](#地址解析协议-arp)
      - [网际控制报文协议 ICMP](#网际控制报文协议-icmp)
      - [虚拟专用网VPN](#虚拟专用网vpn)
      - [网络地址转换NAT](#网络地址转换nat)
      - [路由器的结构](#路由器的结构)
      - [路由器分组转发流程](#路由器分组转发流程)
      - [路由选择协议](#路由选择协议)
      - [ipv6](#ipv6)
      - [路由算法](#路由算法)
    - [数据链路层](#数据链路层)
      - [基本问题](#基本问题)
      - [信道分类](#信道分类)
      - [信道复用技术](#信道复用技术)
      - [CSMA/CD 协议](#csmacd-协议)
      - [介质访问控制](#介质访问控制)
      - [流量控制与可靠传输](#流量控制与可靠传输)
      - [PPP协议](#ppp协议)
      - [MAC地址](#mac地址)
      - [局域网](#局域网)
      - [以太网](#以太网)
      - [广域网](#广域网)
      - [交换机](#交换机)
      - [数据链路层设备](#数据链路层设备)
      - [虚拟局域网](#虚拟局域网)
    - [物理层](#物理层)
      - [名词解释](#名词解释)
      - [通信方式](#通信方式)
      - [电路交换与分组交换以及报文交换](#电路交换与分组交换以及报文交换)
      - [物理层设备](#物理层设备)
    - [总结一下](#总结一下)
  - [TCP 三次握手和四次挥手(面试常客)](#tcp-三次握手和四次挥手面试常客)
    - [2.1 TCP 三次握手漫画图解](#21-tcp-三次握手漫画图解)
    - [2.2 为什么要三次握手](#22-为什么要三次握手)
    - [2.3 第 2 次握手传回了 ACK，为什么还要传回 SYN？](#23-第-2-次握手传回了-ack为什么还要传回-syn)
    - [2.5 为什么要四次挥手](#25-为什么要四次挥手)
  - [三 TCP,UDP 协议的区别](#三-tcpudp-协议的区别)
  - [四 TCP 协议如何保证可靠传输](#四-tcp-协议如何保证可靠传输)
    - [4.1 ARQ 协议](#41-arq-协议)
      - [停止等待 ARQ 协议](#停止等待-arq-协议)
      - [连续 ARQ 协议](#连续-arq-协议)
    - [4.2 滑动窗口和流量控制](#42-滑动窗口和流量控制)
    - [4.3 拥塞控制](#43-拥塞控制)
  - [五 在浏览器中输入 url 地址 ->> 显示主页的过程(面试常客)](#五-在浏览器中输入-url-地址---显示主页的过程面试常客)
  - [六 状态码](#六-状态码)
  - [七 各种协议与 HTTP 协议之间的关系](#七-各种协议与-http-协议之间的关系)
  - [八 HTTP 长连接,短连接](#八-http-长连接短连接)
  - [九 HTTP 是不保存状态的协议,如何保存用户状态?](#九-http-是不保存状态的协议如何保存用户状态)
  - [十 Cookie 的作用是什么?和 Session 有什么区别？](#十-cookie-的作用是什么和-session-有什么区别)
  - [十一 HTTP 1.0 和 HTTP 1.1 的主要区别是什么?](#十一-http-10-和-http-11-的主要区别是什么)
  - [十二 URI 和 URL 的区别是什么?](#十二-uri-和-url-的区别是什么)
  - [十三 HTTP 和 HTTPS 的区别？](#十三-http-和-https-的区别)
  - [建议](#建议)
  - [参考](#参考)
  - [易错点](#易错点)
    - [差错检验](#差错检验)
    - [每一层的功能总结](#每一层的功能总结)
  - [面试题总结](#面试题总结)

<!-- /TOC -->


# 计算机网络

## 计算机网络概述

![1630995509741](https://tprzfbucket.oss-cn-beijing.aliyuncs.com/hadoop/202109/07/141830-279848.png)

网络把主机连接起来，形成一个独立的网络，而互连网（internet）是把多种不同的网络连接起来，因此互连网是网络的网络。而互联网（Internet）是全球范围的互连网。

![1630929056448](https://tprzfbucket.oss-cn-beijing.aliyuncs.com/hadoop/202109/06/195057-83160.png)

### ISP

互联网服务提供商 ISP 可以从互联网管理机构获得许多 IP 地址，同时拥有通信线路以及路由器等联网设备，个人或机构向 ISP 缴纳一定的费用就可以接入互联网，中国移动，联通，电信都是ISP机构。

![1630929157025](https://tprzfbucket.oss-cn-beijing.aliyuncs.com/hadoop/202109/06/195237-582592.png)

目前的互联网是一种多层次 ISP 结构，ISP 根据覆盖面积的大小分为第一层 ISP、区域 ISP 和接入 ISP。互联网交换点 IXP 允许两个 ISP 直接相连而不用经过第三个 ISP。

![1630929192880](https://tprzfbucket.oss-cn-beijing.aliyuncs.com/hadoop/202109/06/195313-33945.png)



### 时延

总时延 = 排队时延 + 处理时延 + 传输时延 + 传播时延

![1630929542601](https://tprzfbucket.oss-cn-beijing.aliyuncs.com/hadoop/202109/06/195903-984209.png)

1. 排队时延

分组在路由器的输入队列和输出队列中排队等待的时间，取决于网络当前的通信量。

2. 处理时延

主机或路由器收到分组时进行处理所需要的时间，例如分析首部、从分组中提取数据、进行差错检验或查找适当的路由等。

3.  传输时延

主机或路由器传输数据帧所需要的时间。

![1630929589232](https://tprzfbucket.oss-cn-beijing.aliyuncs.com/hadoop/202109/06/195950-356750.png)

其中 l 表示数据帧的长度，v 表示传输速率。

4. 传播时延

电磁波在信道中传播所需要花费的时间，电磁波传播的速度接近光速。

![1630929628576](https://tprzfbucket.oss-cn-beijing.aliyuncs.com/hadoop/202109/06/200029-330720.png)

其中 l 表示信道长度，v 表示电磁波在信道上的传播速度。

## OSI 与 TCP/IP 各层的结构与功能,都有哪些协议?

学习计算机网络时我们一般采用折中的办法，也就是中和 OSI 和 TCP/IP 的优点，采用一种只有五层协议的体系结构，这样既简洁又能将概念阐述清楚。

![1630928807627](https://tprzfbucket.oss-cn-beijing.aliyuncs.com/hadoop/202109/06/194648-392852.png)

![1630929707290](https://tprzfbucket.oss-cn-beijing.aliyuncs.com/hadoop/202109/06/200148-981303.png)

### 应用层

**大图**

![1630995518777](https://tprzfbucket.oss-cn-beijing.aliyuncs.com/hadoop/202109/07/141840-723813.png)

**应用层(application-layer）的任务是通过应用进程间的交互来完成特定网络应用。**应用层协议定义的是应用进程（进程：主机中正在运行的程序）间的通信和交互的规则。对于不同的网络应用需要不同的应用层协议。在互联网中应用层协议很多，如**域名系统 DNS**，支持万维网应用的 **HTTP 协议**，支持电子邮件的 **SMTP 协议**等等。我们把应用层交互的数据单元称为**报文**。

**HTTP 协议**

> 超文本传输协议（HTTP，HyperText Transfer Protocol)是互联网上应用最为广泛的一种网络协议。所有的 WWW（万维网） 文件都必须遵守这个标准。设计 HTTP 最初的目的是为了提供一种发布和接收 HTML 页面的方法。（百度百科）

#### 主机之间的通信方式（网络应用模型）

##### 客户-服务器（C/S）：客户是服务的请求方，服务器是服务的提供方。

![1630929239811](https://tprzfbucket.oss-cn-beijing.aliyuncs.com/hadoop/202109/06/195401-79419.png)

1. 在客户/服务器(ClientJServer ，C/S) 模型中，有一个总是打开的主机称为服务器，它服务于许多来自其他称为客户机的主机请求。其工作流程是:
   1. 服务器处于接收请求的状态。
   2. 客户机发出服务请求， 并等待接收结果。
   3. 服务器收到请求后， 分析请求，进行必要的处理，得到结果并发送给客户机。
2. 客户程序必须知道服务器程序的地址，在客户机上一般不需要特妹的硬件和复杂的操作系统。而服务器上运行的软件则是专门用来提供某种服务的程序，可同时处理多个远程或本地客户的要求。系统启动后即自动调用并一直不断地运行着， 被动地等待并接收来自各地客户的请求。因此，服务器程序不需要知道客户程序的地址。
   客户/服务器模型最主要的特征是: 客户是服务请求方，服务器是服务提供方.
3. 常见的使用客户/服务器模型的应用包括：Web、文件传输( FTP、远程登录和电子邮件等)
4. 客户/服务器模型的主要特点还有:
   1. 网络中各计算机的地位不平等，服务器可以通过对用户权限的限制来达到管理客户机的目的，使它们不能随意存储/删除数据，或进行其他受限的网络活动。整个网络的管理工作由少数机服务器担当，故网络管理非常集中和方便。
   2. 客户机相互之间不直接通信。例如， 在Web 应用中两个浏览器并不直接通信。可扩展性不佳。受硬件和网络带宽的限制， 服务器支持的客户机数有限。

##### 对等（P2P）：不区分客户和服务器。

![1630929263640](https://tprzfbucket.oss-cn-beijing.aliyuncs.com/hadoop/202109/06/195425-723150.png)

1. 在C/S 棋型中，服务器性能的好坏决定了整个系统的性能，当大量用户的请求服务时，服务器就必然成为系统的瓶颈.**P2P**的思想是整个网络中的传输内容不再被保存在一个中心服务器上，每个结点都同时具有下载、上传的功能， 其权利和义务都是大体对等的。

2. 在P2P 模型中， 各计算机没有固定的客户和服务器划分。相反， 任意一对计算机一一称为对等方( Peer ) ，且接相互通信.实际上， P2P 模型从本质上来看仍然是使用客户/服务器方式，每个结点既作为客户访问其他结点的资源，也作为服务器提供资源给其他结点访问.当前比较流行的P2P 应用如PPli ve 、Bittorrent 和电驴等。

3. 与C/S 模型相比， P2P 棋型的优点主要体现在:

   1. 减轻了服务器的压力，消除了对某个服务器的完全依赖，可以将任务分配到各个结点上， 因此大大提高了系统效率和资源利用率(例如， 播放流媒体时对服务器的压力过大， 而通过P2P 棋型， 可以利用大量的客户机来提供服务)。
   2. 多个客户机之间可以直接共享文挡。
   3. 可扩展性好， 传统服务器有响应和带宽的限制， 因此只能接受一定数量的请求。
   4. 网络健壮性强，单个结点的失效也不会影响其他部分的结点。
   5. P2P 模型也有缺点， 在获取服务的同时， 还要给其他结点提供服务，因此会占用较多的内存，影响整机速度.例如， 经常进行P2P 下我还会对硬盘造成较大的损伤。据某互联网调研机构统计，当前P2P 程序已经占据了五联网50%~90%的流盘，使网络变得非常拥嚣， 因此各大ISP (互联网服务提供商，如电信、网通等〉通常部对P2P 应用持反对态度。

   **两种模型示意图**

   ![](https://tprzfbucket.oss-cn-beijing.aliyuncs.com/hadoop/202109/07/104003-147853.png)

#### DNS域名系统

DNS 是一个分布式数据库，提供了主机名和 IP 地址之间相互转换的服务。这里的分布式数据库是指，每个站点只保留它自己的那部分数据。

域名系统DNS (Domain Name System ) 是因特网使用的命名系统，用来把便于人们记忆的含有特定含义的主机名(如www.cskaoyan. com )转换为便于机器处理的lP 地址。

从概念上看可以将DNS 分为3 个部分: 层次域名空间、域名服务器和解析器。

域名具有层次结构，从上到下依次为：根域名、顶级域名、二级域名，如下示意图：

![1630977589800](https://tprzfbucket.oss-cn-beijing.aliyuncs.com/hadoop/202109/07/091951-912276.png)

DNS 可以使用 UDP 或者 TCP 进行传输，使用的端口号都为 53。大多数情况下 DNS 使用 UDP 进行传输，这就要求域名解析器和域名服务器都必须自己处理超时和重传从而保证可靠性，在这两种情况下会使用 TCP 进行传输。



##### 层次域名空间

- 因特网采用类似树状结构的命名方法。采用这种命名方法， 任何一个连接在因特网上的主机或路由器，都有一个唯一的层次结构的名字，即域名( Domain Name). "域" ( Domain ) 是名字空间中一个可被管理的划分。域还可以划分为子域，而子域还可以继续划分为子域的子域， 这样就形成了顶级域、-一级域、二级域等。每一个域名部是由标号序列组成，而各标号之间用点(" ." )隔开，如下面的域名：

  ![](https://tprzfbucket.oss-cn-beijing.aliyuncs.com/hadoop/202109/07/104543-34739.png)

  1. 关于域名中的标号有以下几点需要注意:

     1. 标号中的英文不区分大小写。
     2. 标号中除连字符(-)外不能使用其他的标点符号.
     3. 每一个标号不超过63 个字符，多标号组成的完整域名最长不超过255 个字符。
     4. 级别最低的域名写在最左边，而级别最高的顶级域名写在最右边.

  2. 顶级域名有一下三大类：

     1. 国家顶级域名nTLD ，国家和某些地区的域名，如，( .cn" 表示中园， " .μs" 农示美国， ".uk"表示英国， ".hk" 友示中国香港特区。
     2. 通用顶级域名gTLD，常见的有".com " (公司企业)、" .net " (网绵服务机构〉、".0rg" (非
        营利性的组织〉和".gov" (美国的政府部门〉等.
     3. 基础结构域名。这种顶级域名只有一个，即arpa ，用于反向域名解析， 因此又称为反向域名。

  3. 国家顶级域名下注册的域名均由该国家自行确定

     ![](https://tprzfbucket.oss-cn-beijing.aliyuncs.com/hadoop/202109/07/104547-878341.png)

##### 域名服务器

- **因特网的域名系统被设计成一个联机分布式的数据库系统，并采用客户/服务器模式，域名到IP 地址的解析是由运行在域名服务器上的程序完成的**，一个服务器所负由管辖的范围〈或有极限的〉也称为区〈不足以"域"为根位)，各单位根据具体情况来划分自己管辖范围的区，每一个区中的所有结点必须是能够连通的，每个区设有相应的权限域名服务器，用来保存该区的所有主机的域名到IP 地址的映射，每一个域名服务器不但能够进行一些域名到lP 地址的解析，而且还必须具有连向其他域名服务器的信息，当自己不能进行域名到ip地址的转换时，能够知道到什么地方去找别的域名服务器。
- DNS 使用了大量的域名服务器，它们以层次方式组织。没有一台域名服务器具有因特网上所有主机的映射，相反，该映射分布在所有的DNS 服务器上，**采用分布式设计的DNS 系统，是一个在因特网上实现分布式数据库的精彩范例**，主要有四种类砌的域名服务器.

1. 根域名服务器

   根域名服务器是最高层次的域名服务器， 所有的根域名服务器都知道所有的顶级域名服务器的I P 地址。根域名服务器也是最重要的域名服务器，不管是哪一个本地域名服务器，若要对因特网上任何一个域名进行解析，只要自己无法解析，就首先要求助于根域名服务器。因特网上有着13 个根域名服务器，尽管我们将这13 个根域名服务器中的每个都视为单个的服务器，但每台"服务器"实际上是冗余服务器的集群，以提供全性和可靠性。需要注意的是，根域名服务器用来管辖顶级域〈如.com) ，通常它并不直接把待查询的域名直接转换成iP 地址，而是告诉本地域名服务器下一步应可找哪一个顶级域名服务器进行奇询.

2. 顶级成名服务器

   这些域名服务器负责管理在该顶级域名服务器注册的所有二级域名，当收到DN S 查询请求时，就给出相应的回答(可能是最后的结果， 也可能是下一步应当查找的域名服务器的Ip地址〉。

3. 授权精名服务器 (权限域名服务器 )

   每一个主机都必须在授权域名服务器处登记，为了更加方便地工作， 一个主机最好至少有两个授权域名服务器。实际上， 许多域名服务器都同时充当本地域名服务器和授权域名服务器。授权域名服务器总是能够将其管辖的主机名转换为该主机的IP 地址。

4. 本地成名服务器

   本地域名服务器对域名系统非常重要，每一个因特网服务提供者I SP ，或一个大学，甚至一个大学里的系，都可以拥有一个本地域名服务器，当一个主机发出DNS 查询请求时，这个查询请求报文就发送给该主机的本地域名服务器，事实上，我们在Windows 系统中配置"本地连接"时， 就需要填写DNS 服务器地址， 这个地址就是本地DNS 域名服务器的地址。

   **域名服务器图示**

   ![](https://tprzfbucket.oss-cn-beijing.aliyuncs.com/hadoop/202109/07/104602-774339.png)

##### 域名解析过程

- 域名解析过程

  域名解析是指把域名映射成为IP 地址或把lP 地址映射成为域名的过程，前者称为正向解析，后者称为反向解析，客户端需要域名解析时， 通过本机的DNS 客户端构造一个DN S 请求报文，以UDP 数据报方式发往本地域名服务器。域名解析有两种方式: **递归查询和递归与选代相结合的查询**。递归查询的过程如图6-6(a)所示，由于该方法给根域名服务造成的负载过大，所以在实际中几乎不使用。

  ![](https://tprzfbucket.oss-cn-beijing.aliyuncs.com/hadoop/202109/07/104611-123499.png)

  1. 主机向本地域名服务器的查询采用的是递归查询
  2. 本地域名服务器向根域名服务器的查询采用迭代查询

- 为了提高DNS 的查询效率，并减少因特网上的DNS 查询报文数量，在域名服务器中广泛地使用了高速缓存。当一个DNS 服务器接收到DNS 查询结果时，它能将该DNS 信息缓存在高速缓存中。这样，当另一个相同的域名查询到达该DNS 服务器时，该服务器就能够直接提供所要求的IP 地址，而不需要再去向其他DNS 服务器询问了。因为主机名和IP 地址之间的映射不是永久的，所以DNS 服务器将在一段时间后丢弃高速缓存中的息。

> 域名系统(Domain Name System 缩写 DNS，Domain Name 被译为域名)是因特网的一项核心服务，它作为可以将域名和 IP 地址相互映射的一个分布式数据库，能够使人更方便的访问互联网，而不用去记住能够被机器直接读取的 IP 数串。（百度百科）例如：一个公司的 Web 网站可看作是它在网上的门户，而域名就相当于其门牌地址，通常域名都使用该公司的名称或简称。例如上面提到的微软公司的域名，类似的还有：IBM 公司的域名是 www.ibm.com、Oracle 公司的域名是 www.oracle.com、Cisco 公司的域名是 www.cisco.com 等。

#### 文件传输协议

##### 工作原理

- 文件传输协议FTP ( File Transfer Protocol ) 是因特网上使用得最广泛的文件传送协议。FTP提供交互式的访问，允许客户指明文件的类型与格式，并允许文件具有存取权限。它屏蔽了各计算机系统的细节，因而适合于在异构网络中任意计算机之间传选文件。
- FTP 提供以下功能:
  ①提供不同种类主机系统(硬、软件体系等都可以不同〉之间的文件传输能力。
  ②以用户权限管理的方式提供用户对远程FTP 服务器上的文件管理能力。
  ③ 以匿名FTP 的方式提供公用文件共事的能力。
- FTP 采用客户/服务器的工作方式，它使用**TCP 可靠的传输服务**,一个FTP 服务器进程可同时为多个客户进程提供服务. FTP 的服务器进程由两大部分组成: 一个主进程，负责接收新的请求:另外有若干个从属进程，负责处理单个请求.其工作步骤如下:
  1. 打开熟知端口21 (控制端口) ，使客户进程能够连接上.
  2. 等待客户进程发连接请求.
  3. 启动从属进程来处理客户进程发来的情求。主进程与从属进程并发执行， 从属进程对客户进程的请求处理完毕后即终止。
  4. 回到等待状态，继续接收其他客户进程的请求.
- 服务器必须在整个会话期间保留用户的状态信息。特别是服务器必须把指定的用户账户主与控制连接联系起来，服务器必须追踪用户在远程目录树上的当前位置。

FTP 使用 TCP 进行连接，它需要两个连接来传送一个文件：

- 控制连接：服务器打开端口号 21 等待客户端的连接，客户端主动建立连接后，使用这个连接将客户端的命令传送给服务器，并传回服务器的应答。
- 数据连接：用来传送一个文件数据。

##### 控制连接与数据连接

1. FTP 在工作时使用两个并行的TCP 连接 ，一个是控制连接〈端口号21 ) ， 一个是数据连接(端口号20). 使用两个不同的端口号可使协议更加简单和更容易实现.

   ![](https://tprzfbucket.oss-cn-beijing.aliyuncs.com/hadoop/202109/07/105304-82870.png)

2. .控制连接

   服务器监听21号端口，等待客户连接，建立在这个端口上的连接称为控制连接，控制连接用来传输控制信息(如连接请求、传送请求等〉。并且控制信息都是以7 位ASCIl格式传送的。等客户发出的传送请求，通过控制连接发送给服务器端的控制进程，但控制连接并不用来传送文件。在传输文件时还可以使用控制连接(例如，客户在传输中途发一个中止传输的命令)，因此控制连接在整个会话期间一直保持打开状态.

3. 数据连接

   服务器端的控制进程在接收到FTP 客户发送来的文件传输请求后就创建"数据传送进程"和"数据连接"。数据连接用来连接客户端和服务器端的数据传送进程，数据传送进程实际完成文件的传送，在传送完毕后关闭"数据传送连接"并结束运行。

根据数据连接是否是服务器端主动建立，FTP 有主动和被动两种模式：

- 主动模式：服务器端主动建立数据连接，其中服务器端的端口号为 20，客户端的端口号随机，但是必须大于 1024，因为 0~1023 是熟知端口号。

![1630977631121](https://tprzfbucket.oss-cn-beijing.aliyuncs.com/hadoop/202109/07/105255-760128.png)

- 被动模式：客户端主动建立数据连接，其中客户端的端口号由客户端自己指定，服务器端的端口号随机。

![1630977667077](https://tprzfbucket.oss-cn-beijing.aliyuncs.com/hadoop/202109/07/092117-644794.png)

主动模式要求客户端开放端口号给服务器端，需要去配置客户端的防火墙。被动模式只需要服务器端开放端口号即可，无需客户端配置防火墙。但是被动模式会导致服务器端的安全性减弱，因为开放了过多的端口号。

#### 动态主机配置协议

DHCP (Dynamic Host Configuration Protocol) 提供了即插即用的连网方式，用户不再需要手动配置 IP 地址等信息。

DHCP 配置的内容不仅是 IP 地址，还包括子网掩码、网关 IP 地址。

**动态主机配置协议（DHCP）**

- 动态主机配置协议常常用来给主机动态的分配ip地址，他提供即插即用联网的机制，这种机制允许一台主机加入一个新的网络是自动的获取ip地址，而不用动手进行配置，**DHCP是应用层协议，是基于UDP的**。

  - 工作原理：

    使用客户机服务器模式，需要ip地址的主机在启动时DHCP服务器广播发送发现报文，该主机就成为了DHCP服务器的客户，本网络上的所有主机都会收到此报文，但是只有DHCP服务器响应此报文，服务器查询ip地址池中是否有该计算机的配置，若果有就返回信息，没有就分配ip地址。

- DHCP服务器分配给主机的ip地址是临时的，因此客户机只有在有限时间内使用该ip地址。

DHCP 具体工作过程如下：

1. 客户端发送 Discover 报文，该报文的目的地址为 255.255.255.255:67，源地址为 0.0.0.0:68，被放入 UDP 中，该报文被广播到同一个子网的所有主机上。如果客户端和 DHCP 服务器不在同一个子网，就需要使用中继代理。
2. DHCP 服务器收到 Discover 报文之后，发送 Offer 报文给客户端，该报文包含了客户端所需要的信息。因为客户端可能收到多个 DHCP 服务器提供的信息，因此客户端需要进行选择。
3. 如果客户端选择了某个 DHCP 服务器提供的信息，那么就发送 Request 报文给该 DHCP 服务器。
4. DHCP 服务器发送 Ack 报文，表示客户端此时可以使用提供给它的信息。

![1630977711469](https://tprzfbucket.oss-cn-beijing.aliyuncs.com/hadoop/202109/07/092153-88738.png)

#### 远程登录协议

TELNET 用于登录到远程主机上，并且远程主机上的输出也会返回。

TELNET 可以适应许多计算机和操作系统的差异，例如不同操作系统系统的换行符定义。

#### 电子邮件协议

一个电子邮件系统由三部分组成：**用户代理、邮件服务器以及邮件协议。**

邮件协议包含**发送协议和读取协议**，发送协议常用 SMTP，读取协议常用 POP3 和 IMAP。

![1630977754216](https://tprzfbucket.oss-cn-beijing.aliyuncs.com/hadoop/202109/07/092236-626927.png)

##### SMTP（发送协议）

SMTP 只能发送 ASCII 码，而互联网邮件扩充 MIME 可以发送二进制文件。MIME 并没有改动或者取代 SMTP，而是增加邮件主体的结构，定义了非 ASCII 码的编码规则。

![1630977777984](https://tprzfbucket.oss-cn-beijing.aliyuncs.com/hadoop/202109/07/092300-603915.png)

简单邮件传输协议( Simple Majl Transfer Protocol. SMTP ) 是一种提供可靠且有效的电子邮件传输的协议，控制两个相互通信的SMTP 进程交换信息。由于SMTP 使用客户/服务器方式，因此负责发送邮件的SMTP 进程就是S MTP 客户，而负责接收邮件的SMTP 进程就是S MTP 服务器。SMTP 用的是TCP 连接， 端口号25 . SMTP通信有以下三个阶段:

- 连接建立
- 邮件发送
- 连接释放

##### POP3（读取协议）

POP3 的特点是只要用户从服务器上读取了邮件，就把该邮件删除。但最新版本的 POP3 可以不删除邮件。

邮局协议( Post Office Protocol , POP ) 是一个非常简单、但功能有限的邮件读取协议，现在使用的是它的第3 个版本POP3 . POP3 采用的是"拉" ( Pull ) 的通信方式，当用户读取邮件时，用户代理向邮件服务器发出求，" 拉"取用户邮箱中的邮件。POP 也使用客户/服务器的工作方式，在传输层使用TCP 协议，端口号110 . 在接收方计算机中的用户代理必须运行POP 客户程序，而在接收厅的邮件服务器上则运行POP 服务器程序.POP 有两种工作方式"下载并保留"和"下载并删除模式"，在下载并保留"的模式下，用户从邮件服务器上读取邮件之后，邮件依然会保留在邮件服务器上， 用户下次可以再次从服务器上读取该邮件;而使用"下载并删除"时，邮件一旦被读取之后，就被从邮件服务器上删除了，用户不能再次从服务器七读取了。

另一个邮件接收协议是网际报文存取协议IMAP ，它比POP 复杂得多，但是目前还只是因特网的建议标准。

##### IMAP（读取协议）

IMAP 协议中客户端和服务器上的邮件保持同步，如果不手动删除邮件，那么服务器上的邮件也不会被删除。IMAP 这种做法可以让用户随时随地去访问服务器上的邮件。

#### 万维网WWW

##### WWW 的概念与组成结构

1. 万维网WWW ( World Wide Web) 是一个资料空间。在这个空间中: 一样有用的事物，称为一样"资源并且由一个全域"统一资源定位符(URL) 标识.这些资源通过超文本传输协议( HTTP ) 传送给使用者，而后者通过点击链接来'获取资源。
2. 万维网的内核部分是由三个标准构成的:
   1. 统一资源定位符(URL) ，负责标识万维网上的各种文档，并使每个文档在整个万维网的范围内具有唯一的标识符URL ，URL 的一般形式是: <协议>://<主机>:<端口>/<路栓〉，常见的〈协议〉有http 、ftp 等; <主机〉是存放资源的主机在因特网中的域名，也可以是IP 地址;<端口〉和〈路径〉有时可以省略。在URL中 不区分大小写。
   2. 超文本传输协议( Hπ的，它是一个应用层协议，使用TCP 连接进行可靠的传输， HTTP是万维网客户程序和服务器程序之间交互所必须严格遵守的协议.
   3. 超文本标记语言( HTML ) 是一种文档结构的标记语言，使用一些约定的标记对页面上的各种信息(包括文字、卢音、图像、视频等〉、格式进行描述。

##### 超文本传输协议HTTP

- HTTP 协议定义了浏览器〈万维网客户进程)怎样向万维网服务器请求万维网文档，以及服务器怎样把文档传送给浏览器。从层次的角度看， HTTP 是面向事务的(Transacti on- orieoted) 应用层协议， 它规定了在浏览器和服务器之间的请求和响应的格式和规则，它是万维网上能够可靠地交换文件(包括文本、声音、图像等各种多媒体文件〉的重要基础。

1. HTTP 的操作过程

   - 从协议执行过程来说，浏览器要访问WWW 服务器时，首先要完成对WWW 服务器的域名解析。一旦获得了服务器的ip 地址，浏览器将通过TCP 向服务器发送连接建立请求.

   - 万维网的大致工作过程如图6-11 所示。每个万维网站点都有一个服务器进程，它不断地监听TCP 的端口80 (默认) ， 当监听到连接请求后便与浏览器建立连接. TCP 连接边立后，浏览器就向服务器发送请求获取某Web 页面的HTTP请求。服务器收到HTTP 请求后，将构建所请求的Web 页必需的信息， 并通过日HTTP响应返回给浏览器。浏览器再将信息进行解释，然后将Web页显示给用户。最后， TCP 连接释放。

     ![](https://tprzfbucket.oss-cn-beijing.aliyuncs.com/hadoop/202109/07/110140-507862.png)

   - 在浏览器和服务器之间的请求和响应的交瓦， 必须按照规定的格式和遵循一定的规则，这些格式和规则就是HTTP. 因此HTTP 有两类报文: 请求报文(从Web 客户端向Web 服务器发迭服务请求〉和响应报文(从Wcb 服务器对Web 客户端请求的回答).

     - 用户单击鼠标后所发生的事件按顺序如下(以访问清华大学为例) :
       1. 浏览器分析链接指向页面的URL （ `hltp ://WWW.tsinghua. edu.cn !chnlindex.htm` )
       2. 浏览器向DNS 请求解析`www.tsinghua.edu.cn` 的ip地址.
       3. 域名系统DN S 解析出清华大学服务器的iP 地址。
       4. 浏览器与该服务器建立TCP 连接(默认端口号80 ).
       5. 浏览器发出HTTP 请求: `GET !chnlindex.htm.`
       6. 服务器通过HTTP 响应把文件index.htm 发送给浏览器。
       7.  TCP 连接释放。
       8. 浏览器将文件index .htm 进行解释，并将Web 页显示给用户。

2. HTTP 协议的特点

   1. HTTP 协议是**无状态**的.也就是说，同一个客户第二次访问同一个服务器上的页面时， 服务器的响应与第一次被访问时的相同。因为服务器并不记得曾经访问过的这个客户， 也不记得为该客户曾经服务过多少次。HTTP 的无状态特性简化了服务器的设计，使服务器更容易支持大量并发的HTTP 请求。在实际应用中， 通常使用Cookie 加数据库的方式来跟踪用户的活动〈如记录用户最近浏览的商品等)。Cookie 是一个存储在用户主机中的文本文件，Cookie 面含有一串"识别码"， 如" 1 23456"，用于Web服务识别用户。Web 服务器根据Cookie 就能从数据库中查询到该用户的活动记录， 进而执行一些个性化的工作， 如根据用户之前浏览过的商品向其推荐新产品等。

   2. H TTP 采用TCP 作为运输层协议， 保证了数据的可靠传输. HTTP 不必考虑数据在传输过程中被丢弃后又怎样被重传.但是， HTTP 协议本身是无连接的(请读者务必注意).这就是说，虽然HTTP 使用了TCP 连接，但通信的双方在交换HTIP 报文之前不需要先建立HTTP 连接.

   3. HTTP 既可以使用非持久连接，也可以使用持久连接( HTTP! I . I 支持〉。

      1. 对于非持久连接，每-个网页元素对象(比如一个JPEG 图、FLASH 等〉的传输都需要单独建立一个TCP 连接，如剧6 - 12 所示〈第三次握手的报文段中捎带了客户对万维队| 文挡的请求)。也就是说，请求一个万维网文档所需的时间是该文件的传输时间(与文档大小成正比〉加上两倍往返时间RTT,

      2. 所谓持久连接，是指万维网服务在发送响应后仍然保持这条连接，使同一个客户和服务都可以继续在这条连接上传送后续的HTTP请求与响应报文。

         ![](https://tprzfbucket.oss-cn-beijing.aliyuncs.com/hadoop/202109/07/110144-297434.png)

      3. 持久连接又分为非流水线和流水线两种方式.对于非流水线方式，客户在收到前一个响应后才能发出下一个请求. HTTP/ I. I 的默认方式是使用流水线的持久连接.这中情况下， 客户每遇到一个对象引用就立即发出一个情需求，因而客户可以逐个地连续发出对各个引用对象的请求 . 如果所有的请求和响应都是连续发迭的，那么所有引用的对象共计经历l 个RTT 延迟，而不是像非流水线方式那样，每个弓|用都必须有l 个RTT门延迟。

   4. HttP 的报文结构

      - HttP 是面向文本的(Text.Qriented) .因此报文中的每个字段都是一些ASCIl 码串，并且每个字段的长度都是不确定的. 有两类HttP 报文:

        - 请求报文一一从客户向服务器发送的请求报文，如图6- 14(a)所示。

        - 响应报文一一从服务器到客户的回答，如图6-14(b)所示。

          ![](https://tprzfbucket.oss-cn-beijing.aliyuncs.com/hadoop/202109/07/110146-75506.png)

      - HttP 请求报文和响应报文都是由三个部分组成。从图6-14 可以看出，这两种报文的区别就是开始行不同.

      - 开始行，用于区分是请求报文还是响应报文。在请求报文中的开始行叫做请求行，而在响报文中的开始行叫做状态行.开始行的三个字段之间部以空格分隔开，最后的"CR " 和" LF "分别代表"回车"和"换行，请求报文的"请求行"有三个内容: 方法、请求资源的URL 以及HttP 的版本。其中，"方法"就是对所谓求对象进行的操作，这些方法实际上也就是一些命令.表6-1 给出了HTIP 请求报文中常用的几个方法。

        ![](https://tprzfbucket.oss-cn-beijing.aliyuncs.com/hadoop/202109/07/110153-699624.png)

      - 首部行， 用来说明浏览器、服务器或报文上体的一些信息。首部可以有好几行，但可以不使用.在每一个首部行都有首部字段名和它的值，每一行在结束的地方都要有"回车"和"换行“，整个首部结束时，还有一空行将首部行和后面的实体上体分开。

      - 实体主体，在请求报文中一般都不用这个宇段，而在响应报文中也可能没有这个字段。

![](https://tprzfbucket.oss-cn-beijing.aliyuncs.com/hadoop/202109/07/110148-812895.png)

#### WEB页面请求过程

- 假设主机最开始没有 IP 地址以及其它信息，那么就需要先使用 DHCP 来获取。
- 主机生成一个 DHCP 请求报文，并将这个报文放入具有目的端口 67 和源端口 68 的 UDP 报文段中。
- 该报文段则被放入在一个具有广播 IP 目的地址(255.255.255.255) 和源 IP 地址（0.0.0.0）的 IP 数据报中。
- 该数据报则被放置在 MAC 帧中，该帧具有目的地址 FF:<zero-width space>FF:<zero-width space>FF:<zero-width space>FF:<zero-width space>FF:FF，将广播到与交换机连接的所有设备。
- 连接在交换机的 DHCP 服务器收到广播帧之后，不断地向上分解得到 IP 数据报、UDP 报文段、DHCP 请求报文，之后生成 DHCP ACK 报文，该报文包含以下信息：IP 地址、DNS 服务器的 IP 地址、默认网关路由器的 IP 地址和子网掩码。该报文被放入 UDP 报文段中，UDP 报文段有被放入 IP 数据报中，最后放入 MAC 帧中。
- 该帧的目的地址是请求主机的 MAC 地址，因为交换机具有自学习能力，之前主机发送了广播帧之后就记录了 MAC 地址到其转发接口的交换表项，因此现在交换机就可以直接知道应该向哪个接口发送该帧。
- 主机收到该帧后，不断分解得到 DHCP 报文。之后就配置它的 IP 地址、子网掩码和 DNS 服务器的 IP 地址，并在其 IP 转发表中安装默认网关。

2. ARP 解析 MAC 地址

- 主机通过浏览器生成一个 TCP 套接字，套接字向 HTTP 服务器发送 HTTP 请求。为了生成该套接字，主机需要知道网站的域名对应的 IP 地址。
- 主机生成一个 DNS 查询报文，该报文具有 53 号端口，因为 DNS 服务器的端口号是 53。
- 该 DNS 查询报文被放入目的地址为 DNS 服务器 IP 地址的 IP 数据报中。
- 该 IP 数据报被放入一个以太网帧中，该帧将发送到网关路由器。
- DHCP 过程只知道网关路由器的 IP 地址，为了获取网关路由器的 MAC 地址，需要使用 ARP 协议。
- 主机生成一个包含目的地址为网关路由器 IP 地址的 ARP 查询报文，将该 ARP 查询报文放入一个具有广播目的地址（FF:<zero-width space>FF:<zero-width space>FF:<zero-width space>FF:<zero-width space>FF:FF）的以太网帧中，并向交换机发送该以太网帧，交换机将该帧转发给所有的连接设备，包括网关路由器。
- 网关路由器接收到该帧后，不断向上分解得到 ARP 报文，发现其中的 IP 地址与其接口的 IP 地址匹配，因此就发送一个 ARP 回答报文，包含了它的 MAC 地址，发回给主机。

3. DNS 解析域名

- 知道了网关路由器的 MAC 地址之后，就可以继续 DNS 的解析过程了。
- 网关路由器接收到包含 DNS 查询报文的以太网帧后，抽取出 IP 数据报，并根据转发表决定该 IP 数据报应该转发的路由器。
- 因为路由器具有内部网关协议（RIP、OSPF）和外部网关协议（BGP）这两种路由选择协议，因此路由表中已经配置了网关路由器到达 DNS 服务器的路由表项。
- 到达 DNS 服务器之后，DNS 服务器抽取出 DNS 查询报文，并在 DNS 数据库中查找待解析的域名。
- 找到 DNS 记录之后，发送 DNS 回答报文，将该回答报文放入 UDP 报文段中，然后放入 IP 数据报中，通过路由器反向转发回网关路由器，并经过以太网交换机到达主机。

4. HTTP 请求页面

- 有了 HTTP 服务器的 IP 地址之后，主机就能够生成 TCP 套接字，该套接字将用于向 Web 服务器发送 HTTP GET 报文。
- 在生成 TCP 套接字之前，必须先与 HTTP 服务器进行三次握手来建立连接。生成一个具有目的端口 80 的 TCP SYN 报文段，并向 HTTP 服务器发送该报文段。
- HTTP 服务器收到该报文段之后，生成 TCP SYN ACK 报文段，发回给主机。
- 连接建立之后，浏览器生成 HTTP GET 报文，并交付给 HTTP 服务器。
- HTTP 服务器从 TCP 套接字读取 HTTP GET 报文，生成一个 HTTP 响应报文，将 Web 页面内容放入报文主体中，发回给主机。
- 浏览器收到 HTTP 响应报文后，抽取出 Web 页面内容，之后进行渲染，显示 Web 页面。

#### 常用端口号

![1630977828052](https://tprzfbucket.oss-cn-beijing.aliyuncs.com/hadoop/202109/07/092348-131410.png)

### 运输层

**大图**

![1630995518777](https://tprzfbucket.oss-cn-beijing.aliyuncs.com/hadoop/202109/07/141840-723813.png)

**运输层(transport layer)的主要任务就是负责向两台主机进程之间的通信提供通用的数据传输服务**。应用进程利用该服务传送应用层报文。“通用的”是指并不针对某一个特定的网络应用，而是多种应用可以使用同一个运输层服务。由于一台主机可同时运行多个线程，因此运输层有复用和分用的功能。所谓复用就是指多个应用层进程可同时使用下面运输层的服务，分用和复用相反，是运输层把收到的信息分别交付上面应用层中的相应进程。

面向连接服务是指在通信之前双方必须先建立连接，在通信过程中，整个连接的情况一直被实时的监控和管理，通信结束后释放连接。

无连接服务是指双方在通信时不需要建立连接，直接将数据发送到网络中，尽最大努力交付。 

**运输层主要使用以下两种协议:**

1. **传输控制协议 TCP**（Transmission Control Protocol）--提供**面向连接**的，**可靠的**数据传输服务。
2. **用户数据协议 UDP**（User Datagram Protocol）--提供**无连接**的，尽最大努力的数据传输服务（**不保证数据传输的可靠性**）。

**TCP 与 UDP 的对比见问题三。**

网络层只把分组发送到目的主机，但是真正通信的并不是主机而是主机中的进程。传输层提供了进程间的逻辑通信，传输层向高层用户屏蔽了下面网络层的核心细节，使应用程序看起来像是在两个传输层实体之间有一条端到端的逻辑通信信道。

#### 传输层的功能

- 从通信和信息处理的角度看，传输层向他上面的应用层提供通信服务，它属于面向通信部分的最高层，同时也是用户功能中的最底层，传输层位于网络层之上，他为运行在不同主机上面的进程提供了端到端的逻辑通信，而网络层提供主机之间的逻辑通信即使网络层的传输不可靠，传输层也可以保证可靠传输。
- 传输层的功能
  - **传输层提供应用进程之间的逻辑通信（即端到端的通信），而网络层提供主机之间的通信。**
  - 复用和分用的功能。复用是指发送方不同的应用进程都可以使用同一个传输层协议传输数据，分用是指接收方的传输层在剥去报文的首部后能把这些数据交付到目的地的应用进程。
  - 传输层还要对接收到的报文进行差错检验，（首部和数据部分），而网络层只检验首部，
  - 提供两种不同的传输层协议，面向连接的TCP和无连接的UDP。而在网络层只能提供面向连接的（虚电路服务）的服务或者数据报服务（无连接）。

#### 传输层的寻址和端口

1. 端口：端口可以让应用程序将其数据通过端口交付给传输层，以及可以让传输层知道应将其中的报文段交付给应用层的哪一个进程，端口是传输层的服务访问点，数据链路层的服务访问点是MAC地址，网络层的服务访问点是ip。
2. 端口号
   - 服务端使用的端口号：
     - 熟知端口号
     - 登记端口号
   - 客户端使用的端口号：49152-65535
3. 套接字
   - 在网络中通过不同ip来标示一台主机，通过端口号来标示进程，而套接字=（主机ip地址：端口号）可以用来唯一标示一台主机上的一个进程，

#### TCP和UDP的特点

- 用户数据报协议 UDP（User Datagram Protocol）是无连接的，尽最大可能交付，没有拥塞控制，面向报文（对于应用程序传下来的报文不合并也不拆分，只是添加 UDP 首部），支持一对一、一对多、多对一和多对多的交互通信。
- 传输控制协议 TCP（Transmission Control Protocol）是面向连接的，提供可靠交付，有流量控制，拥塞控制，提供全双工通信，面向字节流（把应用层传下来的报文看成字节流，把字节流组织成大小不等的数据块），每一条 TCP 连接只能是点对点的（一对一）。

#### UDP协议

##### UDP协议的特点：

1. UDP协议无需建立连接。
2. 分组首部开销小仅有8B开销，而TCP有20B的开销。
3. 应用层可以更好的控制要发送的数据的发送时间，UDP没有拥塞控制，
4. UDP尽最大努力交付，即不保证可靠交付。但这并不意味着应用对数据的要求是不可靠的。
5. UDP是面向报文的，发送方UDP对应用层叫下来的报文，在添加首部就交给ip层，既不拆分，也不进行合并，而是保留这些报文的边界。

1. UDP首部格式组成（一共8B）：
   1. 源端口2个字节。
   2. 目的端口一共2个字节。
   3. UDP的长度占两个字节。
   4. UDP检验和占两个字节。
2. UDP校验
   1. 校验时，如果UDP数据部分长度不是偶数个字节，需要填入一个全0字节，但是此字节和伪首部是一样的，不发送。
   2. 如果UDP校验检验处UDP数据报是错误的，那么可以丢弃，也可以交付给上层，但是需要附上错误的报告。
   3. 通过伪首部，不仅可以检查源端口号，目的端口号，和UDP数据部分，还可以检查数据报的源IP地址和目的IP地址。

##### UDP首部格式

![1630977156985](https://tprzfbucket.oss-cn-beijing.aliyuncs.com/hadoop/202109/07/091238-905226.png)



首部字段只有 8 个字节，包括源端口、目的端口、长度、检验和。12 字节的伪首部是为了计算检验和临时添加的。

#### TCP协议

##### TCP协议特点

TCP协议的特点：

1. `TCP`是面向连接的传输层协议。
2. 每一条`TCP`连接只能有两个端点，每一条`TCP`连接只能是点对点的。
3. `TCP`协议提供可靠交付服务，保证传输的数据无差错，不重复，无丢失。
4. `TCP`提供全双工的通信。
5. `TCP`是面向字节流的。
6. `tcp`报文段既可以运载数据，也可以用来建立连接，释放连接和应答。

##### TCP首部格式

（固定首部`20B`，长度一般是`4B`的整数倍）

![1630977200999](https://tprzfbucket.oss-cn-beijing.aliyuncs.com/hadoop/202109/07/091321-58378.png)

1. 序号字段：各占4`B`,`TCP`面向字节流，所以`TCP`传输的每一个字节都编上序号。序号字段的值是本报文段所发送数据的第一个字节的序号。
2. 确认序号段：占4`B`，是期望收到对方下一个报文段数据的第一个字节。
3. 数据偏移：占4`B`，标示首部长度，因为`Tcp`首部固定字段后面有选项字段，指出`TCP`数据字段距离`TCP`报文段起始处有多远。数据偏移的单位是32位，以4`B`为计算单位，最大长度达到60`B`。
4. 紧急指针`URL`:当`URG`为1的时候，表名紧急指针字段有效，告诉系统报文段中有紧急数据，相当于高优先级的数据。但是URG要和紧急指针配合使用，即数据从第一个字节到紧急指针所指的字节数为紧急数据。
5. 确认位：只有当ACK=1时确认号字段才有效，当ACK确认序号为0的时候，确认号无效，TCP规定在连接建立后ACK必须为1,。
6. 推送位PSH：当TCP接收到psh=1的报文的时候，就尽快的交付给上面的应用层的进程，而不用等到整个缓存满后再交给上层进程。
7. 复位为RST：RST=1的时候表名TCP连接中出现了严重的差错，必须释放连接，然后在重新建立连接。
8. 同步位（SYN）:同步为标示这是一个连接请求或者连接接收报文。当ACK=0,SYN=1的时候，表名这是一个连接请求的报文，如果对方同意建立连接，就把ACK设置为1进行回应，即SYN表示这是一个连接请求或者接受的报文。
9. 窗口字段：占2B，他指出现在允许发送端发送的数据量，接收方的数据缓存空间时有限的，顾窗口字段作为接收方让发送方允许发送数据量的依据。
10. 校验和：占2B，校验和检验的部分包括首部和数据部分，在计算校验和的时候，和UDP一样，需要在TCP报文的首部添加12B的伪首部，
11. 紧急指针位：栈16位，指出本报文段中数据一共有多少的字节，
12. 选项字段，长度可以改变，TCP最初只规定了一种选项，即最大报文段长度MSS,MSS是TCP报文段中的数据字段的最大长度。
13. 填充字段：这个是为了使整个首部长度为4B的整数倍。
14. 终止位：FIN=1表名此报文的发送方的数据已经发送完毕，并且要求释放连接。
15. 源端口和目的端口字段：各占2`B`，端口是传输层和应用层的服务接口，运输层的

##### TCP链接管理

TCP连接管理：

- TCP是面向连接的协议，因此每个TCP连接有三个阶段：连接建立，数据传送，连接释放

1. TCP连接建立过程：
   1. 客户机的TCP首先向服务器的TCP发送一个连接请求报文，这个特殊的报文中不含数据字段，其中首部的SYN=1,客户机会随机选择一个需要seq=x,（连接请求不需要携带数据，但是消耗序号）
   2. 服务器TCP连接收到请求后，如果允许建立连接，就向客户机发送确认，在确认报文中ACK=1,SYN=1,确认号字段的值为x+1,并且服务器也随机产生一个序号seq=y，（确认报文不携带数据，但是消耗序号）
   3. 当客户机收到确认报文后，还要向服务器给予确认，确认报文中ACK=1,序号字段为seq=x+1,确认号字段ack=y+1,该报文可以携带数据，如果不携带数据就不消耗序号。
   4. 服务器的资源是在完成第二次握手时分配的，而客户机资源是在完成第三次握手时分配的，这就使得服务器免收SYN洪泛攻击。
2. TCP连接的释放：
   1. 客户机关闭连接时，向其TCP发送一个连接释放请求，并且停止发送数据，主动关闭TCP连接，FIN=1，seq=u,（u是前面已经传送数据的最后一个字节的序号+1），FIN报文不携带数据，但是需要消耗一个数据。
   2. 服务器收到连接释放报文段后发出确认，确认号ack=u+1,而这个确认报文段自己的序号是v，（v等于前面传送数据最后一个字节的序号+1），此时这条全双工的链路就处于半关闭状态，即客户机不可以向服务器发送数据，但是服务器可以向客户端发送数据。
   3. 如果服务器没有数据发送，就发出FIN=1的报文，请求释放连接。
   4. 客户机收到连接释放报文段后，必须发出确认，在确认报文段中，ACK=1,确认序号ack=w+1,确认报文段自己的序号seq=U+1,但是此时TCP连接还没有释放，必须经过时间计时器2MSL之后才进入关闭状态。

###### TCP三次握手

![1630977237342](https://tprzfbucket.oss-cn-beijing.aliyuncs.com/hadoop/202109/07/091358-300892.png)

假设 A 为客户端，B 为服务器端。

- 首先 B 处于 LISTEN（监听）状态，等待客户的连接请求。
- A 向 B 发送连接请求报文，SYN=1，ACK=0，选择一个初始的序号 x。
- B 收到连接请求报文，如果同意建立连接，则向 A 发送连接确认报文，SYN=1，ACK=1，确认号为 x+1，同时也选择一个初始的序号 y。
- A 收到 B 的连接确认报文后，还要向 B 发出确认，确认号为 y+1，序号为 x+1。
- B 收到 A 的确认后，连接建立。

**三次握手的原因**

- 第三次握手是为了防止失效的连接请求到达服务器，让服务器错误打开连接。

- 客户端发送的连接请求如果在网络中滞留，那么就会隔很长一段时间才能收到服务器端发回的连接确认。客户端等待一个超时重传时间之后，就会重新请求连接。但是这个滞留的连接请求最后还是会到达服务器，如果不进行三次握手，那么服务器就会打开两个连接。如果有第三次握手，客户端会忽略服务器之后发送的对滞留连接请求的连接确认，不进行第三次握手，因此就不会再次打开连接。

###### TCP四次挥手

![1630977294099](https://tprzfbucket.oss-cn-beijing.aliyuncs.com/hadoop/202109/07/091456-21844.png)

以下描述不讨论序号和确认号，因为序号和确认号的规则比较简单。并且不讨论 ACK，因为 ACK 在连接建立之后都为 1。

- A 发送连接释放报文，FIN=1。
- B 收到之后发出确认，此时 TCP 属于半关闭状态，B 能向 A 发送数据但是 A 不能向 B 发送数据。
- 当 B 不再需要连接时，发送连接释放报文，FIN=1。
- A 收到后发出确认，进入 TIME-WAIT 状态，等待 2 MSL（最大报文存活时间）后释放连接。
- B 收到 A 的确认后释放连接。

**四次挥手的原因**

客户端发送了 FIN 连接释放报文之后，服务器收到了这个报文，就进入了 CLOSE-WAIT 状态。这个状态是为了让服务器端发送还未传送完毕的数据，传送完毕之后，服务器会发送 FIN 连接释放报文。

**TIME_WAIT**

客户端接收到服务器端的 FIN 报文后进入此状态，此时并不是直接进入 CLOSED 状态，还需要等待一个时间计时器设置的时间 2MSL。这么做有两个理由：

- 确保最后一个确认报文能够到达。如果 B 没收到 A 发送来的确认报文，那么就会重新发送连接释放请求报文，A 等待一段时间就是为了处理这种情况的发生。
- 等待一段时间是为了让本连接持续时间内所产生的所有报文都从网络中消失，使得下一个新的连接不会出现旧的连接请求报文。

建立和关闭的总结

- 建立连接,三次挥手

  ```java
  1. SYN=1,seq=x
  2. SYN=1,ACK=1,seq=y,ack=x+1
  3. ACK=1,seq=x+1,ack=y+1
  ```

- 释放连接，四次握手

  ```java
  1. FIN=1,seq=u
  2. ACK=1,seq=v,ack=u+1
  3. FIN=1,ACK=1,seq=w,ack=u+1
  4. ACK=1,seq=u+1,ack=w+1
  ```

##### TCP可靠传输

TCP 使用**超时重传**来实现可靠传输：如果一个已经发送的报文段在超时时间内没有收到确认，那么就重传这个报文段。

**TCP可靠传输机制**

- TCP的任务是在IP层不可靠的传输层之上建立一条可靠的数据传输服务。TCP使用**校验，序号，确认和重传机制**来达到目的，其中校验机制与UDP校验一样。
  - 序号
    - ·TCP连接传送的数据流中的每一个字节都编上了序号，序号字段值是指本报文段发送数据的第一个字节的序号，也就是seq值。
  - 确认：
    - TCP首部的确认号是**期望收到对方的下一个报文段的数据的第一个字节的序号**，发送方的缓存会持续存储哪些已经发送但是未收到确认的报文段，以便在需要的时候重传，TCP默认使用累积确认的方式，即TCP只确认数据流中至第一个丢失字节位置的字节。
  - 重传：
    - 两种事件会导致重传：**超时和冗余ACK**
      - 超时：TCP每发送一个报文段，就对这个报文段设置一个计时器，计时器时间到但是未收到确认就重传数据报。
      - 冗余ACK：标示发送方多次接收到了来自接收方的确认帧，即冗余确认机制，遇到这种情况，发送方通常开始快速重传机制。

一个报文段从发送再到接收到确认所经过的时间称为往返时间 RTT，加权平均往返时间 RTTs 计算如下：

![1630977348080](https://tprzfbucket.oss-cn-beijing.aliyuncs.com/hadoop/202109/07/091553-555622.png)

其中，0 ≤ a ＜ 1，RTTs 随着 a 的增加更容易受到 RTT 的影响。

超时时间 RTO 应该略大于 RTTs，TCP 使用的超时时间计算如下：

![1630977373699](C:\Users\MrR\AppData\Roaming\Typora\typora-user-images\1630977373699.png)

其中 RTTd 为偏差的加权平均值。

##### TCP滑动窗口

窗口是缓存的一部分，用来暂时存放字节流。发送方和接收方各有一个窗口，**接收方通过 TCP 报文段中的窗口字段告诉发送方自己的窗口大小**，发送方根据这个值和其它信息设置自己的窗口大小。

发送窗口内的字节都允许被发送，接收窗口内的字节都允许被接收。如果发送窗口左部的字节已经发送并且收到了确认，那么就将发送窗口向右滑动一定距离，直到左部第一个字节不是已发送并且已确认的状态；接收窗口的滑动类似，接收窗口左部字节已经发送确认并交付主机，就向右滑动接收窗口。

接收窗口只会对窗口内最后一个按序到达的字节进行确认，例如接收窗口已经收到的字节为 {31, 34, 35}，其中 {31} 按序到达，而 {34, 35} 就不是，因此只对字节 31 进行确认。发送方得到一个字节的确认之后，就知道这个字节之前的所有字节都已经被接收。

![1630977413613](https://tprzfbucket.oss-cn-beijing.aliyuncs.com/hadoop/202109/07/091655-700815.png)

##### TCP流量控制

**流量控制是为了控制发送方发送速率，保证接收方来得及接收。**

接收方发送的确认报文中的窗口字段可以用来控制发送方窗口大小，从而影响发送方的发送速率。将窗口字段设置为 0，则发送方不能发送数据。

**流量控制：**

TCP提供流量控制来消除发送方使接收方缓存区域发生溢出的可能，因此可以说流量控制是一个速度匹配服务。TCP的流量控制也是基于滑动窗口协议的。

- 流量控制是一个速度匹配的服务，匹配发送方的发送速率与接收方的接收速率，防止发送方发送数据过快而使接收方来不及接收数据发生丢包现象。

- 在接收方，通常维护一个接收窗口rwnd来动态调整TCP报文段中首部的窗口值，来限制发送方向网络中注入报文的速率。同时，发送方根据网络的拥塞窗口来估计发送窗口值，也叫作拥塞窗口cwnd，通常拥塞窗口=min{cwnd,rwnd}.

- **传输层流量控制和数据链路层流量控制的区别：传输层是端到端的流量控制，数据链路层定义中间两个节点之间的流量控制，并且数据链路层的滑动窗口大小不可以动态的变化传输层窗口可以动态变化。**

  ![](https://tprzfbucket.oss-cn-beijing.aliyuncs.com/hadoop/202109/07/124140-251143.png)

##### TCP拥塞控制

如果网络出现拥塞，分组将会丢失，此时发送方会继续重传，从而导致网络拥塞程度更高。因此当出现拥塞时，应当控制发送方的速率。这一点和流量控制很像，但是出发点不同。流量控制是为了让接收方能来得及接收，而拥塞控制是为了降低整个网络的拥塞程度。

![1630977463586](https://tprzfbucket.oss-cn-beijing.aliyuncs.com/hadoop/202109/07/091745-582403.png)

主要通过四个算法来进行拥塞控制：**慢开始、拥塞避免、快重传、快恢复。**

发送方需要维护一个叫做拥塞窗口（cwnd）的状态变量，注意拥塞窗口与发送方窗口的区别：**拥塞窗口只是一个状态变量，实际决定发送方能发送多少数据的是发送方窗口。**

为了便于讨论，做如下假设：

- 接收方有足够大的接收缓存，因此不会发生流量控制；
- 虽然 TCP 的窗口基于字节，但是这里设窗口的大小单位为报文段。

![1630977488399](https://tprzfbucket.oss-cn-beijing.aliyuncs.com/hadoop/202109/07/091808-361159.png)

**慢开始与拥塞避免**

发送的最初执行慢开始，令 cwnd = 1，发送方只能发送 1 个报文段；当收到确认后，将 cwnd 加倍，因此之后发送方能够发送的报文段数量为：2、4、8 ...

注意到慢开始每个轮次都将 cwnd 加倍，这样会让 cwnd 增长速度非常快，从而使得发送方发送的速度增长速度过快，网络拥塞的可能性也就更高。设置一个慢开始门限 ssthresh，当 cwnd >= ssthresh 时，进入拥塞避免，每个轮次只将 cwnd 加 1。

如果出现了超时，则令 ssthresh = cwnd / 2，然后重新执行慢开始。

**快重传与快恢复**

在接收方，要求每次接收到报文段都应该对最后一个已收到的有序报文段进行确认。例如已经接收到 M1 和 M2，此时收到 M4，应当发送对 M2 的确认。

在发送方，如果收到三个重复确认，那么可以知道下一个报文段丢失，此时执行快重传，立即重传下一个报文段。例如收到三个 M2，则 M3 丢失，立即重传 M3。

在这种情况下，只是丢失个别报文段，而不是网络拥塞。因此执行快恢复，令 ssthresh = cwnd / 2 ，cwnd = ssthresh，注意到此时直接进入拥塞避免。

慢开始和快恢复的快慢指的是 cwnd 的设定值，而不是 cwnd 的增长速率。慢开始 cwnd 设定为 1，而快恢复 cwnd 设定为 ssthresh。

![1630977525467](https://tprzfbucket.oss-cn-beijing.aliyuncs.com/hadoop/202109/07/091845-549526.png)

**补充**

TCP拥塞控制

1. 所谓拥塞控制是防止过多的数据包注入到网络，以使网络中的路由器或者链路过载，当出现拥塞时，端点之间并不了解拥塞发生的细节问题，对于通信的端点来说，往往表现为端到端的传输时延增大，拥塞和流量控制的共同点是都是通过控制发送方发送数据的速率来控制效果。但是两者也有区别，**拥塞控制是让网络可以承受现有的网络负荷，是一个全局性的问题，涉及到所有的主机，路由器，链路，但是，流量控制往往是指点对点的通信量的控制，即接收端控制发送端，接收端所要做的就是抑制发送端发送数据的速率，使得接收端来得及接收。**通常用四种算法来对拥塞进行控制：慢开始，拥塞避免，快重传，快恢复。

2. 发送方在确定发送数据报文段的速率的时候，要根据接收方接收能力，又要从全局考虑使得网络不要过度拥塞，因此TCP往往要维护两个窗口。

   1. 接收窗口（rwnd）:接收窗口根据目前接收缓存的大小所许诺的最新窗口值，反应接收窗口的容量大小，由接收方根据其放在TCP报文段的首部接收窗口大小中传输给发送方。

   2. 拥塞窗口（cwnd):发送方根据自己估算的网络拥塞成都而设置的窗口值，反映了当前网络的拥塞程度。只要网络发生了拥塞，拥塞窗口就会减少一点。

   3. 发送窗口的上限取决于接收窗口和拥塞窗口中较小的哪一个，即：

      发送窗口=min{接收窗口，拥塞窗口}

3. 下面对拥塞窗口的细节进行探讨。

   1. 慢开始算法：

      - 当TCP刚刚进行连接并且进行发送TCP报文的时候，先让拥塞窗口值的大小为1，即一个最大报文段的长度MSS，每收到对一个新的报文段的确认后，就将拥塞窗口增加1即增大一个MSS,用这样的方法逐渐增大拥塞窗口，以控制发送到网络的数据包。
      - 使用慢开始算法，每经过一个传输轮次（即一个RTT），拥塞窗口的值就会增大一倍，即拥塞窗口的大小呈指数型增长，这样，当慢开始算法一直把拥塞窗口的值增大到一个慢开始门限值sstresh时，就开始执行拥塞避免算法。

   2. 拥塞避免算法

      - 拥塞避免的算法如下,发送端的拥塞窗口每经过一个RTT就增加一个MSS大小，而不是加倍，使拥塞窗口按照线性缓慢增长(**即加法增大**)，而当出现一次网络超时的时候（网络拥塞），就让慢开始门限ssthresh的值等于当前拥塞窗口值的一半（**即乘法减小算法**）。ssthresh=cwnd/2。

      - 归纳：

        ```java
        cwnd<ssthresh//使用慢开始算法
        cwnd>ssthresh//改用拥塞避免算法
        cwnd=ssthresh//既可以使用慢开始算法，又可以使用拥塞避免算法
        ```

   3. 网络拥塞的处理：

      - 网络出现拥塞的时候，无论是在慢开始阶段，还是在拥塞避免阶段，只要发送方检测到超时的发生，（没有按时收到确认，重传计时器超时），就把慢开始门限的值ssthresh的值设置为出现拥塞时拥塞窗口值的一半，但是不可以小于2，然后把拥塞窗口的值设置为1，执行慢开始算法，这样做的目的是迅速减少发送到网络中的分组数目，使得发生拥塞的路由器有足够的时间把队列中挤压的分组处理完。

      - 但是拥塞避免也不能完全避免拥塞，拥塞避免是指在拥塞避免算法中把拥塞窗口的大小控制为按照线性增长。

        ![](https://tprzfbucket.oss-cn-beijing.aliyuncs.com/hadoop/202109/07/124412-676000.jpeg)

        - 初始时：拥塞窗口的值为1，慢开始门限设置为16，慢开始阶段，拥塞窗口的初始值为1每次经过一个传输轮次，拥塞窗口的值就加倍，所以在慢开始算法阶段，拥塞窗口的大小呈指数型增长。
        - 当拥塞窗口的值增长到慢开始门限的值16的时候，发生了拥塞，就改用为拥塞避免算法，拥塞窗口的大小呈线性增长。
        - 当拥塞窗口继续增长到24的时候，网络发生拥塞，此时让慢开始门限的值为此时的拥塞窗口值大小的一半，即12，在让拥塞窗口的大小为1，并且开始执行慢开始算法，当拥塞窗口再次达到12的时候，再次改为使用拥塞避免算法。
        - 注意在慢开始〈指数级增长〉阶段， 当2cwnd >ssthresh时，则下一个RTT的cwnd 等于ssthresh，而不是等于2cwnd， 即cwnd 不能跃过ssthresh值，在第16 个轮次时cwnd = 8，ssthresh= 12，在第17 个轮次时cwnd = 12.，而不等于16.
        - 在慢开始和拥塞避免算法中使用了"乘法减小"和"加法增大"方法。"乘法减小"是指不论在慢开始阶段还是拥塞避兔阶段，只要出砚一次超时(即很可能出现了网络拥塞)，就把慢开
          始门限值ssthresh设置为当前的拥塞窗口值的一半。当网络频繁出现拥塞时， ssthresh值就下降得很快，以大大减少注入到网络中的分组数。而"加法增大" 是指执行拥塞避免算法后，当收到对所有报文段的确认后〈即经过一个RTT) ，就把拥塞窗口cwnd 增加一个MSS 大小，使拥塞窗口缓慢增大，以防止网络过早出现拥塞。

      - 快重传和快恢复
        快重传和快恢复算法是对慢开始和拥塞避免算法的改进。

        - 快重传
          在上一节TCP 可靠传输机制中， 快速重传技术使用了用冗余ACK 来检测丢包的发生。同样，冗余ACK 也用于网络拥塞的检测(丢了包当然意味着网络可能出现了拥塞).快重传并非取消重传计时器， 而是在某些情况下可更早地重传丢失的报文段。
          当发送方连续收到三个监复的ACK 报文时，直接重传对方尚未收到的报文段，而不必等待那个报文段设置的重传计时器超时。

        - 快恢复
          快恢复算法原理: 当发送端收到连续三个冗余ACK (即重复确认〉时，就执行"乘法减小"
          算法，把慢开始门限ssthresh 设置为出现拥塞时发送方cwnd 的一半.与慢开始(慢开始算法将拥塞窗口cwnd 设置为1 )不同之处是它把cwnd 的值设置为慢开始门限ssthresh 改变后的数值，然后开始执行拥塞避免算法("加法增大'，使拥塞窗口缓慢地线性增大。

        - 由于跳过了cwnd 从l 起始的慢开始过程， 所以被称为快恢复。快恢复n法的实现过程如下：

          ![](E:/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AD%A6%E4%B9%A0%E6%96%87%E6%A1%A3/BigData_doc/img/network/%E5%BF%AB%E6%81%A2%E5%A4%8D.png)

          在流量控制中，发选方发送数据的量由接收方决定，而在拥塞控制中，发送方自己通过检测网络状况而决定。实际上，慢开始、拥挫避免算法、快蓝传和快恢挝几种算法应该趋同时应用在拥塞控制机制之中的，当发送方检测到超时的时候就采用馒开始和拥l塞避免， 当发送方接收到冗余ACK 的时候就采用快重传和快恢复。发送方发送窗口 的实际大小由流量控制和拥塞控制共同决定。因此，当题目中同时出现了接收端窗口(rwnd) 表明塞窗门(cwnd) 时，发送方实际的发送窗口大小是由rwnd 和cwnd 中较小的那一个确定的。

### 网络层

**大图**

![1630995518777](https://tprzfbucket.oss-cn-beijing.aliyuncs.com/hadoop/202109/07/141840-723813.png)

**在计算机网络中进行通信的两个计算机之间可能会经过很多个数据链路，也可能还要经过很多通信子网。网络层的任务就是选择合适的网络路由和交换结点， 确保数据及时传送。** 在发送数据时，网络层把运输层产生的报文段或用户数据报封装成分组和包进行传送。在 TCP/IP 体系结构中，由于网络层使用 **IP 协议**，因此分组也叫 **IP 数据报** ，简称 **数据报**。

这里要注意：**不要把运输层的“用户数据报 UDP ”和网络层的“ IP 数据报”弄混**。另外，无论是哪一层的数据单元，都可笼统地用“分组”来表示。

这里强调指出，网络层中的“网络”二字已经不是我们通常谈到的具体网络，而是指计算机网络体系结构模型中第三层的名称.

互联网是由大量的异构（heterogeneous）网络通过路由器（router）相互连接起来的。互联网使用的网络层协议是无连接的网际协议（Internet Protocol）和许多路由选择协议，因此互联网的网络层也叫做**网际层**或**IP 层**。

#### 网络层的功能

网络层要完成的功能之一就是寻找一种中间设备实现各种异构网络的互连，以构成更大的网络系统，根据不同层次，划分为不同的中间系统：

- 物理层：中继器，集线器（Hub)
- 数据链路层：网桥，交换机（switch）
- 网络层：交换机（route）
- 网络层以上：网关

采用**物理层以及数据链路层**设备，仅仅是把一个网络从范围上面扩大了，从网络方面看，他们仍属于一个网络，而采用网络层设备，是把许多不同的网络（比如以太网，广域网）相互连接起来。在TCP/IP网络体系结构里，网络层采用的是ip协议，但相互连接的网络可以是异构的，即使用不同的网络层协议，因此，用路由器把不同的网络相互连接起来，从网络层来看就好像是一个虚拟的ip网络，网络上的主机在通信时就好像在一个网络上通信一样，看不见网络具体的异构细节。

因为网络层是整个互联网的核心，因此应当让网络层尽可能简单。网络层向上只提供简单灵活的、无连接的、尽最大努力交互的数据报服务。

使用 IP 协议，可以把异构的物理网络连接起来，使得在网络层看起来好像是一个统一的网络。

![1630975506883](https://tprzfbucket.oss-cn-beijing.aliyuncs.com/hadoop/202109/07/084507-892894.png)

与 IP 协议配套使用的还有三个协议：

- 地址解析协议 ARP（Address Resolution Protocol）
- 网际控制报文协议 ICMP（Internet Control Message Protocol）
- 网际组管理协议 IGMP（Internet Group Management Protocol）

#### 拥塞控制和路由转发

- 路由器主要完成两个功能，**一是路由选择，二是分组转发**，路由选择即根据当前的网络构造出路由表，同时经常的和其他路由器之间相互交换路由表来维护路由信息，而分组转发是路由器根据路由表得出来转发表，每个分组在根据转发表查询从相应的接口转发出去。
- 拥塞控制：在**子网**中通常会出现网络中的分组过多而发生拥塞现象，判断网络是否进入拥塞状态的方法是观察网络的吞吐量，与网络负载之间的关系，如果网络的吞吐量随着网络的负载增大而减小，那么网络就可能进入了拥塞状态，当网络吞吐量下降到0时，网络就进入了死锁状态。为了避免网络发生拥塞，要进行拥塞控制，主要是如何获取网络中拥塞的信息，从而利用这些信息对网络进行控制，避免出现死锁状态发生，注意拥塞控制和流量控制的区别，拥塞控制是一个全局性问题，是控制整个网络上分组的量，拥塞控制涉及各个主机，路由等，如果仅仅单一的增加某一个资源不能解决网络拥塞问题，而流量控制解决的是点到点之间流量问题，可以通过控制发送方发送数据的速率来达到流量控制的目的，
- 拥塞的控制方法：
  - **开环控制是一种静态的预防方法。**
  - **闭环控制：是一种动态的控制方法。**

#### IP数据报格式

一个ipv4分组由数据和首部组成，首部前一部分固定20B，首部固定部分后面是一些可选字段，长度可以改变，用来提供错误检查和安全机制。

- ipv4首部的长度表示固定长度+可选字段长度，最小20B。
- 标示：在把一个数据报分片的时候用来标示每一个分片，使得在接收端可以重组。
- 首部校验和：只检验首部，而不检验数据部分。
- 首部长度，总长度，片偏移的基本单位是4B,1B,8B。

**图示**

![1630990129916](https://tprzfbucket.oss-cn-beijing.aliyuncs.com/hadoop/202109/07/124851-237058.png)

- **版本** : 有 4（IPv4）和 6（IPv6）两个值；
- **首部长度** : 占 4 位，因此最大值为 15。值为 1 表示的是 1 个 32 位字的长度，也就是 4 字节。因为固定部分长度为 20 字节，因此该值最小为 5。如果可选字段的长度不是 4 字节的整数倍，就用尾部的填充部分来填充。
- **区分服务** : 用来获得更好的服务，一般情况下不使用。
- **总长度** : 包括首部长度和数据部分长度。
- **生存时间** ：TTL，它的存在是为了防止无法交付的数据报在互联网中不断兜圈子。以路由器跳数为单位，当 TTL 为 0 时就丢弃数据报。
- **协议** ：指出携带的数据应该上交给哪个协议进行处理，例如 ICMP、TCP、UDP 等。
- **首部检验和** ：因为数据报每经过一个路由器，都要重新计算检验和，因此检验和不包含数据部分可以减少计算的工作量。
- **标识** : 在数据报长度过长从而发生分片的情况下，相同数据报的不同分片具有相同的标识符。
- **片偏移** : 和标识符一起，用于发生分片的情况。片偏移的单位为 8 字节。

ip数据报的分片

- 在数据链路层所能够承受的最大数据部分称之为最大传送单元MTU，因为ip数据报被封装在帧的数据部分，因此ip数据报受MTU的限制当ip数据报长度超过mtu时，就需要进行分片。
- 分组在一个网络中转发需要用MAC地址进行转发，因此这里要用到ARP地址转换协议，并且在一个网络中转发分组的时候MAC地址一直在变化，ip地址只在网络之间进行寻址。

![1630975641932](https://tprzfbucket.oss-cn-beijing.aliyuncs.com/hadoop/202109/07/084731-932832.png)

#### IP地址编码方式

IP 地址的编址方式经历了三个历史阶段：

- 分类
- 子网划分
- 无分类

###### 分类

由两部分组成，网络号和主机号，其中不同分类具有不同的网络号长度，并且是固定的。

IP 地址 ::= {< 网络号 >, < 主机号 >}

![1630975815682](https://tprzfbucket.oss-cn-beijing.aliyuncs.com/hadoop/202109/07/085016-150056.png)

常用三类ip地址的范围

| 网络类别 |                        | 第一个可用网络号 | 最后一个可用网络号 | 每个网络中最大主机数 |
| -------- | ---------------------- | ---------------- | ------------------ | -------------------- |
| A        | 2^7^-2                 | 1                | 126                | 2^24^-2              |
| B        | 2^14^-1，128.0不指派   | 128.1            | 191.255            | 2^16^-2              |
| C        | 2^21^-1，192.0.0不指派 | 192.0.1          | 223.255.255        | 2^8^-2               |

==特殊地址：==

- 主机号全0标示本网络本身，主机号全1标示本网络的广播地址，又叫做直接广播地址。
- 127.0.0.0标示环回测试，标示任何主机自己本身，此主机发出的分组永远不能出现在网络上。
- 32位全为0表示本网络上的本主机。
- 32位全为1表示网络的广播地址，路由器有隔离广播域的功能，因此255.255.255.255等效于本网络的广播地址。
- 网络号全0标示保留地址，意思是本网络。
- 127网络地址作为环回测试。

ip地址的特点：

1. ip地址是一种分等级的结构，由主机号和网络号组成，其中网络号由专门的管理机构分配，主机号由单位自行分配。路由器仅仅根据目的主机的网络号进行转发分组，减小了路由表所占的空间。
2. ip地址标示一台主机和一条链路的接口，当一台主机同时连接到两个网络上的时候，该主机必须有两个ip地址，每个ip地址的网络号必须和所在的网络号相同，并且两个ip地址的网络号不相同，网络上的路由器至少两个ip地址。
3. 用转发器或者网桥连接起来的网络仍然是一个网络，同一个广播域，因此一个网络中所有主机的网络号必然相同，但是主机号不一定相同。
4. 在网络中，所有分配到ip地址的主机是平等的。

###### 子网划分

- 两级的ip地址利用率很低，给每一个物理网络分配一个网络号会使路由表变大使得网络的性能变坏。
- 子网划分的思路：
  - 子网划分属于一个单位内部的事情，单位对外部仍表现为一个网络。
  - 从主机号中借出几个比特位作为子网号，从而ip地址变成了三级结构{<网络号><子网号><主机号>}
  - 凡是从其他主机发送给本单位的数据报，先按照网络号在网络中进行分组转发，最后找到目的网络后，目的网络路由器按照子网号在本网络中进行转发，最后交到目的主机。
- 地址掩码
  - 为了告诉路由器A,B,C类网络进行了子网划分，使用子网掩码来表达对源网络中主机号的借位。
  - 地址掩码只有一串1和一串0组成，其中1的个数对应于ip地址中网络号和子网号的位数，而0的个数对应于主机号的位数，ip地址只需要和子网掩码逐位相与运算就可得到相应子网的网络地址。
  - 一台主机在设置ip地址的同时，必须设置子网掩码。
  - 同属于一个子网的所有主机以及路由器端口必须设置相同的子网掩码。
  - 路由器的路由表中所包含的内容主要有{网络地址，子网掩码，下一条地址}。

通过在主机号字段中拿一部分作为子网号，把两级 IP 地址划分为三级 IP 地址。

IP 地址 ::= {< 网络号 >, < 子网号 >, < 主机号 >}

要使用子网，必须配置子网掩码。一个 B 类地址的默认子网掩码为 255.255.0.0，如果 B 类地址的子网占两个比特，那么子网掩码为 11111111 11111111 11000000 00000000，也就是 255.255.192.0。

注意，外部网络看不到子网的存在。

###### 无分类

无分类编址 CIDR 消除了传统 A 类、B 类和 C 类地址以及划分子网的概念，使用网络前缀和主机号来对 IP 地址进行编码，网络前缀的长度可以根据需要变化。

IP 地址 ::= {< 网络前缀号 >, < 主机号 >}

CIDR 的记法上采用在 IP 地址后面加上网络前缀长度的方法，例如 128.14.35.7/20 表示前 20 位为网络前缀。

CIDR 的地址掩码可以继续称为子网掩码，子网掩码首 1 长度为网络前缀的长度。

一个 CIDR 地址块中有很多地址，一个 CIDR 表示的网络就可以表示原来的很多个网络，并且在路由表中只需要一个路由就可以代替原来的多个路由，减少了路由表项的数量。把这种通过使用网络前缀来减少路由表项的方式称为路由聚合，也称为 **构成超网** 。

在路由表中的项目由“网络前缀”和“下一跳地址”组成，在查找时可能会得到不止一个匹配结果，应当采用最长前缀匹配来确定应该匹配哪一个。

无分类域间路由选择（CIDR）

- 特点：
  - 消除了传统的A,B,C类地址划分和子网掩码的概念，可以更有效的分配ipv4的地址空间，CIDR使用网络前缀的概念代替了子网的概念，因此ip地址变为两级结构{网络前缀，主机号}，使用斜线记法。
  - 将网络前缀相同的连续ip地址组成CIDR地址块，一个CIDR地址块可以表示很多ip地址，这种地址聚合称为路由聚合或者称为构造超网。
  - CIDR地址块中的地址数一定是2的整数次幂，实际可以指定的地址数是2^n^-2,n代表主机号的位数，主机号全0代表网络号，主机号全1代表广播地址。
  - 最长前缀匹配原则，使用CIDR时路由表中的每一个项目由网络前缀和下一条地址组成，在查找路由表时可能有不止一个的匹配结果，因此要选择最长匹配的网络号，应为网络号越长，对应的地址位数就越少，搜索地址范围就越小。

#### 地址解析协议 ARP

- 地址解析协议ARP
  - ip地址是网络层使用的地址，MAC地址是数据链路层和物理层使用的地址，Ip地址放在ip数据报的首部，而ip数据报作为数据部分被封装在了数据链路层的帧的数据部分，MAC地址放在mac帧的首部，数据链路层看不到封装在帧中的ip地址，由于路由器具有隔离广播域的功能，因此ip网络中无法通过MAC地址去完成分组转发的寻址功能，必须运用ip地址在网络层完成寻址，所以要用到ARP地址转换协议，把硬件地址转换为相应的ip地址完成寻址。
  - 网络上的每一台主机都要维护一个ARP高速缓存，用来存放本局域网上所有主机和路由器ip地址到MAC地址的映射，称为ARP表，ARP协议工作在网络层。
  - ARP协议用于解决同一个局域网上主机或者路由器ip地址到硬件地址的映射问题，如果所要找的主机和路由器和源主机不在同一个局域网上，那么就通过找到局域网上的一台路由器，然后把分组准发给路由器，让路由器把分组转发给下一个网络，有下一个网络来完成寻址问题。
  - 从ip地址到硬件地址的映射是自动进行的。

网络层实现主机之间的通信，而链路层实现具体每段链路之间的通信。因此在通信过程中，IP 数据报的源地址和目的地址始终不变，而 MAC 地址随着链路的改变而改变。

![1630976635373](https://tprzfbucket.oss-cn-beijing.aliyuncs.com/hadoop/202109/08/095249-387072.png)

ARP 实现由 IP 地址得到 MAC 地址。

![1630976662104](https://tprzfbucket.oss-cn-beijing.aliyuncs.com/hadoop/202109/08/095328-858192.png)

每个主机都有一个 ARP 高速缓存，里面有本局域网上的各主机和路由器的 IP 地址到 MAC 地址的映射表。

如果主机 A 知道主机 B 的 IP 地址，但是 ARP 高速缓存中没有该 IP 地址到 MAC 地址的映射，此时主机 A 通过广播的方式发送 ARP 请求分组，主机 B 收到该请求后会发送 ARP 响应分组给主机 A 告知其 MAC 地址，随后主机 A 向其高速缓存中写入主机 B 的 IP 地址到 MAC 地址的映射。

![1630976690859](https://tprzfbucket.oss-cn-beijing.aliyuncs.com/hadoop/202109/08/100125-457349.png)

#### 网际控制报文协议 ICMP

ICMP 是为了更有效地转发 IP 数据报和提高交付成功的机会。它封装在 IP 数据报中，但是不属于高层协议。

网际控制报文协议（ICMP）

- 为了让ip数据报提高交付成功的机会，在网络层使用了网际控制报文协议来报告出差错的情况，ICMP报文作为ip数据报的数据部分。加上数据报的首部，组成ip数据报发送，ICMP是网络层协议。
- ICMP有两种报文：**ICMP差错报告报文，ICMP询问报文。**
  - ICMP差错报文用于目标主机或者目标主机路径上的路由器向源主机报告差错的情况
    - 终点不可达：不能按时交付数据。
    - 源点抑制：发生拥塞。
    - 时间超时：终点收到TTL为0的数据报。
    - 参数问题：数据报首部中的字段值不正确。
    - 改变路由：路由器把改变的路由发送给源主机。
  - 不发送ICMP差错报文的情况
    - 对ICMP差错报文不在发送ICMP差错报告报文。
    - 对第一个分片的数据报片的所有后续报片都不在发送ICMP差错报文。
    - 对具有组播地址的数据报不发送ICMP差错报告报文。
    - 对具有特殊地址的数据报不发送ICMP差错报告报文。
  - ICMP询问报文有四种类型
    - 回送请求和回答报文
    - 时间戳请求和回答报文
    - 掩码地址请求和回答报文
    - 路由器询问和通告报文
  - ICMP报文最直接的应用是ping操作，使用了ICMP回送请求和回答报文，ping指令工作在应用层，他直接使用网络层的ICMP，而未使用应用层的tcp和udp。

![1630976727138](https://tprzfbucket.oss-cn-beijing.aliyuncs.com/hadoop/202109/07/090554-254614.png)

ICMP 报文分为差错报告报文和询问报文。

![1630976751887](https://tprzfbucket.oss-cn-beijing.aliyuncs.com/hadoop/202109/07/090553-515201.png)

1. Ping

Ping 是 ICMP 的一个重要应用，主要用来测试两台主机之间的连通性。

Ping 的原理是通过向目的主机发送 ICMP Echo 请求报文，目的主机收到之后会发送 Echo 回答报文。Ping 会根据时间和成功响应的次数估算出数据包往返时间以及丢包率。

2. Traceroute

Traceroute 是 ICMP 的另一个应用，用来跟踪一个分组从源点到终点的路径。

Traceroute 发送的 IP 数据报封装的是无法交付的 UDP 用户数据报，并由目的主机发送终点不可达差错报告报文。

- 源主机向目的主机发送一连串的 IP 数据报。第一个数据报 P1 的生存时间 TTL 设置为 1，当 P1 到达路径上的第一个路由器 R1 时，R1 收下它并把 TTL 减 1，此时 TTL 等于 0，R1 就把 P1 丢弃，并向源主机发送一个 ICMP 时间超过差错报告报文；
- 源主机接着发送第二个数据报 P2，并把 TTL 设置为 2。P2 先到达 R1，R1 收下后把 TTL 减 1 再转发给 R2，R2 收下后也把 TTL 减 1，由于此时 TTL 等于 0，R2 就丢弃 P2，并向源主机发送一个 ICMP 时间超过差错报文。
- 不断执行这样的步骤，直到最后一个数据报刚刚到达目的主机，主机不转发数据报，也不把 TTL 值减 1。但是因为数据报封装的是无法交付的 UDP，因此目的主机要向源主机发送 ICMP 终点不可达差错报告报文。
- 之后源主机知道了到达目的主机所经过的路由器 IP 地址以及到达每个路由器的往返时间。

#### 虚拟专用网VPN

由于 IP 地址的紧缺，一个机构能申请到的 IP 地址数往往远小于本机构所拥有的主机数。并且一个机构并不需要把所有的主机接入到外部的互联网中，机构内的计算机可以使用仅在本机构有效的 IP 地址（专用地址）。

有三个专用地址块：

- 10.0.0.0 ~ 10.255.255.255
- 172.16.0.0 ~ 172.31.255.255
- 192.168.0.0 ~ 192.168.255.255

VPN 使用公用的互联网作为本机构各专用网之间的通信载体。专用指机构内的主机只与本机构内的其它主机通信；虚拟指好像是，而实际上并不是，它有经过公用的互联网。

下图中，场所 A 和 B 的通信经过互联网，如果场所 A 的主机 X 要和另一个场所 B 的主机 Y 通信，IP 数据报的源地址是 10.1.0.1，目的地址是 10.2.0.3。数据报先发送到与互联网相连的路由器 R1，R1 对内部数据进行加密，然后重新加上数据报的首部，源地址是路由器 R1 的全球地址 125.1.2.3，目的地址是路由器 R2 的全球地址 194.4.5.6。路由器 R2 收到数据报后将数据部分进行解密，恢复原来的数据报，此时目的地址为 10.2.0.3，就交付给 Y。

![1630976849870](https://tprzfbucket.oss-cn-beijing.aliyuncs.com/hadoop/202109/07/090731-156740.png)

#### 网络地址转换NAT

网络地址转换（NAT)

- 网络地址转换是指将专网网络地址转换为公共网络地址，从而对外隐藏了内部的ip地址，它使得整个专用网只需要一个全球的ip地址就可以将专用网连接到互联网上，专用网本地的ip地址是可重用的，因此节省了ip地址的消耗。
- 全球的私有ip地址只用于局域网，不用于广域网，因此必须利用NAT转换机制把私有的ip地址转换为共有的唯一全球ip地址，全球私有ip地址：
  - 一个A类网段：10.0.0.0----10.255.255.255
  - 16个B类网段：172.16.0.0----172.31.255.255
  - 256个C类网段：192.168.0.0----192.168.255.255
- 在因特网中的所有路由器中，对目的地址是私有地址的数据报一律不进行转发，这种采用私有ip地址的网络称为专用互联网或者本地互联网，
- NAT路由器至少有一个全球的ip地址，路由器维护一个转发表，路由表中存放{本地ip地址：端口}到{全球ip地址：端口}的映射，可以让多个私有ip地址映射到一个全球唯一ip地址。
- 普通路由器在转发ip数据报的时候，不改变其源ip地址和目的ip地址，而NAT路由器在转发分组的时候要更换其源ip地址和目的ip地址，普通路由器工作在网络层，而NAT路由器还要使用传输层的端口号。

专用网内部的主机使用本地 IP 地址又想和互联网上的主机通信时，可以使用 NAT 来将本地 IP 转换为全球 IP。

在以前，NAT 将本地 IP 和全球 IP 一一对应，这种方式下拥有 n 个全球 IP 地址的专用网内最多只可以同时有 n 台主机接入互联网。为了更有效地利用全球 IP 地址，现在常用的 NAT 转换表把传输层的端口号也用上了，使得多个专用网内部的主机共用一个全球 IP 地址。使用端口号的 NAT 也叫做网络地址与端口转换 NAPT。

![1630976886637](https://tprzfbucket.oss-cn-beijing.aliyuncs.com/hadoop/202109/07/125544-315475.png)

#### 路由器的结构

路由器从功能上可以划分为：路由选择和分组转发。

分组转发结构由三个部分组成：交换结构、一组输入端口和一组输出端口。

![1630976915594](C:\Users\MrR\AppData\Roaming\Typora\typora-user-images\1630976915594.png)

#### 路由器分组转发流程

- 从数据报的首部提取目的主机的 IP 地址 D，得到目的网络地址 N。
- 若 N 就是与此路由器直接相连的某个网络地址，则进行直接交付；
- 若路由表中有目的地址为 D 的特定主机路由，则把数据报传送给表中所指明的下一跳路由器；
- 若路由表中有到达网络 N 的路由，则把数据报传送给路由表中所指明的下一跳路由器；
- 若路由表中有一个默认路由，则把数据报传送给路由表中所指明的默认路由器；
- 报告转发分组出错。

![1630976946285](https://tprzfbucket.oss-cn-beijing.aliyuncs.com/hadoop/202109/07/090908-691834.png)

#### 路由选择协议

路由选择协议都是自适应的，能随着网络通信量和拓扑结构的变化而自适应地进行调整。

互联网可以划分为许多较小的自治系统 AS，一个 AS 可以使用一种和别的 AS 不同的路由选择协议。

可以把路由选择协议划分为两大类：

- 自治系统内部的路由选择：RIP 和 OSPF
- 自治系统间的路由选择：BGP

1. 内部网关协议 RIP

RIP 是一种基于距离向量的路由选择协议。距离是指跳数，直接相连的路由器跳数为 1。跳数最多为 15，超过 15 表示不可达。

RIP 按固定的时间间隔仅和相邻路由器交换自己的路由表，经过若干次交换之后，所有路由器最终会知道到达本自治系统中任何一个网络的最短距离和下一跳路由器地址。

距离向量算法：

- 对地址为 X 的相邻路由器发来的 RIP 报文，先修改报文中的所有项目，把下一跳字段中的地址改为 X，并把所有的距离字段加 1；
- 对修改后的 RIP 报文中的每一个项目，进行以下步骤：
- 若原来的路由表中没有目的网络 N，则把该项目添加到路由表中；
- 否则：若下一跳路由器地址是 X，则把收到的项目替换原来路由表中的项目；否则：若收到的项目中的距离 d 小于路由表中的距离，则进行更新（例如原始路由表项为 Net2, 5, P，新表项为 Net2, 4, X，则更新）；否则什么也不做。
- 若 3 分钟还没有收到相邻路由器的更新路由表，则把该相邻路由器标为不可达，即把距离置为 16。

RIP 协议实现简单，开销小。但是 RIP 能使用的最大距离为 15，限制了网络的规模。并且当网络出现故障时，要经过比较长的时间才能将此消息传送到所有路由器。

2. 内部网关协议 OSPF

开放最短路径优先 OSPF，是为了克服 RIP 的缺点而开发出来的。

开放表示 OSPF 不受某一家厂商控制，而是公开发表的；最短路径优先表示使用了 Dijkstra 提出的最短路径算法 SPF。

OSPF 具有以下特点：

- 向本自治系统中的所有路由器发送信息，这种方法是洪泛法。
- 发送的信息就是与相邻路由器的链路状态，链路状态包括与哪些路由器相连以及链路的度量，度量用费用、距离、时延、带宽等来表示。
- 只有当链路状态发生变化时，路由器才会发送信息。

所有路由器都具有全网的拓扑结构图，并且是一致的。相比于 RIP，OSPF 的更新过程收敛的很快。

3. 外部网关协议 BGP

BGP（Border Gateway Protocol，边界网关协议）

AS 之间的路由选择很困难，主要是由于：

- 互联网规模很大；
- 各个 AS 内部使用不同的路由选择协议，无法准确定义路径的度量；
- AS 之间的路由选择必须考虑有关的策略，比如有些 AS 不愿意让其它 AS 经过。

BGP 只能寻找一条比较好的路由，而不是最佳路由。

每个 AS 都必须配置 BGP 发言人，通过在两个相邻 BGP 发言人之间建立 TCP 连接来交换路由信息。

![1630977015863](https://tprzfbucket.oss-cn-beijing.aliyuncs.com/hadoop/202109/07/091017-866509.png)

#### ipv6

- ipv6的主要特点
  - 更大的地址空间，从32位增大到128位，
  - 扩展的地址层次结构。
  - 灵活的首部格式。
  - 改进的选项。
  - 允许协议继续扩充。
  - 支持自动配置。
  - 支持资源的预分配。
  - ipv6只允许在源点进行分片，不允许在中间经过的路由出分片。
  - ipv6首部必须是8B的整数倍，ipv4是4B的整数倍。
  - 身份验证和保密功能是ipv6的关键特征。
- ipv6的地址
  - ipv6的目的地址可以是一下三种类型之一。
    - 单播
    - 多播：一点对多点的通信。
    - 任播：任播的目的站是一组计算机，但是数据在交付时只交给其中的一台计算机。
  - ippv6向ipv4的过度
    - 双协议栈法：在主机中配置两个协议栈。
    - 隧道技术法，将ipv6数据报封装在iPv4数据报中传输。

#### 路由算法

1. 动态路由算法（自适应路由算法），指路由器之间相互交换信息，然后按照一定的算法得出来的路由表，这些路由信息在一定时间内会不断的更新，从而适合网络的动态变化。

2. 静态路由算法（非自适应路由算法）：通过网络管理员手工进行路由信息的配置，当网络的拓扑结构发生变化时，网络管理员手工配置路由表的信息，适合小型网络。

   - 距离-向量路由算法：所有节点定期的将他们的整个路由表选择传送给所有与之直接相连的相邻节点，这种选择路由包含：

     - 每一条路径的目的地
     - 路径的代价
     - 相邻路由器所交换的是全部路由信息。

   - 链路状态路由算法：要求每个参与该算法的节点都具有完全的网络拓扑信息，他们执行两个任务：主动测试所有临接节点的路由状态，定期的将链路状态传播给所有其他的节点

     链路状态路由算法的主要特征：

     - 向本自治系统中所有的路由器发送信息，使用洪泛法，即路由器通过所有端口向所有节点发送路由信息，而每个相邻的路由器又将此信息发往其相邻的路由器。
     - 只有当链路状态发生变化时，路由器才向所有路由器发送消息。
     - 发送的消息是与路由器相邻的所有路由器的链路状态，但这只是路由器所知道的部分信息，链路装态是指本路由器与那些路由器相连以及相邻链路的状态。

   - 两种算法的比较：

     - 在距离路由向量算法中，每一个节点仅仅与他的直接相邻节点交换信息，他为他的相邻路由器提供从自己到所有其他节点的最低费用，在链路状态路由算法中，每个节点通过广播方式与其他的节点交换信息，但是仅仅告诉他们与直接相连的链路的费用，但是距离向量路由算法中会遇到环路等问题。

   - 层次路由

     - 因特网将整个网络划分成许多小的自制系统，（每一个自制系统包含许多小的局域网），每一个自制系统有权决定本自制系统内部采取什么协议，如果两个自制系统内部主机想要进行通信，就必须屏蔽掉这种差异，所以路由协议被划分成两大类。
       - 自制系统内部的协议：内部网关协议(IGP)，也叫作域内路由选择协议。
       - 自制系统之间使用的协议，外部网关协议(EGP)，也叫作域间路由选择协议，
     - 使用层次路由时候，ospf将一个自制系统划分成多个域，每个路由器都知道在本区域内部如何把分组路由到目的地的细节，但是不用知道其他区域的内部结构。

3. 内部路由选择协议（RIp和OSPF)

   1. RIP协议的特点（RIP是应用层协议，使用udp传输数据rip选择的路径比一定时间最短，一定是跳数最少）
      1. 仅仅和相邻的路由器交换信息。
      2. 路由器交换的信息是当前路由器所知道的全部信息，即自己的路由表。
      3. 按照固定的时间间隔交换路由信息。
      4. 通过RIP收敛以后，每一个路由器到每一个目标网络的路由都是距离最短的（即跳数最少）.
   2. RIP的缺点
      1. RIP限制了网络的规模，他可以使用的最大规模为15跳。
      2. 路由器中交换的是路由器中整个的路由表，因此网络规模越大，开销就越大。
      3. 网络出现故障时，会出现慢收敛的现象，（即需要很长时间需要将信息传输到所有的路由器），也叫作坏消息传输的慢，使得网络的收敛时间过长。

4. 开放最短路径优先（OSPF）协议

   1. 特点：
      1. OSPF向本自制系统中所有的路由器发送消息，这里使用的是洪泛法，而rip仅仅向相邻的路由器发送消息。
      2. 发送的消息是与本路由器相邻的所有路由器的链路状态，但这只是路由器所知道的部分信息，“链路状态”说明本路由器和那些路由器相邻以及该链路的度量代价，而在rip中，所发送的信息是本路由器所知道的全部信息。
      3. 只有当链路状态发生变化时路由器才使用洪泛法向所有路由器发送信息，并且更新过程很慢，不会出现坏消息发送的慢的情况。但是这里交换信息仅仅是发送变化部分的信息。
      4. OSPF是网络层协议，直接使用ip发送数据报传输，而RIP是应用层协议，使用传输层的UDP.
   2. OSPF的工作原理：
      1. 由于各个路由器之间频繁的交换路由信息，因此所有的路由器都建立了一个链路状态数据库，这个数据库实际上是全网的拓扑结构，在全网内是唯一的，然后根据全网络的拓扑结构，用地杰斯特拉算法计算从自己到各个路由器的最佳路径，从而构造路由表，使用算法构造的路由表，存储的不是完整的路径，而是下一跳地址，而OSPF还把一个自制系统划分成许多的域，使用洪泛法交换信息时候，每个路由器交换的链路状态信息仅仅局限于每一个区域内部，而不是整个自制系统，减少了整个网络的通信量，在一个区域内部的路由器仅仅知道本区域网络的拓扑结构，。

5. 外部网关协议（BGP)

   - 外部网关协议只能力求寻找一条能够到达目的网络比较好的路径，而不是寻找一条最佳路径，BGP采用路径向量路由选择协议，BGP是应用层协议，是基于TCP的协议。

   1. BGP的工作原理
      - 每一个自制系统至少选择一个路由器作为该系统的“BGP发言人”，一个系统的bgp发言人和其他系统的发言人交换信息，就是要先建立tcp连接，然后再连接之上交换BGP报文进行会话，当所有发言人都相互交换网络的可达性信息之后，各个发言人可以找到到达各个自制系统的较好的路由。每一个BGP发言人除了运行外部网关协议，还要运行本自制系统内部的协议。
   2. BGP的特点
      1. BGP交换路由的信息的节点数量级是自制系统的数量级，这比自制系统中的网络数少很多。
      2. 每一个自制系统中的发言人很少，这样自制系统之间的路由选择协议不是很复杂。
      3. BGP协议支持CIDR。

   

| 协议     | RIP                      | OSPF                                 | BGP                                    |
| -------- | ------------------------ | ------------------------------------ | -------------------------------------- |
| 类型     | 内部                     | 内部                                 | 外部                                   |
| 路由算法 | 距离向量                 | 链路状态                             | 距离向量                               |
| 传递协议 | UDP                      | IP                                   | TCP                                    |
| 路径选择 | 跳数最少                 | 代价最低                             | 较好，非最佳                           |
| 交换节点 | 和本节点的相邻节点路由器 | 网络中的所有路由器                   | 和本节点相邻路由器                     |
| 交换内容 | 当前路由器的路由表       | 与本路由器相邻的所有路由器的链路状态 | 首次：整个路由表，非首次：有变化的部分 |

### 数据链路层

**大图**

![1630995518777](https://tprzfbucket.oss-cn-beijing.aliyuncs.com/hadoop/202109/07/141840-723813.png)

**数据链路层(data link layer)通常简称为链路层。两台主机之间的数据传输，总是在一段一段的链路上传送的，这就需要使用专门的链路层的协议。** 在两个相邻节点之间传送数据时，**数据链路层将网络层交下来的 IP 数据报组装成帧**，在两个相邻节点间的链路上传送帧。每一帧包括数据和必要的控制信息（如同步信息，地址信息，差错控制等）。

在接收数据时，控制信息使接收端能够知道一个帧从哪个比特开始和到哪个比特结束。这样，数据链路层在收到一个帧后，就可从中提出数据部分，上交给网络层。
控制信息还使接收端能够检测到所收到的帧中有无差错。如果发现差错，数据链路层就简单地丢弃这个出了差错的帧，以避免继续在网络中传送下去白白浪费网络资源。如果需要改正数据在链路层传输时出现差错（这就是说，数据链路层不仅要检错，而且还要纠错），那么就要采用可靠性传输协议来纠正出现的差错。这种方法会使链路层的协议复杂些。

> 小结：
>
> 1. 为网络层提供服务
>    - 数据链路层在物理层的基础之上向网络层提供服务，主要是加强物理层传输原始比特流的功能，将物理层提供的可能出错的物理连接改造为逻辑上无差错的数据链路。主要三种服务：无确认无连接的服务，有确认无连接的服务，有确认面向连接的服务。
> 2. 链路管理
> 3. 帧定界，帧同步，透明传输
> 4. 透明传输(比特填充，字符填充，字符计数法，违规编码法)
> 5. 差错控制（循环冗余码）

#### 基本问题

1. 封装成帧

将网络层传下来的分组添加首部和尾部，用于标记帧的开始和结束。

![1630930521913](https://tprzfbucket.oss-cn-beijing.aliyuncs.com/hadoop/202109/06/201522-205008.png)

2. 透明传输

透明表示一个实际存在的事物看起来好像不存在一样。

帧使用首部和尾部进行定界，如果帧的数据部分含有和首部尾部相同的内容，那么帧的开始和结束位置就会被错误的判定。需要在数据部分出现首部尾部相同的内容前面插入转义字符。如果数据部分出现转义字符，那么就在转义字符前面再加个转义字符。在接收端进行处理之后可以还原出原始数据。这个过程透明传输的内容是转义字符，用户察觉不到转义字符的存在。

![1630930555072](https://tprzfbucket.oss-cn-beijing.aliyuncs.com/hadoop/202109/06/201555-931441.png)

3. 差错检验

目前数据链路层广泛使用了循环冗余检验（CRC）来检查比特差错。

#### 信道分类

1. 广播信道

一对多通信，一个节点发送的数据能够被广播信道上所有的节点接收到。

所有的节点都在同一个广播信道上发送数据，因此需要有专门的控制方法进行协调，避免发生冲突（冲突也叫碰撞）。

主要有两种控制方法进行协调，一个是使用**信道复用技术，一是使用 CSMA/CD 协议**。

2. 点对点信道

一对一通信。

因为不会发生碰撞，因此也比较简单，使用 PPP 协议进行控制。

#### 信道复用技术

- 频分多路复用（FDM）
- 时分多路复用（TDM）
- 波分多路复用（WDM)
- 码分多路复用（CDM）

1. 频分复用

频分复用的所有主机在相同的时间占用不同的频率带宽资源。

![1630930676263](https://tprzfbucket.oss-cn-beijing.aliyuncs.com/hadoop/202109/06/201757-584488.png)

2. 时分复用

时分复用的所有主机在不同的时间占用相同的频率带宽资源。

![1630930705493](https://tprzfbucket.oss-cn-beijing.aliyuncs.com/hadoop/202109/06/201827-15220.png)

使用频分复用和时分复用进行通信，在通信的过程中主机会一直占用一部分信道资源。但是由于计算机数据的突发性质，通信过程没必要一直占用信道资源而不让出给其它用户使用，因此这两种方式对信道的利用率都不高。

3. 统计时分复用

是对时分复用的一种改进，不固定每个用户在时分复用帧中的位置，只要有数据就集中起来组成统计时分复用帧然后发送。

![1630930744024](https://tprzfbucket.oss-cn-beijing.aliyuncs.com/hadoop/202109/06/201905-179684.png)

4. 波分复用

光的频分复用。由于光的频率很高，因此习惯上用波长而不是频率来表示所使用的光载波。

5. 码分复用

![1630930795725](https://tprzfbucket.oss-cn-beijing.aliyuncs.com/hadoop/202109/06/201957-142860.png)

码分复用需要发送的数据量为原先的 m 倍

![1630930818562](https://tprzfbucket.oss-cn-beijing.aliyuncs.com/hadoop/202109/06/202019-51207.png)

#### CSMA/CD 协议

CSMA/CD 表示载波监听多点接入 / 碰撞检测。

- **多点接入** ：说明这是总线型网络，许多主机以多点的方式连接到总线上。
- **载波监听** ：每个主机都必须不停地监听信道。在发送前，如果监听到信道正在使用，就必须等待。
- **碰撞检测** ：在发送中，如果监听到信道已有其它主机正在发送数据，就表示发生了碰撞。虽然每个主机在发送数据之前都已经监听到信道为空闲，但是由于电磁波的传播时延的存在，还是有可能会发生碰撞。

记端到端的传播时延为 τ，最先发送的站点最多经过 2τ 就可以知道是否发生了碰撞，称 2τ 为 **争用期** 。只有经过争用期之后还没有检测到碰撞，才能肯定这次发送不会发生碰撞。

当发生碰撞时，站点要停止发送，等待一段时间再发送。这个时间采用 **截断二进制指数退避算法** 来确定。从离散的整数集合 {0, 1, .., (2k-1)} 中随机取出一个数，记作 r，然后取 r 倍的争用期作为重传等待时间。

![1630930910145](https://tprzfbucket.oss-cn-beijing.aliyuncs.com/hadoop/202109/06/202150-51236.png)

#### 介质访问控制

介质访问控制层的任务：为使用介质的每个节点隔离来自同一条信道上面其他节点所传送的信号，以协调节点的传输，用来决定广播信道中信道的分配的协议属于数据链路层的一个子层，称为介质访问控制（MAC），常用的有三种，信道划分介质访问控制，随机访问介质访问，轮询访问介质访问控制。

1. 信道划分介质访问控制：

   - 频分多路复用（FDM）
   - 时分多路复用（TDM）
   - 波分多路复用（WDM)
   - 码分多路复用（CDM）

2. 随机访问介质访问控制

   1. ALOHA协议：

      - 纯ALOHA协议：当网络中任何一个站点要发送数据时，不需要监听就可以直接发送，当遇到冲突就随机等待一个时间继续发送数据，
      - 时隙ALOHA协议：时隙的ALOHA协议把许多站点的时间同步起来，划分成许多的时间片，每个站点发送数据只在时间片内，每个站点刚好可以在一个时间片内发送完数据，如果发生碰撞，等待若干个时间片继续发送。

   2. CSMA协议：

      - 如果每个站点在发送数据前先监听一下信道是否空闲，如果空闲就发送数据，否则等待随机时间在发送，根据监听方式和监听到信道空闲时处理方式不同分为三种：

        - 1坚持：监听到信道空闲立即发送数据，信道忙的话则等待，1坚持中的1是信道空闲就立即发送，信道忙就等待。

          note:传播时延对1坚持影响较大。

        - 非坚持：监听到信道空闲就立即发送数据，监听到信道忙就放弃监听，等待一个时间继续发送数据。

          note:非坚持在监听到信道忙后就立即放弃监听，这避免了多个信道同事发送产生碰撞的概率，但是大大增加了数据的传播时延。

        - p坚持，监听到信道空闲后就以概率p发送数据，以概率1-p推迟一个时隙发送数据，监听到信道忙后，就等待一个时隙继续监听，p坚持是1坚持和非坚持的折中。

        | 信道状态 | 1坚持        | 非坚持                         | p坚持                                      |
        | -------- | ------------ | ------------------------------ | ------------------------------------------ |
        | 空闲     | 立即发送数据 | 立即发送数据                   | 以概率p发送数据，1-p推迟下一个时隙发送数据 |
        | 忙       | 继续监听信道 | 放弃监听，推迟一个时隙继续监听 | 持续监听                                   |

   3. CSMA/CD协议（载波监听，多路碰撞，碰撞检测）

      1. CSMA/CD协议在发送数据前先监听信道是否空闲，如果信道空闲就立即发送数据，一边发送数据一边监听信道，如果信道空闲就停止发送数据，用二进制退避算法等待一个时隙继续监听信道发送数据。所以协议的工作方法可以概括为先听后发，边听边发，但是总线的传播时延对协议的影响很大。
         - 设想一下这种情况，A向B发送数据，假设单程时延为a,A在t=0开始发送数据，而B在a-b时检测到信道空闲，于是开始发送数据，经过b/2时间，B检测到信道发生碰撞，于是停止发送数据，而A在2a-b时间检测到了信道发生碰撞，于是停止发送数据，所以，由于信道传播的时延会对两端检测到信道是否发生碰撞有很大的影响，所以csma/cd协议不能支持全双工通信，只能在半双工下通信。以上讨论中，由于A在2a-b时间没检测到信道发生碰撞，所以，假设在b很小的情况下，A在2a时间内，也就是信道的往返时间就可以检测到信道是否发生碰撞，如果在往返时间2a内没有发生碰撞，在以后A发送数据是不可能发生碰撞的，所以往返时间2a也称为争用期，如果在争用期内没有发生碰撞，那么A就占据了信道的使用权，以后发生数据不可能在发生碰撞，为了在A发送完数据之前就可以监听到信道是否发生了冲突，即帧的传输时延最少两倍于帧在信道上面的传播时延，所以就产生了最小帧长度概念，如果在帧发送完前监听到信道忙，就立即放弃发送，由此得到最小帧长度是=总线传播时延*2*数据传输速率。

      ![1630980507445](https://tprzfbucket.oss-cn-beijing.aliyuncs.com/hadoop/202109/07/100828-687709.png)

      1. 退避算法：

         1. CSMA/CD协议在发生冲突时执行二进制退避算法，具体如下：

            - 一般取总线的往返时间作为争用期。
            - 定义参数k作为重传的次数。但是k不超过10，k=min[重传次数，10]，当重传次数大于10的时候，k就等于10不在变化。
            - 从离散集合[0,1,2........2^k^-1]中选取一个数r,重传的退避时间就是r倍的基本退避时间，2ra。
            - 当重传达到16此仍然不能成功时，就认为网络拥挤，向高层报告出错。

            二进制退避算法的好处：使用二进制退避算法重传所需要的时间随着重传的次数而增大，可以大大降低发生碰撞的概率，所以也称为动态退避算法。

   4. CSMA/CA协议

      1. CSMA/CD协议应用于有线的局域网，但是在无线局域网应用上，使用CSNA/CD协议在碰撞检测方面不是很好，主要有两个原因：
         - 接收信号的强度往往会远远小于发送信号的强度，信号在无线的介质上传输变化失真很大，因此去检测无线信道是否发生碰撞代价很大。
         - 在无线局域网中并非所有的站都可以听见对方，即存在隐蔽站问题。
      2. 无线局域网使用CSMA/CA协议，尽量在传输数据过程中避免碰撞，而不是检测碰撞，当发生碰撞时，该协议也使用二进制退避算法来处理。
         - 避免碰撞的方法：
           预约信道，在发送数据的站点发送数据前先向信道上其他主机通知自己所要发送数据的长度，以便让其他站点在此时间不要发送数据来避免碰撞。
         - ACK帧，所有的站点在收到向自己发送的数据以后都要返回一个确认帧给发送站，发送站才可以继续发送数据，如果发送站在规定时间内没有收到确认帧的话，就重新发送数据帧。
         - RTS/CTS主要用来解决隐蔽站的问题。
      3. CSMA/CA和CSMA/CD协议的区别：
         - csma/cd协议是检测冲突，检测到冲突以后就立即停止发送数据等到信道空闲时再发送数据，但是无法避免冲突，而csma/ca协议是尽最大努力避免冲突，信道上有冲突，但尽力避免。
         - 传输介质不同：csma/cd协议使用总线型以太网，而csma/ca协议用无线局域网802.11a/b/g/n.
         - 检测方式不同：csma/cd协议使用电缆中的电压范围来检测，而csma/ca协议使用能量检测，载波检测，能量载波混合检测方式等。
         - 而csma/ca协议在本节点出没有冲突，但是不带表在其他节点处也没有冲突。
      4. 而csma/ca协议的思想是在发送数据前通知其他节点自己要发送数据，不允许其他节点也发送数据，csma/cd协议思想是在发送数据前先监听，没有冲突就发送数据，有冲突等待。

   5. 轮询访问介质访问控制，令牌传递协议，主要用在令牌环局域网中。

      - 局域网中有一个帧充当令牌，没有数据帧时再各个主机之间相互传递，当有主机要发送数据时就获得令牌，而在此期间其他主机没有获得令牌不允许发送数据，当令牌传递回发送方时，由发送方来撤销该帧，释放令牌供其他主机来使用，传输介质物理上不必是一个环，但是逻辑上必须是一个环。

#### 流量控制与可靠传输

流量控制：流量控制是端到端直接的流量控制（注意和拥塞控制区分），是指限制发送端向网络上发送数据的速率使得接收端来得及接收数据，是局部性问题，而非全局问题，常见有停止等待协议，活动窗口协议。

- 停止等待协议停止等待协议相当于发送端和接收端维持的窗口都是1，发送端每发送一个帧，都要等待接收端返回一个确认帧以后再发送下一帧。

  - 在停止等待协议中可能出现两种差错：
    - 到达接收端的帧后帧被破坏，那么接收端就简单的丢弃帧即可，所以此时在发送端要维持一个计时器，等到超时没有收到接收端发送的确认帧后就重新传输此帧。
    - 另一种情况是接收端返回的确认帧在返回的途中被破坏，此种情况发送端也收不到确认帧，因此会进行超时重传，这种情况接收端会收到重复帧，会简单的丢弃，重新返回一个确认帧，但重新发送的确认帧需用ack0和ack1来标示，接收端在收到有误的确认帧，就重新传输此数据帧。

- 后退N帧协议（GBN）

  为了解决单帧确认中效率低下的问题，有了后退N帧协议，后退N帧协议运行发送端每次发送多个数据帧，不必等待接收方发送一个确认帧之后再发送数据帧，当接收方收到失序的数据帧以后，要求发送方重新发送最后的一个确认帧后未确认的帧，或者当发送方发送了n个帧以后，发现该n个帧的前一个帧在计时器超时后没有按时返回确认帧，就认为n个帧前的帧全部丢失，于是重新发送n帧以前的帧以及这n个帧，接收方只允许接收按顺序到达的帧，在这种协议下，相当于发送方维持的发送窗口大于1，而接收窗口的值为1.后退N帧协议的接收窗口大小为1，保证接收方只能按顺序接收帧，如果采用n比特对帧进行编号，发送窗口的大小为1<=W~t~<=2^n^-1。

  - 缺点：当信道的传输质量不高时，会导致重传许多帧，因此信道质量不好时用后退N帧协议还不如停止单帧确认的协议好。

- 选择重传协议（SR）

  为进一步提高信道利用率，可以设法只重新传输出现差错的帧，但有必须加大接收窗口的缓存空间，ARQ协议要求为每个发送缓冲区设置一个计时器，当缓冲区的帧出现超时时候，就会重新传输此帧。一旦接收方发现帧出错，就会发送一个出错NAK帧，要求发送方对出错的帧进行重传。

  - 选择重传协议的发送窗口和接收窗口都大于1，一次可以发送和接收多个帧，若果采用n比特对帧编号，那么接收窗口和发送窗口的大小为W~tmax~=W~rmax~=2^n-1^.

- 信道的利用率：在一个周期内实际发送数据的时间/周期。

  - =(L/C)/T,L是在一个周期内实际发送的比特数，C是数据发送率,T是周期。
  - 信道吞吐率=信道利用率*发送方的发送速率。

#### PPP协议

互联网用户通常需要连接到某个 ISP 之后才能接入到互联网，PPP 协议是用户计算机和 ISP 进行通信时所使用的数据链路层协议。

![1630930949224](https://tprzfbucket.oss-cn-beijing.aliyuncs.com/hadoop/202109/06/202230-964778.png)

PPP 的帧格式：

- F 字段为帧的定界符
- A 和 C 字段暂时没有意义
- FCS 字段是使用 CRC 的检验序列
- 信息部分的长度不超过 1500

![1630930972441](https://tprzfbucket.oss-cn-beijing.aliyuncs.com/hadoop/202109/06/202253-195710.png)

#### MAC地址

MAC 地址是链路层地址，长度为 6 字节（48 位），用于唯一标识网络适配器（网卡）。

一台主机拥有多少个网络适配器就有多少个 MAC 地址。例如笔记本电脑普遍存在无线网络适配器和有线网络适配器，因此就有两个 MAC 地址。

#### 局域网

1. 概念:局域网是指在一个较小的地理范围内，将各种计算机，外部设备，和数据库系统等通过双绞线电缆等连接起来，组成资源和信息共享的计算机互连网络。

2. 主要特点：

   - 局域网常常为一个单位所有，并且在地理范围内站点个数有限。
   - 所有站点共享较高的总带宽。
   - 较低的时延和误码率。
   - 各个站点是平等关系而非主从关系。
   - 可以进行广播和组播。

3. 局域网的三个决定要素：拓扑结构，传输介质，和介质访问控制方式

   三种局域网的拓扑结构：星型结构，总线型结构，环形结构，

   局域网的介质访问控制方式有：CSMA/CD协议，令牌总线和令牌环，前两种主要用于总线型，后一种用于环形。

   两种特殊局域网的拓扑结构实现：以太网，逻辑拓扑总线型，物理拓扑星型的。

   令牌环，逻辑拓扑环形，物理拓扑星型。

   局域网只使用iso参考模型的下两层：数据链路层和物理层。其中在链路层又分为逻辑链路控制（LLC）和介质访问控制子层，与接入传输媒体有关的内容都放在传输媒体自层，主要功能包括：组帧和拆卸帧，比特传输和差错检验，透明传输，LLC子层与传输媒体媒体无关，他向网络层提供无确认无连接，面向连接，待确认无连接，高速传输等四种不同连接服务。

主要有以太网、令牌环网、FDDI 和 ATM 等局域网技术，目前以太网占领着有线局域网市场。

可以按照网络拓扑结构对局域网进行分类：

![1630974428337](https://tprzfbucket.oss-cn-beijing.aliyuncs.com/hadoop/202109/07/082709-310673.png)

1. 以太网和ieee 802.3

   1. 以太网采用无连接的工作方式，不对发送的数据帧进行编号，也不要求你

      接收方返回确认帧，即以太网提供尽最大努力的交付，提供不可靠的服务对于差错的纠正由高层来处理。

   2. 一台网传输介质： 

      - 10base5:粗缆，总线型拓扑结构，最大长度500米。
      - 10base2:细缆，总线型拓扑结构，最大长度185米。
      - 10base-T:非屏蔽双绞线，星型拓扑结构，最大长度100米。
      - 10base-fl:光纤，点对点通信，最大长度2000米。

   3. 以太网的MAC帧：每一块网络适配器都有一个6字节MAC硬件地址，高24位是厂商的代码，低24位有厂商进行自行分配。由于以太网使用的是广播通信，因此以太网的网卡每收到一个MAC帧，首先用硬件检查帧中的MAC地址，如果发往本站就收下，否则就丢弃。

      以下就是以太网的帧格式，前面8个字节中有7个字节是前同步码，后面一个字节是真开始定界附，以太网帧不需要帧结束符，应为以太网发送帧的时候会每隔一个间隙在发送帧，所以连续收到的比特流一定属于同一个帧。

      ![1630980642250](https://tprzfbucket.oss-cn-beijing.aliyuncs.com/hadoop/202109/07/101044-386127.png)

   4. 高速以太网：速率达到100Mb/s的以太网称为高速以太网。

      - 100BASE-T以太网：是在双绞线上传送100MB/s的基带信号，拓扑结构是星型，使用CSMA/CD协议，这种以太网可以再全双工和半双工下工作，在全双工下不使用CSMA/CD协议。
      - 吉比特以太网：速率达到1Gb/s的以太网称为吉比特以太网，这种以太网可以再全双工和半双工下工作，在全双工下不使用CSMA/CD协议，在半双工下使用CSMA/CD协议。
      - 10吉比特以太网：10吉比特以太网用光纤作为传输媒体，但是只能在全双工方式下工作，不使用CSMA/CD协议。

2. 无线局域网（有固定基础设施的无线局域网和无固定基础设施无线局域网自组织网络）

   1. 令牌环网：令牌环网的每一站通过电缆与环接口干线耦合器（TCU)相连接，TCU主要作用是传递所有经过的帧，为接入站发送和接收数据提供接口，TCU的状态也有两个，收听状态和发送状态，数据总是在某个特定的方向上从上一个TCU到下一个TCU逐比特的发送信息，每一个TCU重新产生并且重传每一个比特，令牌环网的令牌是一个特殊的帧，本身并不包含数据，仅仅是控制信道的使用，确保同一时刻仅有一台主机独占信道，，因此令牌环网不会发生碰撞。

      令牌环网在物理上是星型结构，但逻辑上是环形结构。

#### 以太网

以太网是一种星型拓扑结构局域网。

早期使用集线器进行连接，集线器是一种物理层设备， 作用于比特而不是帧，当一个比特到达接口时，集线器重新生成这个比特，并将其能量强度放大，从而扩大网络的传输距离，之后再将这个比特发送到其它所有接口。如果集线器同时收到两个不同接口的帧，那么就发生了碰撞。

目前以太网使用交换机替代了集线器，交换机是一种链路层设备，它不会发生碰撞，能根据 MAC 地址进行存储转发。

以太网帧格式：

- **类型** ：标记上层使用的协议；
- **数据** ：长度在 46-1500 之间，如果太小则需要填充；
- **FCS** ：帧检验序列，使用的是 CRC 检验方法；

![1630974506499](https://tprzfbucket.oss-cn-beijing.aliyuncs.com/hadoop/202109/07/082827-506539.png)

#### 广域网

1. 广域网通常是指覆盖范围很广的长距离网络，广域网是因特网的核心部分，其任务是长距离运送主机发送的数据，但是广域网不等于互联网，互联网可以连接各种异构的网络（即可以连接局域网，又可以连接广域网），通常使用路由器来连接，广域网由一些节点交换机和连接这些节点交换机的链路组成，（节点交换机是在单个的网络中转发分组，而路由器是在多个异构的网络之间转发分组，）节点之间都是点到点的连接，通常一个节点交换机和多个节点交换机相连接。

   |          | 广域网                                                       | 局域网                   |
   | -------- | ------------------------------------------------------------ | ------------------------ |
   | 覆盖范围 | 很广，通常是跨区域                                           | 很小，通常在一个区域内   |
   | 连接方式 | 节点之间都是点到点的连接，但为了可靠性，一个节点往往和多个节点交换机相连接 | 普遍采用多点接入的方式   |
   | osi层次  | 三层：网络层，数据链路层，物理层                             | 两层：数据链路层，物理层 |
   | 着重点   | 强调资源共享                                                 | 强调数据传输             |

   共同点：广域网和局域网都是互联网的重要组成部分，从互联网角度看，二者是平等关系，非包含关系。连接在一个局域网或者一个广域网上的主机在通信时仅仅使用物理地址。

2. 两个典型的协议（ppp协议和hdlc协议）

   - ppp协议：ppp协议是串行通路的面向字节的协议

     组成：链路控制协议（LCP）,一种扩展的链路控制协议，用于建立，配置，测试和管理数据连接。

     ​	网际控制协议（NCP），ppp协议允许同时采用多种网络层协议，每个不同的网络层协议都要一个相应的

     NCP来配置，为网络层协议建立和配置逻辑连接。

     一个将ip数据报封装到串行的方法：ip数据报被封装到ppp帧的数据部分，这个数据部分受到MTU的限制。

   - 特点：

     - ppp协议是点对点的，并不是总线型，因此不需要CSMA/CD协议。
     - ppp协议提供检错功能但是不提供纠错功能，只能保证无差错接收，是不可靠的传输协议，因此也没有序号和确认机制。
     - ppp协议是在全双工方式下工作。
     - ppp协议两端的网络层可以运行不同的协议，但仍然可以使用ppp协议进行通信。
     - ppp协议是面向字节的协议，因此可以使用两种透明传输机制，字节填充和字符填充。

   - HDLC协议（高级数据链路控制）

     - 高级数据链路控制是iso制定的面向比特的数据链路层协议，在全双工方式写通信，有较高的数据传输速率，采用crc冗余检验，对帧进行编号，防止漏发或者重发，传输的可靠型比较高。

     - 两种基本配置：

       - 非平衡配置的特点是一个主站控制整个链路工作。
       - 平衡配置的特点是链路两端的两个站是复合站，每一个站都可以平等的发送数据和传输数据，而不需要得到对方的认可。

     - 站：主站：主站控制链路层的操作，主站发出的帧为命令帧，从站受控于主站，按照主站命令进行操作，发出的帧为相应帧，复合站就可以发送命令，又可以相应命令。

     - 数据操作方式：

       - 正常相应方式：是一种非平衡结构的操作方式，即主站传输数据，从站接收数据，但是只有通过主站的允许后从站才可以接收数据。
       - 异步平衡方式：是一种平衡的操作方式，这种方式两端的复合站都可以传送和接收数据。
       - 异步相应方式：是一种非平衡的操作方式，从站即使未得到主站的允许，也可以接收数据。

     - 帧格式：

       !["hdlc帧"的图片搜索结果](https://tprzfbucket.oss-cn-beijing.aliyuncs.com/hadoop/202109/07/101216-289971.png)

       - HDLC有三种帧：
         - 信息帧：第一位是0，用来传输数据或者用捎带确认技术对帧进行确认。
         - 监督帧：第一二位是10，用来流量控制，差错控制，执行对信息帧的确认请求重发和暂停等功能。
         - 无编号帧：第一二位全是1，用来建立连接拆除连接等。

     - ppp和HDLC的对比

       - ppp协议是面向字节的，HDLC是面向比特的。
       - ppp帧比HDLC帧多了两个字节的协议字段。
       - ppp帧不使用确认和序号，只保证无差错的接收，而端到端的差错由高层来保证，HDLC使用序号和确认机制，保证了端到端的可靠传输。

#### 交换机

交换机具有**自学习能力**，学习的是交换表的内容，交换表中存储着 MAC 地址到接口的映射。

正是由于这种自学习能力，因此交换机是一种即插即用设备，不需要网络管理员手动配置交换表内容。

下图中，交换机有 4 个接口，主机 A 向主机 B 发送数据帧时，交换机把主机 A 到接口 1 的映射写入交换表中。为了发送数据帧到 B，先查交换表，此时没有主机 B 的表项，那么主机 A 就发送广播帧，主机 C 和主机 D 会丢弃该帧，主机 B 回应该帧向主机 A 发送数据包时，交换机查找交换表得到主机 A 映射的接口为 1，就发送数据帧到接口 1，同时交换机添加主机 B 到接口 2 的映射。

![1630975232087](https://tprzfbucket.oss-cn-beijing.aliyuncs.com/hadoop/202109/07/084033-886686.png)

#### 数据链路层设备

**网桥的概念及其基本原理**

- 两个或多个以太网通过网桥连接起来后，就成为一个覆盖范围更大的以太网，而原来的每个以太网就可称为一个网段. 网桥工作在链路层的MAC 子层，可以便以太网各网段成为隔离开的碰撞域。如果把网桥换成工作在物理层的转发器，就没有这种过滤通信的功能。由于各网段的相对独立， 一个网段的故障不会影响到另一个网段的运行。
- 注意:网桥处理数据的对象是帧，所以它是工作在数据链路层的设备，中继器、放大器处理数据的对象是信号， 所以它是工作在物理层的设备.
- 网络l 和网络2 通过网桥连接后，网桥接收网络1发送的数据帧，检查数据帧中的地址， 如果是网络2 的地址，就转发给网络2; 如果是网络1 的地址，就将其丢弃，因为源站和目的站处在同一个网段，目的姑能够直接收到这个帧而不需要借助网桥的转发。

**网桥的基本特点**

- 网桥的基本特点: ①网桥必须具备寻址和路径选择能力，以确定帧的传输方向: ②从源网络接收帧，以目的网络的介质访问控制协议向目的网络转发该帧: ③网桥在不同或相同类型的LAN之间存储并转发帧，必要时还进行链路层上的协议转换。提醒读者， 一般情况下，存储转发类设备都可以进行协议转换， 即连接的两个问段可以使用不同的协议:④网桥对所接收到的帧不做任何修改，或只对帧的封装格式做很少的修改: ⑤网桥可以通过执行帧翻译互联不同类型的局域网，即把原协议的信息段的内容作为另一种协议的信息部分封装在帧中: ⑥网桥应有足够大的缓冲空间， 因为在短时间内帧的到达速度可能高于转发速度。
- 网桥的优点: ①过滤通信量;②扩大了物理范围:③可使用不向的物理层: @可互联不同类型的局域网: ⑤提高了可靠性;⑥性能得到改善。
- 网桥的缺点:①增加时延:②MAC 子层没有流量控制功能(流址控制需要用到编号机制，编号机制的实现在LLC 子层) : ③不同MAC 子层的网段桥接在一起时，帧格式的转换: ④网桥只适合于用户数不多和通信量不太大的局域网，否则有时还会因传播过多的广播信息而产生网络拥塞，这就是所谓的广播风暴。
- 网桥必须具有路径选择的功能，当接收到帧后，要决定正确的路径，将该帧转送到相应的目的局域网站点。根据路径选择算法的不同，可将网桥分为透明网桥和源路由网桥。

**局域网交换机及其工作原理**

1. 局域网交换机

   - 桥接器的主要限制是在任一时刻通常只能执行一个帧的转发操作，于是就出现了局域网交换机，又称以太网交换机.从本质上说，以太网交换机就是一个多端口的网桥，工作在数据链路层。交换机能经济地将网络分成小的冲突域，为每个工作站提供更高的带宽。
   - 以太网交换机对工作站是透明的，这样管理开销低廉，简化了网络结点的增加、移动和网络变化的操作。利用以太网交换机还可以很方便地实现虚拟局域网( Virtual LAN, VLAN) ，VLAN不仅可以隔离冲突域，也可以隔离广播域。

2. 原理

   以太网交换机的原理是， 它检测从以太端口来的数据帧的源和目的地的MAC ( 介质访问层〉地址，然后与系统内部的动态查找表进行比较，若数据帧的MAC 地址不在查找表中，则将该地址加入查找表中，并将数据帧发送给相应的目的端口。

3. 特点

   - 以太网交换机的特点如下:
     1)以太网交换机的每个端口都直接与单个主机相连(普通网桥的端口往往是连接到以太网的一个网段)，并且一般都工作在全双工方式.
     2) 以太网交换机能同时连通许多对的端口，使每一对相互通信的主机都能像独占通信媒体那样，无碰撞地传输数据。
     3) 以太网交换机也是一种即插即用设备(和透明网桥一样)，其内部的帧的转发表也是通过自学习算法自动地逐渐建立起来的。

     4)以太网交换机由于使用了专用的交换结构芯片，其交换速率较高.
     5) 以太网交换机独占传输媒体的带宽.

   - 对于普通10Mb危的共享式以太网，若共有N 个用户，则每个用户占有的平均带宽只有总带宽( 10Mb/s ) 的N 分之一。在使用以太网交换机时，虽然在每个端口到主机的带宽还是10Mb危，但由于一个用户在通信时是独占而不是和其他网络用户共享传输媒体的带宽，因此对于拥有N 对端口的交换机的总容量为N>< 10Mb/so 这正是交换机的最大优点.以太网交换机一般都具有多种速率的端口，例如，可以具有10Mb/s ， IOOMb/s 和1 Gb/s 的端口的各种组合， 这就大大方便了各种不同情况的用户.

4. 两种交换模式

   - 目前，以太网交换机主要采用两种交换模式，即直通式和存储转发式。
     1. 直通式交换机只检查帧的目的地址，这使得帧在接收后几乎能马上就被传出去。这种方式速度很快， 但缺乏智能性和安全性，也无法支持具有不同速恕的端口的交换.
     2. 存储转发式交换机先将接收到的帧缓存到高速缓存器中，并检查数据是否正确，确认无误后通过查找表转换成输出端口将该帧发迭出去. 如果发现帧有错，就将其丢弃。存储转发式的优点是可靠性高并能支持不同速度端口间的转换，缺点是延迟较大.

#### 虚拟局域网

虚拟局域网可以建立与物理位置无关的逻辑组，只有在同一个虚拟局域网中的成员才会收到链路层广播信息。

例如下图中 (A1, A2, A3, A4) 属于一个虚拟局域网，A1 发送的广播会被 A2、A3、A4 收到，而其它站点收不到。

使用 VLAN 干线连接来建立虚拟局域网，每台交换机上的一个特殊接口被设置为干线接口，以互连 VLAN 交换机。IEEE 定义了一种扩展的以太网帧格式 802.1Q，它在标准以太网帧上加进了 4 字节首部 VLAN 标签，用于表示该帧属于哪一个虚拟局域网。

![1630975298132](https://tprzfbucket.oss-cn-beijing.aliyuncs.com/hadoop/202109/07/084139-184551.png)



### 物理层

**大图**

![1630995518777](https://tprzfbucket.oss-cn-beijing.aliyuncs.com/hadoop/202109/07/141840-723813.png)

在物理层上所传送的数据单位是比特。

**物理层(physical layer)的作用是实现相邻计算机节点之间比特流的透明传送，尽可能屏蔽掉具体传输介质和物理设备的差异，** 使其上面的数据链路层不必考虑网络的具体传输介质是什么。“透明传送比特流”表示经实际电路传送后的比特流没有发生变化，对传送的比特流来说，这个电路好像是看不见的。

在互联网使用的各种协议中最重要和最著名的就是 TCP/IP 两个协议。现在人们经常提到的 TCP/IP 并不一定单指 TCP 和 IP 这两个具体的协议，而往往表示互联网所使用的整个 TCP/IP 协议族。

#### 名词解释

- 数据：数据是指传送信息 的实体。
- 信号：信号是指数据的电器或者电磁表现（数据和数字都用数字的或者模拟的来形容）。
- 码元：码元是指用一个固定时长的信号波形（数字脉冲）标示以为k进制的数据，代表不同离散数值的基本波形，是数字通信中数字信号的基本单位，这个时长内的信号称为k进制码元，而该时长称为码元宽度，一个码元可以携带多个比特信息。
- 信源：信源是指产生和发送数据的源头，
- 信宿：指接受数据的终点。
- 信道：指信号的传输媒体，按照传输信号形式的不同分为传送模拟信号的模拟信道和传送数字信号的数据信道，按照传输介质分为无线信道和有线信道，基带信号将数字信号1和0直接用两种不同的电压标示，然后传送到数字信道上进行传输（基带传输），带宽信号将基带信号进行调制后形成频分复用的模拟信号，然后在模拟信道上进行传输。
- 带宽：在计算机网络中，带宽用来表示单位时间内从网络的一点到另一点通过的最高数据传输率（也即速率）。
- 速率：数据率，指的是数据的传输速率，标示单位时间内传输的数据量，可以用码元速率和信息传输速率来标示。
  - 码元传输速率：标示单位时间内通过的码元个数。也可以是脉冲个数或者信号的变化次数，码元速率与进制数无关。
  - 信息传输速率：标示单位时间内通过的比特数，单位bit/s。

#### 通信方式

根据信息在传输线上的传送方向，分为以下三种通信方式：

- 单工通信：单向传输
- 半双工通信：双向交替传输
- 全双工通信：双向同时传输

#### 电路交换与分组交换以及报文交换

**图示**

![1630929485492](https://tprzfbucket.oss-cn-beijing.aliyuncs.com/hadoop/202109/06/195806-654816.png)

1. 电路交换

电路交换需要建立一条专用的数据通信路径，这条路径上可能包含许多中间节点。这条通信路径在整个通信过程中将被独占，直到通信结束才会释放资源。电路交换适合实时性要求较高的大量数据传输的情况。

电路交换的优点主要包括以下几个方面：

- 通信时延小，通信双方通过专用线路进行通信，数据可以直达。当数据传输量较大时，优点将十分显著。
- 线路独占，没有冲突。
- 实时性强。一旦通信线路建立，双方可以实时通信。

电路交换的缺点主要包括以下几个方面：

- 线路独占，利用率太低。
- 连接建立时间过长。
- 灵活性比较差

电路一旦建立后，电路上的任何节点都采用直通的方式发送数据和接收数据，显然比分组转发时延小很多。

2. 分组交换

分组交换是将大的数据块分割成小的分组，并添加源地址、目的地址和分组编号等信息。**分组交换是为了解决报文交换中报文段过大的问题，把一个报文段分割成组，每一组自由的在网络上利用存储转发机制进行转发。**

分组交换的优点主要包括以下几个方面：

- 无需建立连接。
- 线路利用率高。
- 相对报文交换，分组长度固定，缓冲区容易管理。
- 分组比报文小，因此传输时间更短。
- 简化了存储管理，相对于报文，分组小得多，因此每个节点的缓存空间相对较小方便管理。
- 加速传输，分组是逐个传输的，因此各个分组可以**并行进行传输**。
- 减少报文出错和重发的概率。

分组交换的缺点主要包括以下几个方面：

- 需要传输包括源地址、目的地址、分组编号等额外信息。
- 分组可能遇到失序、丢失、重复等问题。
- 存在传输时延。
- 需要传输额外的信息，增加了处理时延。
- 分组采取数据报服务时候，可能出现分组不按序到达，分组丢失等情况。

分组交换还可以进一步细分为**数据报方式和虚电路方式**。 数据报为网络层提供无连接服务，不同分组到达目的节点可能会乱序、重复或丢失。分组在交换节点时，可能会带来一定的时延。数据报方式适用于突发性通信，不适合长报文、会话式通信。 虚电路方式将数据报方式与电路交换结合，发挥两者优点。虚电路在源节点和目的节点建立一条逻辑链路，与电路交换不同的地方在于虚电路并不是独占链路资源的。虚电路方式避免了分组的乱序、重复和丢失等问题

> 当传输的数据量很大并且传输时延远远大于连接时延，用电路交换比较好，端到端的通路由很多链路组成，采用分组交换比较好，其中分组交换比报文交换时延小，适合计算机之间突发式通信。

**下面总结一下数据报服务和虚电路服务的区别：**

- 建立连接：数据报服务不要建立连接，虚电路服务需要建立连接。
- 目的地址：数据报服务的每个分组有完整的目的地址，虚电路服务只在建立连接时使用目的地址，当连接建立完成后使用长度较短的虚电路号。
- 路由选择：数据报服务的每个分组都是独立进行路由选择与转发的，虚电路服务属于同一条虚电路的分组按同一路由进行转发。
- 分组顺序：数据报服务不保证分组顺序，虚电路服务保证分组有序到达。
- 可靠性：数据报服务不保证可靠通信，由用户主机保证可靠性，虚电路可靠性由网络来保证。
- 对网络故障的适应性：数据报服务出故障的节点丢失分组，其他分组路径变化可正常传输，虚电路服务所有经过故障节点的虚电路都不能工作。
- 差错处理和流量控制：数据报服务由用户主机进行流量控制，不保证数据可靠性，虚电路服务可由分组交换网或用户主机负责差错处理及流量控制。、

**对比**

![1630979874129](https://tprzfbucket.oss-cn-beijing.aliyuncs.com/hadoop/202109/07/095755-890185.png)

3. 报文交换

报文交换以报文作为数据传输单位，携带有源地址和目的地址等信息。报文交换的单位是报文，报文携带有目的地地址，原地址等信息，报文在转发过程中使用的是**存储转发机制**。

报文交换的优点主要包括以下几个方面：

- 不需要建立连接，不存在建立连接时延。
- 动态的分配线路，发送数据是不需要一直占用整个链路。
- 提高线路的可靠性，某一个节点发生故障，可重新选择线路发送。
- 提高线路的利用率，通信双方不必一直占用通信线路，而是一段一段的占用物理信道。
- 提供多目标服务。

报文交换的缺点主要包括以下几个方面：

- 报文交换对报文的大小没有限制，需要网络节点有足够的缓存空间。
- 报文交换在节点处要经历存储、转发等操作，从而引起一定时延。

#### 物理层设备

1. 中继器：
   1. 中继器又称为转发器，主要功能是将信号整型放大再转发出去，以消除信号由于经过一长段电缆，因噪卢或其他原因而造成的失真和衰减，使信号的波形和强度达到所需要的要求，来扩大网络传输的距离。其原理是信号再生〈而不是简单地将衰减的信号放大〉。中继器有两个端口，将一个端口输入的数据从另一个端口发送出去，但仅作用于信号的电气部分，而不管数据中是否有错误数据或不适于网段的数据。
   2. 中继器在局域网环境下用来扩大网络规模的最简单最廉价的互联设备。使用中继器连接起来的几个网段仍然是一个局域网.一般情况下，中继器的两端连接的是相同的媒体，但有的中继器也可 以完成不同媒体的转接工作。但由于中继器工作在物理层，所以它不能连接两个具有不同速率的局域网. 中继器两端的网络部分是网段，而不是子网，中继器若出现故障， 对相邻的个网段的工作都将产生影响。
      - 放大器和中继器都是起放大作用，只不过放大器放大的是模拟信号，原理是将衰减的信号放大，中继器放大的是数字信号，原理是将衰减的信号整形再生，如果某个网络设备具有存储转发的功能，那么可以认为该设备可以连接两个不同的协议，如果该网络设备没有存储转发功能， 则认为该设备不能连接两个不同的协议。中继器是没有存储转发功能的，因此中继器不能连接两个速率不同的网段，中继器两端的网段一定要是同一个协议。
2. 集线器：
   1. 集线器( Hub ) 实质上是一个多端υ口的中继器，也工作在物理层。在Hub 工作时，当一个端口接收到数据信号后， 由于信号在从端口至Hub 的传输过程中已有 衰减，所以Hub 便将该信号进行整形放大，使之再生〈恢复)到发送时的状态，紧接着转发到其他所有(除输入端口以外)处于工作状态的端口上.如果同时有两个或多个端口输入，则输出时会发生冲突，会使这些数据都成为无效的。从Hub 的工作方式可以看出，它在网络中只起到信号放大和转发作用，其目的是在扩大网络的传输范围， 而不是信号的定向传送能力即信号传输的方向是固定，是一个标准的共享式设备.
   2. 由Hub 组成的网络是共享式网络，在逻辑上仍然是一个总线网. Hub 每个端口连接的网络部分是同一个网络的不同网段.同时Hub 也只能够在半双工下工作， 网络的吞吐率因而受到限制。
   3. 注意: 多台计算机同时通信必然会发生，所以集线器不能分割冲突域，所有集线器端口都属于同一个冲突域。集线器在一个时钟周期中只能传输一组信息，如果一台集线器连接的机器数目较多，并且多台机器经常需要同时通信，将导致信息的碰撞， 使得集线器的工作效率很差。比如一个带宽为10Mb/s 的集线器上连接了8 台计算机，当这8 台计算机同时工作时，每台计算机真正所拥有的带宽为10/8 Mb/s=1.25Mb/s。

### 总结一下

上面我们对计算机网络的五层体系结构有了初步的了解，下面附送一张七层体系结构图总结一下（图片来源于网络）。

![七层体系结构图](https://tprzfbucket.oss-cn-beijing.aliyuncs.com/hadoop/202109/06/194608-675257.png)

## TCP 三次握手和四次挥手(面试常客)

为了准确无误地把数据送达目标处，TCP 协议采用了三次握手策略。

### 2.1 TCP 三次握手漫画图解

如下图所示，下面的两个机器人通过 3 次握手确定了对方能正确接收和发送消息(图片来源：《图解 HTTP》)。
![1630929872977](https://tprzfbucket.oss-cn-beijing.aliyuncs.com/hadoop/202109/06/200433-327882.png)

**简单示意图：**
![1631253394739](https://tprzfbucket.oss-cn-beijing.aliyuncs.com/hadoop/202109/10/135635-548441.png)

- 客户端–发送带有 SYN 标志的数据包–一次握手–服务端
- 服务端–发送带有 SYN/ACK 标志的数据包–二次握手–客户端
- 客户端–发送带有带有 ACK 标志的数据包–三次握手–服务端

**详细示意图（图片来源不详）**

![1631253415673](https://tprzfbucket.oss-cn-beijing.aliyuncs.com/hadoop/202109/10/135656-527432.png)

### 2.2 为什么要三次握手

**三次握手的目的是建立可靠的通信信道，说到通讯，简单来说就是数据的发送与接收，而三次握手最主要的目的就是双方确认自己与对方的发送与接收是正常的。**

第一次握手：Client 什么都不能确认；Server 确认了对方发送正常，自己接收正常

第二次握手：Client 确认了：自己发送、接收正常，对方发送、接收正常；Server 确认了：对方发送正常，自己接收正常

第三次握手：Client 确认了：自己发送、接收正常，对方发送、接收正常；Server 确认了：自己发送、接收正常，对方发送、接收正常

所以三次握手就能确认双发收发功能都正常，缺一不可。

### 2.3 第 2 次握手传回了 ACK，为什么还要传回 SYN？

接收端传回发送端所发送的 ACK 是为了告诉客户端，我接收到的信息确实就是你所发送的信号了，这表明从客户端到服务端的通信是正常的。而回传 SYN 则是为了建立并确认从服务端到客户端的通信。”

> SYN 同步序列编号(Synchronize Sequence Numbers) 是 TCP/IP 建立连接时使用的握手信号。在客户机和服务器之间建立正常的 TCP 网络连接时，客户机首先发出一个 SYN 消息，服务器使用 SYN-ACK 应答表示接收到了这个消息，最后客户机再以 ACK(Acknowledgement）消息响应。这样在客户机和服务器之间才能建立起可靠的 TCP 连接，数据才可以在客户机和服务器之间传递。

### 2.5 为什么要四次挥手

![1631253702002](https://tprzfbucket.oss-cn-beijing.aliyuncs.com/hadoop/202109/10/140143-674775.png)

断开一个 TCP 连接则需要“四次挥手”：

- 客户端-发送一个 FIN，用来关闭客户端到服务器的数据传送
- 服务器-收到这个 FIN，它发回一 个 ACK，确认序号为收到的序号加 1 。和 SYN 一样，一个 FIN 将占用一个序号
- 服务器-关闭与客户端的连接，发送一个 FIN 给客户端
- 客户端-发回 ACK 报文确认，并将确认序号设置为收到序号加 1

任何一方都可以在数据传送结束后发出连接释放的通知，待对方确认后进入半关闭状态。当另一方也没有数据再发送的时候，则发出连接释放通知，对方确认后就完全关闭了 TCP 连接。

举个例子：A 和 B 打电话，通话即将结束后，A 说“我没啥要说的了”，B 回答“我知道了”，但是 B 可能还会有要说的话，A 不能要求 B 跟着自己的节奏结束通话，于是 B 可能又巴拉巴拉说了一通，最后 B 说“我说完了”，A 回答“知道了”，这样通话才算结束。

上面讲的比较概括，推荐一篇讲的比较细致的文章：[https://blog.csdn.net/qzcsu/article/details/72861891](https://blog.csdn.net/qzcsu/article/details/72861891)

## 三 TCP,UDP 协议的区别

![TCP、UDP协议的区别](https://my-blog-to-use.oss-cn-beijing.aliyuncs.com/2019-11/tcp-vs-udp.jpg)

UDP 在传送数据之前不需要先建立连接，远地主机在收到 UDP 报文后，不需要给出任何确认。虽然 UDP 不提供可靠交付，但在某些情况下 UDP 却是一种最有效的工作方式（一般用于即时通信），比如： QQ 语音、 QQ 视频 、直播等等

TCP 提供面向连接的服务。在传送数据之前必须先建立连接，数据传送结束后要释放连接。 TCP 不提供广播或多播服务。由于 TCP 要提供可靠的，面向连接的传输服务（TCP 的可靠体现在 TCP 在传递数据之前，会有三次握手来建立连接，而且在数据传递时，有确认、窗口、重传、拥塞控制机制，在数据传完后，还会断开连接用来节约系统资源），这一难以避免增加了许多开销，如确认，流量控制，计时器以及连接管理等。这不仅使协议数据单元的首部增大很多，还要占用许多处理机资源。TCP 一般用于文件传输、发送和接收邮件、远程登录等场景。

## 四 TCP 协议如何保证可靠传输

1. 应用数据被分割成 TCP 认为最适合发送的数据块。
2. TCP 给发送的每一个包进行编号，接收方对数据包进行排序，把有序数据传送给应用层。
3. **校验和：** TCP 将保持它首部和数据的检验和。这是一个端到端的检验和，目的是检测数据在传输过程中的任何变化。如果收到段的检验和有差错，TCP 将丢弃这个报文段和不确认收到此报文段。
4. TCP 的接收端会丢弃重复的数据。
5. **流量控制：** TCP 连接的每一方都有固定大小的缓冲空间，TCP 的接收端只允许发送端发送接收端缓冲区能接纳的数据。当接收方来不及处理发送方的数据，能提示发送方降低发送的速率，防止包丢失。TCP 使用的流量控制协议是可变大小的滑动窗口协议。 （TCP 利用滑动窗口实现流量控制）
6. **拥塞控制：** 当网络拥塞时，减少数据的发送。
7. **ARQ 协议：** 也是为了实现可靠传输的，它的基本原理就是每发完一个分组就停止发送，等待对方确认。在收到确认后再发下一个分组。
8. **超时重传：** 当 TCP 发出一个段后，它启动一个定时器，等待目的端确认收到这个报文段。如果不能及时收到一个确认，将重发这个报文段。

### 4.1 ARQ 协议

**自动重传请求**（Automatic Repeat-reQuest，ARQ）是 OSI 模型中数据链路层和传输层的错误纠正协议之一。它通过使用确认和超时这两个机制，在不可靠服务的基础上实现可靠的信息传输。如果发送方在发送后一段时间之内没有收到确认帧，它通常会重新发送。**ARQ 包括停止等待 ARQ 协议和连续 ARQ 协议。**

#### 停止等待 ARQ 协议

停止等待协议是为了实现可靠传输的，它的基本原理就是每发完一个分组就停止发送，等待对方确认（回复 ACK）。如果过了一段时间（超时时间后），还是没有收到 ACK 确认，说明没有发送成功，需要重新发送，直到收到确认后再发下一个分组。

在停止等待协议中，若接收方收到重复分组，就丢弃该分组，但同时还要发送确认。

**优缺点：**

- **优点：** 简单
- **缺点：** 信道利用率低，等待时间长

**1) 无差错情况:**

发送方发送分组,接收方在规定时间内收到,并且回复确认.发送方再次发送。

**2) 出现差错情况（超时重传）:**

停止等待协议中超时重传是指只要超过一段时间仍然没有收到确认，就重传前面发送过的分组（认为刚才发送过的分组丢失了）。因此每发送完一个分组需要设置一个超时计时器，其重传时间应比数据在分组传输的平均往返时间更长一些。这种自动重传方式常称为 **自动重传请求 ARQ** 。另外在停止等待协议中若收到重复分组，就丢弃该分组，但同时还要发送确认。**连续 ARQ 协议** 可提高信道利用率。发送维持一个发送窗口，凡位于发送窗口内的分组可连续发送出去，而不需要等待对方确认。接收方一般采用累积确认，对按序到达的最后一个分组发送确认，表明到这个分组位置的所有分组都已经正确收到了。

**3) 确认丢失和确认迟到**

- **确认丢失** ：确认消息在传输过程丢失。当 A 发送 M1 消息，B 收到后，B 向 A 发送了一个 M1 确认消息，但却在传输过程中丢失。而 A 并不知道，在超时计时过后，A 重传 M1 消息，B 再次收到该消息后采取以下两点措施：1. 丢弃这个重复的 M1 消息，不向上层交付。 2. 向 A 发送确认消息。（不会认为已经发送过了，就不再发送。A 能重传，就证明 B 的确认消息丢失）。
- **确认迟到** ：确认消息在传输过程中迟到。A 发送 M1 消息，B 收到并发送确认。在超时时间内没有收到确认消息，A 重传 M1 消息，B 仍然收到并继续发送确认消息（B 收到了 2 份 M1）。此时 A 收到了 B 第二次发送的确认消息。接着发送其他数据。过了一会，A 收到了 B 第一次发送的对 M1 的确认消息（A 也收到了 2 份确认消息）。处理如下：1. A 收到重复的确认后，直接丢弃。2. B 收到重复的 M1 后，也直接丢弃重复的 M1。

#### 连续 ARQ 协议

连续 ARQ 协议可提高信道利用率。发送方维持一个发送窗口，凡位于发送窗口内的分组可以连续发送出去，而不需要等待对方确认。接收方一般采用累计确认，对按序到达的最后一个分组发送确认，表明到这个分组为止的所有分组都已经正确收到了。

**优缺点：**

- **优点：** 信道利用率高，容易实现，即使确认丢失，也不必重传。
- **缺点：** 不能向发送方反映出接收方已经正确收到的所有分组的信息。 比如：发送方发送了 5 条 消息，中间第三条丢失（3 号），这时接收方只能对前两个发送确认。发送方无法知道后三个分组的下落，而只好把后三个全部重传一次。这也叫 Go-Back-N（回退 N），表示需要退回来重传已经发送过的 N 个消息。

### 4.2 滑动窗口和流量控制

**TCP 利用滑动窗口实现流量控制。流量控制是为了控制发送方发送速率，保证接收方来得及接收。** 接收方发送的确认报文中的窗口字段可以用来控制发送方窗口大小，从而影响发送方的发送速率。将窗口字段设置为 0，则发送方不能发送数据。

### 4.3 拥塞控制

在某段时间，若对网络中某一资源的需求超过了该资源所能提供的可用部分，网络的性能就要变坏。这种情况就叫拥塞。拥塞控制就是为了防止过多的数据注入到网络中，这样就可以使网络中的路由器或链路不致过载。拥塞控制所要做的都有一个前提，就是网络能够承受现有的网络负荷。**拥塞控制是一个全局性的过程**，涉及到所有的主机，所有的路由器，以及与降低网络传输性能有关的所有因素。相反，流量控制往往是点对点通信量的控制，是个端到端的问题。流量控制所要做到的就是抑制发送端发送数据的速率，以便使接收端来得及接收。

为了进行拥塞控制，TCP 发送方要维持一个 **拥塞窗口(cwnd)** 的状态变量。拥塞控制窗口的大小取决于网络的拥塞程度，并且动态变化。**发送方让自己的发送窗口取为拥塞窗口和接收方的接受窗口中较小的一个。**

TCP 的拥塞控制采用了四种算法，即 **慢开始** 、 **拥塞避免** 、**快重传** 和 **快恢复**。在网络层也可以使路由器采用适当的分组丢弃策略（如主动队列管理 AQM），以减少网络拥塞的发生。

- **慢开始：** 慢开始算法的思路是当主机开始发送数据时，如果立即把大量数据字节注入到网络，那么可能会引起网络阻塞，因为现在还不知道网络的符合情况。经验表明，较好的方法是先探测一下，即由小到大逐渐增大发送窗口，也就是由小到大逐渐增大拥塞窗口数值。cwnd 初始值为 1，每经过一个传播轮次，cwnd 加倍。
- **拥塞避免：** 拥塞避免算法的思路是让拥塞窗口 cwnd 缓慢增大，即每经过一个往返时间 RTT 就把发送放的 cwnd 加 1.
- **快重传与快恢复：**
  在 TCP/IP 中，快速重传和恢复（fast retransmit and recovery，FRR）是一种拥塞控制算法，它能快速恢复丢失的数据包。没有 FRR，如果数据包丢失了，TCP 将会使用定时器来要求传输暂停。在暂停的这段时间内，没有新的或复制的数据包被发送。有了 FRR，如果接收机接收到一个不按顺序的数据段，它会立即给发送机发送一个重复确认。如果发送机接收到三个重复确认，它会假定确认件指出的数据段丢失了，并立即重传这些丢失的数据段。有了 FRR，就不会因为重传时要求的暂停被耽误。 　当有单独的数据包丢失时，快速重传和恢复（FRR）能最有效地工作。当有多个数据信息包在某一段很短的时间内丢失时，它则不能很有效地工作。

## 五 在浏览器中输入 url 地址 ->> 显示主页的过程(面试常客)

百度好像最喜欢问这个问题。

> 打开一个网页，整个过程会使用哪些协议？

图解（图片来源：《图解 HTTP》）：

![1631260834637](https://tprzfbucket.oss-cn-beijing.aliyuncs.com/hadoop/202111/25/120557-348326.png)

> 上图有一个错误，请注意，是 OSPF 不是 OPSF。 OSPF（Open Shortest Path First，ospf）开放最短路径优先协议,是由 Internet 工程任务组开发的路由选择协议

总体来说分为以下几个过程:

1. DNS 解析
2. TCP 连接
3. 发送 HTTP 请求
4. 服务器处理请求并返回 HTTP 报文
5. 浏览器解析渲染页面
6. 连接结束

具体可以参考下面这篇文章：

- [https://segmentfault.com/a/1190000006879700](https://segmentfault.com/a/1190000006879700)

## 六 状态码

![1631260911564](https://tprzfbucket.oss-cn-beijing.aliyuncs.com/hadoop/202109/10/160216-346253.png)

## 七 各种协议与 HTTP 协议之间的关系

一般面试官会通过这样的问题来考察你对计算机网络知识体系的理解。

图片来源：《图解 HTTP》

![1631261069923](https://tprzfbucket.oss-cn-beijing.aliyuncs.com/hadoop/202109/10/160431-338595.png)

![1631261120963](https://tprzfbucket.oss-cn-beijing.aliyuncs.com/hadoop/202109/10/160522-920814.png)

## 八 HTTP 长连接,短连接

在 HTTP/1.0 中默认使用短连接。也就是说，客户端和服务器每进行一次 HTTP 操作，就建立一次连接，任务结束就中断连接。当客户端浏览器访问的某个 HTML 或其他类型的 Web 页中包含有其他的 Web 资源（如 JavaScript 文件、图像文件、CSS 文件等），每遇到这样一个 Web 资源，浏览器就会重新建立一个 HTTP 会话。

而从 HTTP/1.1 起，默认使用长连接，用以保持连接特性。使用长连接的 HTTP 协议，会在响应头加入这行代码：

```
Connection:keep-alive
```

在使用长连接的情况下，当一个网页打开完成后，客户端和服务器之间用于传输 HTTP 数据的 TCP 连接不会关闭，客户端再次访问这个服务器时，会继续使用这一条已经建立的连接。Keep-Alive 不会永久保持连接，它有一个保持时间，可以在不同的服务器软件（如 Apache）中设定这个时间。实现长连接需要客户端和服务端都支持长连接。

**HTTP 协议的长连接和短连接，实质上是 TCP 协议的长连接和短连接。**

—— [《HTTP 长连接、短连接究竟是什么？》](https://www.cnblogs.com/gotodsp/p/6366163.html)

## 九 HTTP 是不保存状态的协议,如何保存用户状态?

HTTP 是一种不保存状态，即无状态（stateless）协议。也就是说 HTTP 协议自身不对请求和响应之间的通信状态进行保存。那么我们保存用户状态呢？Session 机制的存在就是为了解决这个问题，Session 的主要作用就是通过服务端记录用户的状态。典型的场景是购物车，当你要添加商品到购物车的时候，系统不知道是哪个用户操作的，因为 HTTP 协议是无状态的。服务端给特定的用户创建特定的 Session 之后就可以标识这个用户并且跟踪这个用户了（一般情况下，服务器会在一定时间内保存这个 Session，过了时间限制，就会销毁这个 Session）。

在服务端保存 Session 的方法很多，最常用的就是内存和数据库(比如是使用内存数据库 redis 保存)。既然 Session 存放在服务器端，那么我们如何实现 Session 跟踪呢？大部分情况下，我们都是通过在 Cookie 中附加一个 Session ID 来方式来跟踪。

**Cookie 被禁用怎么办?**

最常用的就是利用 URL 重写把 Session ID 直接附加在 URL 路径的后面。

![HTTP是无状态协议](https://my-blog-to-use.oss-cn-beijing.aliyuncs.com/2019-6/HTTP是无状态的.png)

## 十 Cookie 的作用是什么?和 Session 有什么区别？

Cookie 和 Session 都是用来跟踪浏览器**用户身份的会话方式**，但是两者的应用场景不太一样。

**Cookie 一般用来保存用户信息** 比如 ① 我们在 Cookie 中保存已经登录过得用户信息，下次访问网站的时候页面可以自动帮你登录的一些基本信息给填了；② 一般的网站都会有保持登录也就是说下次你再访问网站的时候就不需要重新登录了，这是因为用户登录的时候我们可以存放了一个 Token 在 Cookie 中，下次登录的时候只需要根据 Token 值来查找用户即可(为了安全考虑，重新登录一般要将 Token 重写)；③ 登录一次网站后访问网站其他页面不需要重新登录。**Session 的主要作用就是通过服务端记录用户的状态。** 典型的场景是购物车，当你要添加商品到购物车的时候，系统不知道是哪个用户操作的，因为 HTTP 协议是无状态的。服务端给特定的用户创建特定的 Session 之后就可以标识这个用户并且跟踪这个用户了。

**Cookie 数据保存在客户端(浏览器端)，Session 数据保存在服务器端。**

Cookie 存储在客户端中，而 Session 存储在服务器上，相对来说 Session 安全性更高。如果要在 Cookie 中存储一些敏感信息，不要直接写入 Cookie 中，最好能将 Cookie 信息加密然后使用到的时候再去服务器端解密。

## 十一 HTTP 1.0 和 HTTP 1.1 的主要区别是什么?

> 这部分回答引用这篇文章 <https://mp.weixin.qq.com/s/GICbiyJpINrHZ41u_4zT-A?> 的一些内容。

HTTP1.0 最早在网页中使用是在 1996 年，那个时候只是使用一些较为简单的网页上和网络请求上，而 HTTP1.1 则在 1999 年才开始广泛应用于现在的各大浏览器网络请求中，同时 HTTP1.1 也是当前使用最为广泛的 HTTP 协议。 主要区别主要体现在：

1. **长连接** : **在 HTTP/1.0 中，默认使用的是短连接**，也就是说每次请求都要重新建立一次连接。HTTP 是基于 TCP/IP 协议的,每一次建立或者断开连接都需要三次握手四次挥手的开销，如果每次请求都要这样的话，开销会比较大。因此最好能维持一个长连接，可以用个长连接来发多个请求。**HTTP 1.1 起，默认使用长连接** ,默认开启 Connection： keep-alive。 **HTTP/1.1 的持续连接有非流水线方式和流水线方式** 。流水线方式是客户在收到 HTTP 的响应报文之前就能接着发送新的请求报文。与之相对应的非流水线方式是客户在收到前一个响应后才能发送下一个请求。
1. **错误状态响应码** :在 HTTP1.1 中新增了 24 个错误状态响应码，如 409（Conflict）表示请求的资源与资源的当前状态发生冲突；410（Gone）表示服务器上的某个资源被永久性的删除。
1. **缓存处理** :在 HTTP1.0 中主要使用 header 里的 If-Modified-Since,Expires 来做为缓存判断的标准，HTTP1.1 则引入了更多的缓存控制策略例如 Entity tag，If-Unmodified-Since, If-Match, If-None-Match 等更多可供选择的缓存头来控制缓存策略。
1. **带宽优化及网络连接的使用** :HTTP1.0 中，存在一些浪费带宽的现象，例如客户端只是需要某个对象的一部分，而服务器却将整个对象送过来了，并且不支持断点续传功能，HTTP1.1 则在请求头引入了 range 头域，它允许只请求资源的某个部分，即返回码是 206（Partial Content），这样就方便了开发者自由的选择以便于充分利用带宽和连接。

## 十二 URI 和 URL 的区别是什么?

- URI(Uniform Resource Identifier) 是统一资源标志符，**可以唯一标识一个资源**。
- URL(Uniform Resource Locator) 是统一资源定位符，**可以提供该资源的路径**。它是一种具体的 URI，即 URL 可以用来标识一个资源，而且还指明了如何 locate 这个资源。

URI 的作用像身份证号一样，URL 的作用更像家庭住址一样。URL 是一种具体的 URI，它不仅唯一标识资源，而且还提供了定位该资源的信息。

## 十三 HTTP 和 HTTPS 的区别？

1. **端口** ：HTTP 的 URL 由“http://”起始且默认使用端口80，而HTTPS的URL由“https://”起始且默认使用端口443。
2. **安全性和资源消耗：** HTTP 协议运行在 TCP 之上，所有传输的内容都是明文，客户端和服务器端都无法验证对方的身份。HTTPS 是运行在 SSL/TLS 之上的 HTTP 协议，SSL/TLS 运行在 TCP 之上。所有传输的内容都经过加密，加密采用对称加密，但对称加密的密钥用服务器方的证书进行了非对称加密。所以说，HTTP 安全性没有 HTTPS 高，但是 HTTPS 比 HTTP 耗费更多服务器资源。
   - 对称加密：密钥只有一个，加密解密为同一个密码，且加解密速度快，典型的对称加密算法有 DES、AES 等；
   - 非对称加密：密钥成对出现（且根据公钥无法推知私钥，根据私钥也无法推知公钥），加密解密使用不同密钥（公钥加密需要私钥解密，私钥加密需要公钥解密），相对对称加密速度较慢，典型的非对称加密算法有 RSA、DSA 等。

## 建议

非常推荐大家看一下 《图解 HTTP》 这本书，这本书页数不多，但是内容很是充实，不管是用来系统的掌握网络方面的一些知识还是说纯粹为了应付面试都有很大帮助。下面的一些文章只是参考。大二学习这门课程的时候，我们使用的教材是 《计算机网络第七版》（谢希仁编著），不推荐大家看这本教材，书非常厚而且知识偏理论，不确定大家能不能心平气和的读完。

## 参考

- [https://blog.csdn.net/qq_16209077/article/details/52718250](https://blog.csdn.net/qq_16209077/article/details/52718250)
- [https://blog.csdn.net/zixiaomuwu/article/details/60965466](https://blog.csdn.net/zixiaomuwu/article/details/60965466)
- [https://blog.csdn.net/turn\_\_back/article/details/73743641](https://blog.csdn.net/turn__back/article/details/73743641)
- <https://mp.weixin.qq.com/s/GICbiyJpINrHZ41u_4zT-A?>

## 易错点

### 差错检验

1. 数据链路层的差错控制

   - 由于信道噪声等各种原因，帧在传输过程中可能会出现错误。用以使发送方确定接收方是否正确收到了由它发送的数据的方法称为差错控制。通常，这些错误可分为位错和帧错误。
   - 位错指帧中某些位出现了差错。通常采用循环冗余校验(C RC) 方式发现位错，通过自动重传请求(Automatic Repeat reQuest, ARQ ) 方式来重传出错的帧.具体做法是:让发送方将要发送的数据帧附加一定的CRC 冗余检错码一并发迭，接收方则根据检错码对数据帧进行错误检测，若发现错误， 则丢弃， 发送方超时重传该数据帧.这种差错控制方法就称为ARQ 法， ARQ 法仅返回很少的控制信息，便可有效地确认所发数据帧是否被正确接收.
   - 帧错误是指帧的丢失，重复或失序等错误。在数据链路层引入定时器和编号机制，可以保证每一帧最终都能有且仅有一次正确地交付给目的结点。

2. 传输层的UDP校验

   1. 在计算校验和时，要在UDP 数据报之前增加12个字节的伪首部，伪收部并不是UDP 真正的首部。只是在计算校验和时，临时添加在UDP 数据报的前面，得到一个临时的UDP 数据报。校验和就是按照这个临时的U DP 数据报计算的. 伪首部既不向下传送也不向上递交，而仅仅是为了计算校验和.这样的校验和，既检查了UDP 数据报， 又对IP 数据报的源IP 地址和目的IP地址进行了检验。
   2. UD P 校验和的计算方法和TCP 数据报首部校验和的计算方法相似，都使用二进制反码运算求和再取反。**但不同的是:lP 数据报的校验和只检验lP 数据报的首郁， 但UDP 的校验和是把首部和数据部分一起都检验。**
   3. 在发送方，首先是把全零放入校验和字段并且添加伪首部。然后，把UDP 数据报看成是由许多1 6 位的字串连接起来。若UDP 数据报的数据部分不是偶数个字节，则要在数据部分末尾增加一个全零字节(但此字节不发送〉。接下来就按二进制反码计算出这些16 位字的和.将此和的二进制反码写入校验和字段。在接收方，把收到的UDP 数据报加上伪首部(如果不为偶数个字第节，还需要补上全零字节〉后，按二进制反码计算出这些16 位字的和. 当无差错时其结果应全为1， 否则就表明有差错出现，接收方就应该丢弃这个UDP 数据报。

3. 传输层的TCP校验

   检验和字段检验的范围包括首部和数据这两部分。在计算检验和时，和UDP 一样，要在TCP 报文段的前面加 12 字节的伪首部〈只需将UDP 伪首部的第4 个字段，即协议字段的1 7 改成6 ，其他的和UDP 一样)。

- **在这里注意吧，不管是UDP还是TCP,检验的部分都包括首部和数据部分。**

### 每一层的功能总结

1. 物理层：该层包括物理连接媒介，是计算机联网的基础，进行转发比特流。（任何一种调制解调器）
2. 数据链路层：在不可靠的物理线路上进行可靠的数据传递。（ALOHA,PPP,CSMA,CSMA/CD,CDMA）
3. 网络层：实际上是完成主机到主机之间的通信服务，（IP,ARP,RARP,ICMP,OSPF,BGP）
4. 传输层：提供的是端到端的数据通信服务，（TCP,UDP）
5. 会话层：负责在网络中的两个节点之间建立和维持通信。
6. 表示层：为不同终端的上层用户提供数据和信息的格式化标示方法（数据加密解密,XML,HTML）
7. 应用层：负责对软件提供接口以使程序能够使用网络的服务，（注意：不是运行着的那些程序，而是对应用程序提供接口或服务）FTP,HTTP,DNS。

## 面试题总结

1. 拥塞控制

   1. 慢开始
      - 发送方维持一个叫做拥塞窗口`cwnd（congestion window）`的状态变量。拥塞窗口的大小取决于网络的拥塞程度，并且动态地在变化。发送方让自己的发送窗口等于拥塞窗口，另外考虑到接受方的接收能力，发送窗口可能小于拥塞窗口。
      - 慢开始算法的思路就是，不要一开始就发送大量的数据，先探测一下网络的拥塞程度，也就是说由小到大逐渐增加拥塞窗口的大小。
      - 实时拥塞窗口大小是以字节为单位的。当然收到单个确认但此确认多个数据报的时候就加相应的数值。所以一次传输轮次之后拥塞窗口就加倍。这就是乘法增长，和后面的拥塞避免算法的加法增长比较。
      - 为了防止`cwnd `增长过大引起网络拥塞，还需设置一个慢开始门限`ssthresh `状态变量。`ssthresh` 的用法如下：
        - 当`cwnd<ssthresh `时，使用慢开始算法。
        - 当`cwnd>ssthresh` 时，改用拥塞避免算法。
        - 当`cwnd=ssthresh `时，慢开始与拥塞避免算法任意。
   2. 拥塞避免
      - 拥塞避免算法让拥塞窗缓慢增长，即每经过一个往返时间`RTT` 就把发送方的拥塞窗口`cwnd` 加1，而不是加倍。这样拥塞窗口按线性规律缓慢增长。
      - 无论是在慢开始阶段还是在拥塞避免阶段，只要发送方判断网络出现拥塞（其根据就是没有收到确认，虽然没有收到确认可能是其他原因的分组丢失，但是因为无法判定，所以都当做拥塞来处理），就把慢开始门限`ssthresh` 设置为出现拥塞时的发送窗口大小的一半。然后把拥塞窗口设置为1，执行慢开始算法。
   3. 快重传
      - 快重传要求接收方在收到一个失序的报文段后就立即发出重复确认（为的是使发送方及早知道有报文段没有到达对方）而不要等到自己发送数据时捎带确认。快重传算法规定，发送方只要一连收到三个重复确认就应当立即重传对方尚未收到的报文段，而不必继续等待设置的重传计时器时间到期。
   4. 快恢复
      - 当发送方连续收到三个重复确认时，就执行“乘法减小”算法，把`ssthresh `门限减半。但是接下去并不执行慢开始算法。
      - 考虑到如果网络出现拥塞的话就不会收到好几个重复的确认，所以发送方现在认为网络可能没有出现拥塞。所以此时不执行慢开始算法，而是将`cwnd` 设置为`ssthresh `的大小，然后执行拥塞避免算法。

2. 为什么建立连接协议是三次握手，而关闭连接却是四次握手呢？

   - 这是因为服务端的`LISTEN `状态下的`SOCKET `当收到`SYN` 报文的建连请求后，它可以把`ACK`和`SYN`（`ACK `起应答作用，而`SYN` 起同步作用）放在一个报文里来发送。但关闭连接时，当收到对方的`FIN` 报文通知时，它仅仅表示对方没有数据发送给你了；但未必你所有的数据都全部发送给对方了，所以你可以未必会马上会关闭`SOCKET`,也即你可能还需要发送一些数据给对方之后，再发送`FIN `报文给对方来表示你同意现在可以关闭连接了，所以它这里的`ACK `报文和`FIN `报文多数情况下都是分开发送的。

3. 第三次握手失败

   - 当客户端收到服务端的`SYN+ACK `应答后，其状态变为`ESTABLISHED`，并会发送`ACK `包给服务端，准备发送数据了。如果此时`ACK `在网络中丢失，过了超时计时器后，那么`Server`端会重新发送`SYN+ACK` 包，重传次数根据`/proc/sys/net/ipv4/tcp_synack_retries `来指定，默认是5 次。如果重传指定次数到了后，仍然未收到`ACK `应答，那么一段时间后，`Server` 自动关闭这个连接。但是`Client` 认为这个连接已经建立，如果`Client` 端向`Server` 写数据，`Server`端将以`RST`包响应，方能感知到`Server` 的错误。
   - 在`S erver`返回一个确认的`SYN-ACK` 包的时候，S 可能由于各种原因不会接到C 回应的ACK 包。这个也就是所谓的半开放连接，S 需要耗费一定的数量的系统内存来等待这个未决的连接，虽然这个数量是受限，但是恶意者可以通过创建很多的半开放式连接来发动SYN 洪水攻击。攻击者可以通过IP 欺骗发送SYN 包给受害者系统，这个看起来是合法的，但事实上所谓的C 根本不会进行ACK 回应服务端S 的SYN-ACK 报文，这意味着受害者将永远不会接到ACK报文。而此时，半开放连接将最终耗用受害者所有的系统资源（即使等待ACK 包有超时限制），受害者将不能再接收任何其他的请求。

4. 如何应对TCP SYN Flood

   - 第一个参数tcp_synack_retries = 0 是关键，表示回应第二个握手包（SYN+ACK 包）给客户端IP 后，如果收不到第三次握手包（ACK 包）后，不进行重试，加快回收“半连接”，不要耗光资源。
   - 修改这个参数为0 的副作用：网络状况很差时，如果对方没收到第二个握手包，可能连接服务器失败，但对于一般网站，用户刷新一次页面即可。这些可以在高峰期或网络状况不好时tcpdump 抓包验证下。
   - 之所以可以把tcp_synack_retries 改为0，因为客户端还有tcp_syn_retries 参数，默认是5，即使服务器端没有重发SYN+ACK 包，客户端也会重发SYN 握手包。
   - tcp_max_syn_backlog
     从字面上就可以推断出是什么意思。在内核里有个队列用来存放还没有确认ACK 的客户端
     请求，当等待的请求数大于tcp_max_syn_backlog 时，后面的会被丢弃。
   - 所以，适当增大这个值，可以在压力大的时候提高握手的成功率。手册里推荐大于1024。使用服务器的内存资源，换取更大的等待队列长度，让攻击数据包不至于占满所有连接而导致正常用户无法完成握手。
     当半连接的请求数量超过了tcp_max_syn_backlog 时，内核就会启用SYN cookie 机制，不再把半连接请求放到队列里，而是用SYN cookie 来检验。
   - 启用3
     启用之前，服务器在接到SYN 数据包后，立即分配存储空间，并随机化一个数字作为SYN号发送SYN+ACK 数据包。然后保存连接的状态信息等待客户端确认。启用SYN Cookie 之后，服务器不再分配存储空间，而且通过基于时间种子的随机数算法设置一个SYN 号，替代完全随机的SYN 号。发送完SYN+ACK 确认报文之后，清空资源不保存任何状态信息。直到服务器接到客户端的最终ACK 包，通过Cookie 检验算法鉴定是否与发出去的SYN+ACK报文序列号匹配，匹配则通过完成握手，失败则丢弃。当然，前文的高级攻击中有SYN 混合ACK 的攻击方法，则是对此种防御方法的反击，其中优劣由双方的硬件配置决定

5. 客户端收到一个窗口为0 的包怎么处理

   - TCP 长连接与短连接

     TCP 短连接的情况，client 向server 发起连接请求，server 接到请求，然后双方建立连接。client 向server 发送消息，server 回应client，然后一次读写就完成了，这时候双方任何一个都可以发起close 操作，不过一般都是client 先发起close 操作。为什么呢，一般的server不会回复完client 后立即关闭连接的，当然不排除有特殊的情况。从上面的描述看，短连接
     一般只会在client/server 间传递一次读写操作client 向server 发起连接，server 接受client 连接，双方建立连接。Client 与server 完成一次读写之后，它们之间的连接并不会主动关闭，后续的读写操作会继续使用这个连接。

6. 为什么要有time_wait

   1. 可靠的终止TCP 连接。

      可靠的终止TCP 连接，若处于time_wait 的client 发送给server 确认报文段丢失的话，server将在此又一次发送FIN 报文段，那么client 必须处于一个可接收的状态就是time_wait 而不是close 状态。

   2. 保证让迟来的TCP 报文段有足够的时间被识别并丢弃。

      保证迟来的TCP 报文段有足够的时间被识别并丢弃，linux 中一个TCPport 不能打开两次或两次以上。当client 处于time_wait 状态时我们将无法使用此port 建立新连接，假设不存在time_wait 状态，新连接可能会收到旧连接的数据。

   3. 可靠地实现TCP 全双工连接的终止

      TCP 协议在关闭连接的四次握手过程中，最终的ACK 是由主动关闭连接的一端（后面统称A端）发出的，如果这个ACK 丢失，对方（后面统称B 端）将重发出最终的FIN，因此A 端必须维护状态信息（TIME_WAIT）允许它重发最终的ACK。如果A 端不维持TIME_WAIT 状态，而是处于CLOSED 状态，那么A 端将响应RST 报文，B 端收到后将此报文解释成一个错误（在java 中会抛出connection reset 的SocketException)。
      因而，要实现TCP 全双工连接的正常终止，必须处理终止过程中四个报文任何一个报文的
      丢失情况，主动关闭连接的A 端必须维持TIME_WAIT 状态。

   4. 允许老的重复报文在网络中消逝

      TCP 报文可能由于路由器异常而“迷途”，在迷途期间，TCP 发送端可能因确认超时而重发这个报文，迷途的报文在路由器修复后也会被送到最终目的地，这个迟到的迷途报文到达时可能会引起问题。在关闭“前一个连接”之后，马上又重新建立起一个相同的IP 和端口之间的“新连接”，“前一个连接”的迷途重复分组在“前一个连接”终止后到达，而被“新连接”收到了。为了避免这个情况，TCP 协议不允许处于TIME_WAIT 状态的连接启动一个新的可用连接，因为TIME_WAIT 状态持续2MSL，就可以保证当成功建立一个新TCP 连接的时候，来自旧连接重复分组已经在网络中消逝。

7. 客户端和服务器都可能会进入time_wait

   - 高并发TCP 服务器中进行主动关闭的一方最好是客户端：因为对于高并发服务器来说文件描述符资源是很重要的资源，如果对于每一个连接都要经历TIME_WAIT 这个2MSL 的时长，势必造成资源不能立马复用的浪费。虽然对于客户端来说TIME_WAIT 状态会占用端口和句柄资源，但是客户端一般很少有并发资源限制，所以客户端执行主动关闭是比较合适的。

   - TIME_WAIT 状态到底会占用什么？

     被占用的是一个五元组：（协议，本地IP，本地端口，远程IP，远程端口）。对于Web 服务器，协议是TCP，本地IP 通常也只有一个，本地端口默认的80 或者443。只剩下远程IP 和远程端口可以变了。如果远程IP 是相同的话，就只有远程端口可以变了。这个只有几万个，所以当同一客户端向服务器建立了大量连接之后，会耗尽可用的五元组导致问题。

8. 客户端断开连接造成time_wait 影响

   - 客户端：
     客户端与服务端进行短连接的TCP 通信，如果在同一台机器上进行压力测试模拟上万的客户请求，并且循环与服务端进行短连接通信，那么这台机器将产生4000 个左右的TIME_WAITsocket，后续的短连接就会产生address already in use : connect 的异常。如果是客户端发起了连接，传输完数据然后主动关闭了连接，这时这个连接在客户端就会处于TIMEWAIT 状态，同时占用了一个本地端口。如果客户端使用短连接请求服务端的资源或者服务，客户端上将有大量的连接处于TIMEWAIT 状态，占用大量的本地端口。最坏的情况就是，本地端口都被用光了，这时将无法再建立新的连接。

9. 客户端断开连接造成time_wait 解决

   - 客户端：

   1. 使用长连接，如果是http，可以使用keepalive
   2. 增加本地端口可用的范围，比如Linux 中调整内核参数：net.ipv4.ip_local_port_range
   3. tcp_tw_reuse 参数用来设置是否可以在新的连接中重用TIME_WAIT 状态的套接字。注
      意，重用的是TIME_WAIT 套接字占用的端口号，而不是TIME_WAIT 套接字的内存等。这个
      参数对客户端有意义，在主动发起连接的时候会在调用的inet_hash_connect()中会检查是否
      可以重用TIME_WAIT 状态的套接字。如果你在服务器段设置这个参数的话，则没有什么作
      用，因为服务器端ESTABLISHED 状态的套接字和监听套接字的本地IP、端口号是相同的，
      没有重用的概念。但并不是说服务器端就没有TIME_WAIT 状态套接字。

   - 服务器：
     不像客户端有端口限制， 处理大量TIME_WAIT Linux 已经优化很好了， 每个处于
     TIME_WAIT 状态下连接内存消耗很少，
     而且也能通过tcp_max_tw_buckets = 262144 配置最大上限，现代机器一般也不缺这点内存。
     tcp_timestamps 参数用来设置是否启用时间戳选项，tcp_tw_recycle 参数用来启用快速回收
     TIME_WAIT 套接字。tcp_timestamps 参数会影响到tcp_tw_recycle 参数的效果。如果没有时
     间戳选项的话，tcp_tw_recycle 参数无效

10. 客户端收到ConnectionReset

    - server 端主动发起了断连
      导致“Connection reset”的原因是服务器端因为某种原因关闭了Connection，而客户端依然
      在读写数据， 此时服务器会返回复位标志“RST” ， 然后此时客户端就会提示
      “java.net.SocketException: Connection reset”。
      服务器返回了“RST”时，如果此时客户端正在从Socket 套接字的输出流中读数据则会提示
      Connection reset”；
      服务器返回了“RST”时，如果此时客户端正在往Socket 套接字的输入流中写数据则会提示
      “Connection reset by peer”。

11. UDP 可靠传输

    - 实现一个最基础的可靠udp 通讯协议，我们只需要提供一个重传机制即可。在这我实现了
      一个简单的可靠udp 协议，这个协议为每一个发送出去的udp 数据包分配一个包id，每次
      接收方收到一个数据包时，都要回应发送方一个ack 对应这个包id。协议通过这种确认机制
      来保证接收方能收到发送方发出的udp 数据包，在发出的时候，发送方应该设置一个计时
      器，超时的话会重传数据包。

    - 具体来说它没做这些事情：

      它没有保证包的有序性。发送方连续发送几个udp 数据包，接收方可以以任何顺序收到这
      几个数据包。如果想要做到有序性，必须由应用层来完成。
      它没做流量控制。发送方连续大量发送数据包会导致网络性能变差，丢包次数增大。
      它没对数据包大小做控制。为了避免IP 层对数据包进行分片，应用层应该要保证每个数据
      包的大小不超过MTU。如果这个数据包会经过广域网（一般情况下）这个值应该不超过576。
      考虑到IP 头的20 字节，udp 头的8 个字节，以及这个协议头的字节。最好每次发送的数据大小在512m以内。

12. socket 选项TCP_NODELAY在网络拥塞控制领域，有一个非常有名的算法叫做Nagle 算法（Nagle algorithm），这是
    使用它的发明人John Nagle 的名字来命名的，John Nagle 在1984 年首次用这个算法来尝
    试解决福特汽车公司的网络拥塞问题（RFC 896）。
    该问题的具体描述是：如果我们的应用程序一次产生1 个字节的数据，而这个1 个字节数
    据又以网络数据包的形式发送到远端服务器，那么就很容易导致网络由于太多的数据包而过
    载。比如，当用户使用Telnet 连接到远程服务器时，每一次击键操作就会产生1 个字节数
    据，进而发送出去一个数据包，所以，在典型情况下，传送一个只拥有1 个字节有效数据
    的数据包，却要发费40 个字节长包头（即ip 头20 字节+tcp 头20 字节）的额外开销，这
    种有效载荷（payload）利用率极其低下的情况被统称之为愚蠢窗口症候群（Silly Window
    Syndrome）。可以看到，这种情况对于轻负载的网络来说，可能还可以接受，但是对于重
    负载的网络而言，就极有可能承载不了而轻易的发生拥塞瘫痪。

    针对上面提到的这个状况，Nagle 算法的改进在于：如果发送端欲多次发送包含少量字符的
    数据包（一般情况下，后面统一称长度小于MSS 的数据包为小包，与此相对，称长度等于
    MSS 的数据包为大包，为了某些对比说明，还有中包，即长度比小包长，但又不足一个MSS
    的包），则发送端会先将第一个小包发送出去，而将后面到达的少量字符数据都缓存起来而
    不立即发送，直到收到接收端对前一个数据包报文段的ACK 确认、或当前字符属于紧急数
    据，或者积攒到了一定数量的数据（比如缓存的字符数据已经达到数据包报文段的最大长度）
    等多种情况才将其组成一个较大的数据包发送出去。
    设置NODELAY 会立即发送，不会延迟。

13. 如何解决tcp 粘包问题

    面向流的协议 
    1）数据包固定大小，每收到该大小字节视为一个包
    2）分隔符，比如\r\n
    3）自定义数据包，header 中指定body 的长度（最常使用）

 

   







