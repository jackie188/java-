## 第二章，数据生成模块

### 目标数据

我们要收集和分析的数据主要包括**页面数据**、**事件数据、曝光数据、启动数据和错误数据。**

**按照日志的内容分类**

#### 页面

页面数据主要记录一个页面的用户访问情况，包括**访问时间、停留时间、页面路径**等信息。

![1619415865700](https://tprzfbucket.oss-cn-beijing.aliyuncs.com/hadoop/202105/17/154419-165594.png)

**所有页面id如下**

```java
home("首页"),
category("分类页"),
discovery("发现页"),
top_n("热门排行"),
favor("收藏页"),
search("搜索页"),
good_list("商品列表页"),
good_detail("商品详情"),
good_spec("商品规格"),
comment("评价"),
comment_done("评价完成"),
comment_list("评价列表"),
cart("购物车"),
trade("下单结算"),
payment("支付页面"),
payment_done("支付完成"),
orders_all("全部订单"),
orders_unpaid("订单待支付"),
orders_undelivered("订单待发货"),
orders_unreceipted("订单待收货"),
orders_wait_comment("订单待评价"),
mine("我的"),
activity("活动"),
login("登录"),
register("注册");
```

**所有页面对象类型如下：**

```java
sku_id("商品skuId"),
keyword("搜索关键词"),
sku_ids("多个商品skuId"),
activity_id("活动id"),
coupon_id("购物券id");
```

**所有来源类型如下：**

```java
promotion("商品推广"),
recommend("算法推荐商品"),
query("查询结果商品"),
activity("促销活动");
```

#### 事件

事件数据主要记录应用内一个具体操作行为，包括**操作类型、操作对象、操作对象描述**等信息。

![1619416283210](https://tprzfbucket.oss-cn-beijing.aliyuncs.com/hadoop/202105/17/154421-792500.png)

**所有动作类型如下：**

```java
favor_add("添加收藏"),
favor_canel("取消收藏"),
cart_add("添加购物车"),
cart_remove("删除购物车"),
cart_add_num("增加购物车商品数量"),
cart_minus_num("减少购物车商品数量"),
trade_add_address("增加收货地址"),
get_coupon("领取优惠券");
```

注：对于下单、支付等业务数据，可从业务数据库获取。

**所有动作目标类型如下：**

```java
sku_id("商品"),
coupon_id("购物券");
```

#### 曝光

曝光数据主要记录页面所曝光的内容，包括**曝光对象，曝光类型**等信息。

![1619416406284](https://tprzfbucket.oss-cn-beijing.aliyuncs.com/hadoop/202104/26/135332-977230.png)

**所有曝光类型如下：**

```java
promotion("商品推广"),
recommend("算法推荐商品"),
query("查询结果商品"),
activity("促销活动");
```

**所有曝光对象类型如下：**

```java
sku_id("商品skuId"),
activity_id("活动id");
```

#### 启动

启动数据记录应用的启动信息。

![1619416581539](https://tprzfbucket.oss-cn-beijing.aliyuncs.com/hadoop/202105/17/154427-352497.png)

**所有启动入口类型如下：**

```java
icon("图标"),
notification("通知"),
install("安装后启动");
```

#### 错误

错误数据记录应用使用过程中的错误信息，包括错误编号及错误信息。

### 数据埋点

#### 主流的埋点方式

目前主流的埋点方式，有代码埋点（前端/后端）、可视化埋点、全埋点三种。

**代码埋点**是通过调用埋点SDK（sdk是一些封装好的库）函数，在需要埋点的业务逻辑功能位置调用接口，上报埋点数据。例如，我们对页面中的某个按钮埋点后，当这个按钮被点击时，可以在这个按钮对应的 OnClick 函数里面调用SDK提供的数据发送接口，来发送数据。

**可视化埋点**只需要研发人员集成采集 SDK，不需要写埋点代码，业务人员就可以通过访问分析平台的“圈选”功能，来“圈”出需要对用户行为进行捕捉的控件，并对该事件进行命名。圈选完毕后，这些配置会同步到各个用户的终端上，由采集 SDK 按照圈选的配置自动进行用户行为数据的采集和发送。

**全埋点**是通过在产品中嵌入SDK，前端自动采集页面上的全部用户行为事件，上报埋点数据，相当于做了一个统一的埋点。然后再通过界面配置哪些数据需要在系统里面进行分析。

#### 埋点数据的基本格式

我们的日志结构大致可分为两类，**一是普通页面埋点日志（包括曝光日志），二是启动日志。**

普通页面日志结构如下，每条日志包含了：

- 当前页面的**页面信息**，
- 所有事件（**动作**）、
- 所有**曝光信息**
- 以及**错误信息**。

除此之外，还包含了一系列公共信息，包括设备信息，地理位置，应用信息等，即下边的common字段。

按照日志的结构划分

- 公共字段：基本所有安卓手机都包含的字段
- 业务字段：埋点上报的字段，有具体的业务类型

```java
{
  "common": {                  -- 公共信息
    "ar": "230000",              -- 地区编码
    "ba": "iPhone",              -- 手机品牌
    "ch": "Appstore",            -- 渠道
    "md": "iPhone 8",            -- 手机型号
    "mid": "YXfhjAYH6As2z9Iq", -- 设备id
    "os": "iOS 13.2.9",          -- 操作系统
    "uid": "485",                 -- 会员id
    "vc": "v2.1.134"             -- app版本号
  },
"actions": [                     --动作(事件)  
    {
      "action_id": "favor_add",   --动作id
      "item": "3",                   --目标id
      "item_type": "sku_id",       --目标类型
      "ts": 1585744376605           --动作时间戳
    }
  ]，
  "displays": [
    {
      "displayType": "query",        -- 曝光类型
      "item": "3",                     -- 曝光对象id
      "item_type": "sku_id",         -- 曝光对象类型
      "order": 1                        --出现顺序
    },
    {
      "displayType": "promotion",
      "item": "6",
      "item_type": "sku_id",
      "order": 2
    },
    {
      "displayType": "promotion",
      "item": "9",
      "item_type": "sku_id",
      "order": 3
    },
    {
      "displayType": "recommend",
      "item": "6",
      "item_type": "sku_id",
      "order": 4
    },
    {
      "displayType": "query ",
      "item": "6",
      "item_type": "sku_id",
      "order": 5
    }
  ],
  "page": {                       --页面信息
    "during_time": 7648,        -- 持续时间毫秒
    "item": "3",                  -- 目标id
    "item_type": "sku_id",      -- 目标类型
    "last_page_id": "login",    -- 上页类型
    "page_id": "good_detail",   -- 页面ID
    "sourceType": "promotion"   -- 来源类型
  },
"err":{                     --错误
"error_code": "1234",      --错误码
    "msg": "***********"       --错误信息
},
  "ts": 1585744374423  --跳入时间戳
}

```

**格式展示**

一条完整的页面日志包括的字段，是一个页面为单位，一个页面一条日志，公共字段，行为动作，曝光，页面信息，错误信息，页面跳转时间五部分。

![1619418096740](https://tprzfbucket.oss-cn-beijing.aliyuncs.com/hadoop/202104/26/142138-394480.png)

**公共字段**

![1619418199252](https://tprzfbucket.oss-cn-beijing.aliyuncs.com/hadoop/202104/26/142320-885637.png)

**行为字段**

里面存储的是数组，数组中存储json对象，每一个对象表示一个动作。

![1619418263093](C:\Users\MrR\AppData\Roaming\Typora\typora-user-images\1619418263093.png)

**曝光字段**

也是一个json数组，里面存储的是json对象，每一个对象表示一个曝光对象。

![1619418354321](https://tprzfbucket.oss-cn-beijing.aliyuncs.com/hadoop/202104/26/142555-449526.png)

**page信息**

json对象，存储的是页面信息

![1619418424720](C:\Users\MrR\AppData\Roaming\Typora\typora-user-images\1619418424720.png)

**error**

错误信息

![1619418454568](C:\Users\MrR\AppData\Roaming\Typora\typora-user-images\1619418454568.png)

**ts**

浏览页面的时间

![1619418483164](C:\Users\MrR\AppData\Roaming\Typora\typora-user-images\1619418483164.png)

> 上面展示的是一个最完整的结构，某一些日志信息可能不完整

**启动日志格式**

启动日志结构相对简单，主要包含**公共信息，启动信息和错误信息。**

```java
{
  "common": {
    "ar": "370000",
    "ba": "Honor",
    "ch": "wandoujia",
    "md": "Honor 20s",
    "mid": "eQF5boERMJFOujcp",
    "os": "Android 11.0",
    "uid": "76",
    "vc": "v2.1.134"
  },
  "start": {   
    "entry": "icon",         --icon手机图标  notice 通知   install 安装后启动
    "loading_time": 18803,  --启动加载时间
    "open_ad_id": 7,        --广告页ID
    "open_ad_ms": 3449,    -- 广告总共播放时间
    "open_ad_skip_ms": 1989   --  用户跳过广告时点
  },
"err":{                     --错误
"error_code": "1234",      --错误码
    "msg": "***********"       --错误信息
},
  "ts": 1585744304000
}

```

**字段信息**

![1619418630427](https://tprzfbucket.oss-cn-beijing.aliyuncs.com/hadoop/202105/17/154440-640393.png)

**common**

公共字段的信息

![1619418657205](https://tprzfbucket.oss-cn-beijing.aliyuncs.com/hadoop/202105/17/154438-477174.png)

**start**

启动信息

![1619418693874](https://tprzfbucket.oss-cn-beijing.aliyuncs.com/hadoop/202105/17/154435-171225.png)

**err**

错误信息

![1619418726506](https://tprzfbucket.oss-cn-beijing.aliyuncs.com/hadoop/202105/17/154436-500888.png)

**时间信息**

![1619418744289](https://tprzfbucket.oss-cn-beijing.aliyuncs.com/hadoop/202104/26/143226-946531.png)

#### 埋点数据上报时机

埋点数据上报时机包括两种方式。

方式一，在离开该页面时，上传在这个页面产生的所有数据（页面、事件、曝光、错误等）。优点，批处理，减少了服务器接收数据压力。缺点，不是特别及时。

方式二，每个事件、动作、错误等，产生后，立即发送。优点，响应及时。缺点，对服务器接收数据压力比较大。

### Json语法

1. 什么是Json?

- JSON 指的是 JavaScript 对象表示法（*J*ava*S*cript *O*bject *N*otation）
- JSON 是轻量级的文本数据交换格式
- JSON 独立于语言 *
- JSON 具有自我描述性，更易理解

2. Json语法？

   JSON 语法是 JavaScript 对象表示法语法的子集。

   - 数据在名称/值对中
   - 数据由逗号分隔
   - 花括号保存对象
   - 方括号保存数组

```java
//1 json名称/值
//JSON 数据的书写格式是：名称/值对。名称/值对包括字段名称（在双引号中），后面写一个冒号，然后是值：
"firstName" : "John"
//2 json值
JSON 值可以是：

    数字（整数或浮点数）
    字符串（在双引号中）
    逻辑值（true 或 false）
    数组（在方括号中）
    对象（在花括号中）
    null
//3 JSON 对象在花括号中书写：
//对象可以包含多个名称/值对：
{ "firstName":"John" , "lastName":"Doe" }
//4 json数组
JSON 数组在方括号中书写：
数组可包含多个对象：
{
"employees": [
{ "firstName":"John" , "lastName":"Doe" },
{ "firstName":"Anna" , "lastName":"Smith" },
{ "firstName":"Peter" , "lastName":"Jones" }
]
}
// 5 json文件

    JSON 文件的文件类型是 ".json"
    JSON 文本的 MIME 类型是 "application/json"

```

### 服务器和jdk安装

安装三台虚拟机或者云主机，然后安装上jdk。

#### 环境变量配置说明

Linux的环境变量可在多个文件中配置，如/etc/profile，/etc/profile.d/*.sh，~/.bashrc等，下面说明上述几个文件之间的关系和区别。

bash的运行模式可分为login shell和non-login shell。

例如，我们通过终端，输入用户名、密码，登录系统之后，得到就是一个login shell，而当我们执行以下命令ssh hadoop103 command，在hadoop103执行command的就是一个non-login shell。

这两种shell的主要区别在于，它们启动时会加载不同的配置文件，login shell启动时会加载/etc/profile，non-login shell启动时会加载~/.bashrc。

而在加载~/.bashrc（实际是~/.bashrc中加载的/etc/bashrc）或/etc/profile时，都会执行如下代码片段，

![1619422099419](https://tprzfbucket.oss-cn-beijing.aliyuncs.com/hadoop/202105/17/154447-60167.png)

因此不管是loginshell还是non-login shell，启动时都会加载/etc/profile.d/*.sh中的环境变量。

### 模拟数据

hadoop100和hadoop101存放生成的日志文件。

#### 使用说明

将application.properties、gmall2020-mock-log-2020-05-10.jar、path.json、logback.xml上传到hadoop100的/opt/module/applog目录下

**配置文件**

- application.properteis文件，可以根据需求生成对应日期的用户行为日志。

```java
# 外部配置打开
logging.config=./logback.xml
#业务日期
mock.date=2020-06-14 //可以在这里修改日期

#模拟数据发送模式
mock.type=log
#mock.type=http
#http模式下，发送的地址
mock.url=http://localhost:8080/applog

#启动次数
mock.startup.count=100
#设备最大值
mock.max.mid=50
#会员最大值
mock.max.uid=500
#商品最大值
mock.max.sku-id=10
#页面平均访问时间
mock.page.during-time-ms=20000
#错误概率 百分比
mock.error.rate=3
#每条日志发送延迟 ms
mock.log.sleep=10
#商品详情来源  用户查询，商品推广，智能推荐, 促销活动
mock.detail.source-type-rate=40:25:15:20
```

- path.json，该文件用来配置访问路径，根据需求，可以灵活配置用户点击路径。

```java
[
  {"path":["home","good_list","good_detail","cart","trade","payment"],"rate":20 },
  {"path":["home","search","good_list","good_detail","login","good_detail","cart","trade","payment"],"rate":50 },
  {"path":["home","mine","orders_unpaid","trade","payment"],"rate":10 },
  {"path":["home","mine","orders_unpaid","good_detail","good_spec","comments","trade","payment"],"rate":10 },
  {"path":["home","mine","orders_unpaid","good_detail","good_spec","comments","home"],"rate":10 }
]
```

- logback配置文件可配置日志生成路径，修改内容如下

```java
<?xml version="1.0" encoding="UTF-8"?>
<configuration>
    <property name="LOG_HOME" value="/opt/module/applog/log" />
    <appender name="console" class="ch.qos.logback.core.ConsoleAppender">
        <encoder>
            <pattern>%msg%n</pattern>
        </encoder>
    </appender>

    <appender name="rollingFile" class="ch.qos.logback.core.rolling.RollingFileAppender">
        <rollingPolicy class="ch.qos.logback.core.rolling.TimeBasedRollingPolicy">
            <fileNamePattern>${LOG_HOME}/app.%d{yyyy-MM-dd}.log</fileNamePattern>
        </rollingPolicy>
        <encoder>
            <pattern>%msg%n</pattern>
        </encoder>
    </appender>

    <!-- 将某一个包下日志单独打印日志 -->
    <logger name="com.atgugu.gmall2020.mock.log.Mocker"
            level="INFO" additivity="true">
        <appender-ref ref="rollingFile" />
         <appender-ref ref="console" />
    </logger>

    <root level="error" additivity="true">
        <appender-ref ref="console" />
        <!-- <appender-ref ref="async-rollingFile" />  -->
    </root>
</configuration>
```

**生成日志**

1. 进入到/opt/module/applog路径，执行以下命令

```java
java -jar gmall2020-mock-log-2020-05-10.jar
```

2. 拷贝生成的日志文件到另一台节点

```java
scp -r applog/ hadoop101:/opt/module/
```

### 集群日志生成脚本

在hadoop100的/home/rzf目录下创建bin目录，这样脚本可以在服务器的任何目录执行。

在bin目录下面创建lg.sh文件，添加下面的内容。

```java
#!/bin/bash
for i in hadoop100 hadoop101; do
    echo "========== $i =========="
    ssh $i "cd /opt/module/applog/; java -jar gmall2020-mock-log-2020-05-10.jar >/dev/null 2>&1 &" 
done 
>/dev/null 2>&1 &" //表示将日志信息写入到黑洞文件中
```

注：

1. /opt/module/applog/为jar包及配置文件所在路径
2. /dev/null代表linux的空设备文件，所有往这个文件里面写入的内容都会丢失，俗称“黑洞”。

- 标准输入0：从键盘获得输入 /proc/self/fd/0 
- 标准输出1：输出到屏幕（即控制台） /proc/self/fd/1 
- 错误输出2：输出到屏幕（即控制台） /proc/self/fd/2

**修改脚本的执行权限**

```java
chmod u+x lg.sh
//至此，可以随意修改时间内进行日志的生成
```