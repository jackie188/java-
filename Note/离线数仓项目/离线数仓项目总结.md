
<!-- TOC -->

- [离线数仓项目总结](#离线数仓项目总结)
  - [如何向别人说明你的项目](#如何向别人说明你的项目)
  - [你对数据仓库的理解](#你对数据仓库的理解)
  - [Hadoop项目经验](#hadoop项目经验)
    - [hdfs多目录存储](#hdfs多目录存储)
    - [集群数据均衡](#集群数据均衡)
    - [项目经验之支持LZO压缩配置](#项目经验之支持lzo压缩配置)

<!-- /TOC -->

## 离线数仓项目总结

### 如何向别人说明你的项目

首先说明项目背景：做的是一个电商项目，后台的数据，使用的是电商系统的业务数据和日志数据。

### 你对数据仓库的理解






### Hadoop项目经验

#### hdfs多目录存储

在hdfs-site.xml文件中配置多目录，注意新挂载磁盘的访问权限问题。

HDFS的DataNode节点保存数据的路径由dfs.datanode.data.dir参数决定，其默认值为`file://${hadoop.tmp.dir}/dfs/data`，这个路径可以决定namenode和datanode存储数据的位置，若服务器有多个磁盘，必须对该参数进行修改。参数应修改为如下的值。

```java
<property>
    <name>dfs.datanode.data.dir</name>
  <value>
    file:///dfs/data1,file:///hd2/dfs/data2,file:///hd3/dfs/data3,file:///hd4/dfs/data4
  </value>
</property>
file://代表是一种协议
```
注意：每台服务器挂载的磁盘不一样，所以每个节点的多目录配置可以不一致。单独配置即可。

#### 集群数据均衡

**节点间数据均衡**

节点之间数据不均衡指的是，有的节点空间占用率达到80%，而有的节点空间占用率才30%，所以需要均衡节点之间的数据。

开启数据均衡命令：
```java
start-balancer.sh -threshold 10
```

开启这一个进程，那么默认就会对数据进行跨界点数据的转移，直到数据均衡为止。

对于参数10，代表的是集群中各个节点的磁盘空间利用率相差不超过10%，可根据实际情况进行调整。

停止数据均衡命令：`stop-balancer.sh`

停止数据均衡后，已经均衡的数据不会恢复。

**磁盘间数据均衡**

这个是hadoop3.x之后的新特性，在这之前是没有的。

比如新加一块磁盘，那么就需要这个命令，让各个磁盘的数据均衡。

（1）生成均衡计划（我们只有一块磁盘，不会生成计划）

hdfs diskbalancer -plan hadoop103(新加磁盘的节点，这个计划其实就是一个json文件)

（2）执行均衡计划

hdfs diskbalancer -execute hadoop103.plan.json(生成的执行计划)

（3）查看当前均衡任务的执行情况

hdfs diskbalancer -query hadoop103

（4）取消均衡任务

hdfs diskbalancer -cancel hadoop103.plan.json

如果是取消执行计划，那么已经均衡的数据，是不会再恢复的。

#### 项目经验之支持LZO压缩配置

1. hadoop本身并不支持lzo压缩，故需要使用twitter提供的hadoop-lzo开源组件。hadoop-lzo需依赖hadoop和lzo进行编译。
2. 将编译好后的hadoop-lzo-0.4.20.jar 放入hadoop-3.1.3/share/hadoop/common/
3. 同步hadoop-lzo-0.4.20.jar到集群中的所有节点。
4. core-site.xml增加配置支持LZO压缩

```java
<configuration>
    <property>
        <name>io.compression.codecs</name>
        <value>
            org.apache.hadoop.io.compress.GzipCodec,
            org.apache.hadoop.io.compress.DefaultCodec,
            org.apache.hadoop.io.compress.BZip2Codec,
            org.apache.hadoop.io.compress.SnappyCodec,
            com.hadoop.compression.lzo.LzoCodec,
            com.hadoop.compression.lzo.LzopCodec
        </value>
    </property>

    <property>
        <name>io.compression.codec.lzo.class</name>
        <value>com.hadoop.compression.lzo.LzoCodec</value>
    </property>
</configuration>
```
同步配置文件到集群中其他的节点。

