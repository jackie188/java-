
<!-- TOC -->

- [第一章，数仓概念及项目需求分析](#第一章数仓概念及项目需求分析)
  - [1.1、什么是数仓？](#11什么是数仓)
  - [1.2、数仓需求分析](#12数仓需求分析)
  - [1.3、技术选型](#13技术选型)
  - [1.4，系统数据流程设计](#14系统数据流程设计)
  - [1.5、系统框架版本选择](#15系统框架版本选择)
  - [1.6、集群规模计算(==重点==)](#16集群规模计算重点)
  - [1.7、服务器集群规划](#17服务器集群规划)

<!-- /TOC -->

## 第一章，数仓概念及项目需求分析

### 1.1、什么是数仓？

![](https://tprzfbucket.oss-cn-beijing.aliyuncs.com/hadoop/202106/09/154944-454057.png)

### 1.2、数仓需求分析

**项目需求**

1. 用户行为数据采集平台搭建，**也就是我们的日志数据**
2. 业务数据采集平台搭建，**也就是存储在mysql中的业务数据**
3. **数据仓库维度建模，也就是对数据仓库分层设计，分多少层合适，这是数据仓库的核心，使用的是维度模型**
4. 分析，设备、会员、商品、地区、活动等电商核心**主题**，统计的报表指标近100个。完全对比中型公司。
5. 采用即席查询工具，随时进行指标分析，比如我们计算日活跃用户，等指标，有固定的计算步骤，数据来源都是一样的，sql已经被我们写好，需要的时候，直接查询即可。但是有一些指标，提前是不能预知的，分析不固定，并且这类型的分析反应要快，这类查询就是即席查询，也就是需求不固定，延迟低，速递必须快。
6. 对集群性能进行监控，发生异常需要报警。使用askabn工具监控集群，防止进程出现故障
7. 元数据管理，主要是针对hive中的元数据进行管理，备份，hive中有很多的表，需要管理，对不同的表之间建立血缘关系，其实就是数仓中的分层关系。表和表之间的关系，建立一个层次，容易理解。
8. 质量监控，也就是验证数仓的计算结果是否准确。

上面的所有需求，是一个比较完善的数据仓库。

- **前五条是数据仓库的核心内容**

**思考问题**

1. 项目技术如何选型？如何选择框架。使用什么采集日志，业务数据等等。
2. 框架版本如何选型（Apache（原生发行版）、CDH（商业版）、HDP）发行版本+框架版本号
3. 服务器使用**物理机还是云主机**？
4. 如何确认集群规模？每一台服务器8t硬盘

### 1.3、技术选型

技术选型主要考虑因素：**数据量大小、业务需求、行业内经验、技术成熟度、开发维护成本、总成本预算**

- 数据采集传输：Flume（采集日志）,Kafka（消息队列，实时采集数据，起缓冲的作用）,Sqoop（采集mysql数据）,Logstash,DataX（可以采集多种数据源的数据，比如redis）
- 数据存储：Mysql（存储业务数据和报表数据）,Hdfs(hive存储数据),HBase,Redis,MongoDB（在实时计算中使用）
- 数据计算：Hive,Tez,Spark,Flink,Storm
  - Hive底层是基于mapreducer计算的框架，而mapreduce计算框架是基于磁盘的
  - Tez是基于内存运算，速度比mapreducer计算块。
  - **本次项目底层的基层引擎是spark。**
- 数据查询：Presto,Druid,Impala,Kylin（即席查询框架）
  - Presto是一个开源的分布式SQL查询引擎，适用于交互式分析查询，数据量支持GB到PB字节。Presto支持在线数据查询，包括Hive, Cassandra, 关系数据库以及专有数据存储。一条Presto查询可以将多个数据源的数据进行合并，可以跨越整个组织进行分析。
- 数据可视化：Echarts（百度）、**Superset**（免费）、QuickBI、DataV（阿里付费）
- 任务调度：**Azkaban**、Oozie
- 集群监控：Zabbix
- 元数据管理：Atlas，做元数据依赖。

> 在这里采集日志的时候为什么会用到kafka，因为在采集日志数据的时候，因为是离线数仓，所以并不需要追求时效性，所以如果说仅仅完成日志传输功能的话，就可以直接使用flume将日志数据传输到hdfs上，因为flume有采集文件的source和写入hdfs的sink接口。
>
> 但是在正常的企业中，都会有实时和离线两套系统，两套系统的话，会公用数据采集系统，那么对于实时系统，通常是采用kafka采集数据，所以对于离线系统，在日志采集这块添加kafka组件，将所有日志首先传输到kafka中，然后在做分流，如果实时系统需要，就从kafka中获取，如果离线系统需要，就可以使用flume从kakfa中采集。这样重用性很高，一套采集系统即可。
>
> kafka在这里相当于一个总线的作用，或者说是缓冲的作用，防止实时数据消费满产生反压。

### 1.4，系统数据流程设计

**离线数据仓库**

![](https://tprzfbucket.oss-cn-beijing.aliyuncs.com/hadoop/202104/26/124054-36867.png)

- flume采集的日志文件只能是本地磁盘上的日志文件，不能采取其他服务器的日志文件，所以flume服务应该部署在日志服务器上面，所以说每一台日志服务器上面都需要部署一台flume。
- 在把kafka数据放到hdfs上面也可以自己写一个consumer消费者，然后把数据写入hdfs上面。在这里采用的是flume组件，在flume中有kafka的source和hdfs的sinK,所以可以直接把kafka中的数据传输到hdfs。
- mysql业务数据使用sqoop导入到hdfs上面，sqoop底层采用的是mr计算方式，因为是离线数仓，所以不需要考虑延迟问题。但是在实时数仓中，考虑数据的延迟，所以采用的是Flink CDC组件。

**实时数据仓库**

![1619413619832](https://tprzfbucket.oss-cn-beijing.aliyuncs.com/hadoop/202104/26/130701-789240.png)

- 所谓的埋点就是嵌入一些代码在前端页面中，如果用户点击页面，就收集用户的一些点击行为行为。
- flume采集日志文件只能采集本地磁盘上面的文件，所以flume需要和产生日志的服务器部署在一台机器上。
- kafka在这里做缓冲的作用，还有一个作用就是作为向实时数仓和离线数仓传输日志的接口，实时和离线可以公用一套日志采集接口。

### 1.5、系统框架版本选择

![](https://tprzfbucket.oss-cn-beijing.aliyuncs.com/hadoop/202104/26/125620-596992.png)

Apache可以说是原生的版本，搭建集群的时候，需要自己去选型各种框架的版本，然后调整兼容性。

CM指的是集群管理器，cdh集群管理器不开源，但是hdp版本的集群管理器开源，所以可以二次开发。

![1638769825527](https://tprzfbucket.oss-cn-beijing.aliyuncs.com/hadoop/202112/06/135027-192584.png)

![1619414172508](https://tprzfbucket.oss-cn-beijing.aliyuncs.com/hadoop/202104/26/131614-28320.png)

### 1.6、集群规模计算(==重点==)

**服务器选型**

![1619414353230](https://tprzfbucket.oss-cn-beijing.aliyuncs.com/hadoop/202104/26/131915-192916.png)

**确定集群规模**

![1638770389996](https://tprzfbucket.oss-cn-beijing.aliyuncs.com/hadoop/202112/06/135952-939520.png)

数据仓库中一般会保存我们的历史数据，不像我们的mysql数据库，一般会存储最新的数据，为什么需要保存历史数据，保存历史数据多给了我们分析数据的一个维度，时间，我们可以分析随着时间变化，我们的数据是如何变化的。数仓中保存的历史数据一般是半年到一年。

考虑到数仓的分层，我们一般让数仓的容量为目前容量的二到三被，也即是大概需要20-30台节点。

然后在考虑数据的压缩，按照压缩率50%计算，那么就需要10-15台节点。

> 一天100G的数据量，集群的规模大概在10-15台左右。

### 1.7、服务器集群规划

| 服务名称           | 子服务                | 服务器hadoop102 | 服务器hadoop103 | 服务器hadoop104 |
| ------------------ | --------------------- | --------------- | --------------- | --------------- |
| HDFS               | NameNode              | √               |                 |                 |
|                    | DataNode              | √               | √               | √               |
|                    | SecondaryNameNode     |                 |                 | √               |
| Yarn               | NodeManager           | √               | √               | √               |
|                    | Resourcemanager       |                 | √               |                 |
| Zookeeper          | Zookeeper Server      | √               | √               | √               |
| Flume(采集日志)    | Flume                 | √               | √               |                 |
| Kafka              | Kafka                 | √               | √               | √               |
| Flume（消费Kafka） | Flume                 |                 |                 | √               |
| Hive               | Hive                  | √               |                 |                 |
| MySQL              | MySQL                 | √               |                 |                 |
| Sqoop              | Sqoop                 | √               |                 |                 |
| Presto             | Coordinator           | √               |                 |                 |
|                    | Worker                |                 | √               | √               |
| Azkaban            | AzkabanWebServer      | √               |                 |                 |
|                    | AzkabanExecutorServer | √               |                 |                 |
| Druid              | Druid                 | √               | √               | √               |
| 服务数总计         |                       | 13              | 8               | 9               |

- 尽量让每一台节点上面的负载均衡。
- 有依赖关系的服务尽量部署在一台节点上面。