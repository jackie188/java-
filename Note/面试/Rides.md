## Rides

![1640429156626](https://tprzfbucket.oss-cn-beijing.aliyuncs.com/hadoop/202112/25/184557-269834.png)

### 什么是redis?

redis是一个高性能的key-value数据库，它是完全开源免费的，而且redis是一个**NOSQL**类型数据库，是为了解决**高并发、高扩展，大数据存储**等一系列的问题而产生的数据库解决方案，是一个非关系型的数据库

### Reids的特点

Redis本质上是一个Key-Value类型的**内存数据库**，很像memcached，整个数据库统统加载在内存当中进行操作，**定期通过异步操作把数据库数据flush到硬盘上进行保存**。

因为是纯内存操作，Redis的性能非常出色，每秒可以处理超过 10万次读写操作，是已知性能最快的Key-Value DB。

Redis的出色之处不仅仅是性能，Redis最大的魅力是支持保存多种数据结构，此外单个value的最大限制是**1GB**，不像 memcached只能保存1MB的数据，因此Redis可以用来实现很多有用的功能，比方说用他的List来做FIFO双向链表，实现一个轻量级的高性 能消息队列服务，用他的Set可以做高性能的tag系统等等。

另外Redis也可以对存入的Key-Value设置expire时间，因此也可以被当作一 个功能加强版的memcached来用。

Redis的主要缺点是数据库容量受到物理内存的限制，不能用作海量数据的高性能读写，因此Redis适合的场景主要局限在较小数据量的高性能操作和运算上。

> String类型：一个String类型的value最大可以存储512M
>
> List类型：list的元素个数最多为2^32-1个，也就是4294967295个。
>
> Set类型：元素个数最多为2^32-1个，也就是4294967295个。
>
> Hash类型：键值对个数最多为2^32-1个，也就是4294967295个。
>
> Sorted set类型：跟Set类型相似。

### 使用redis有哪些好处？

速度快，因为数据存在内存中，类似于HashMap，**HashMap的优势就是查找和操作的时间复杂度都是O(1)**

支持丰富数据类型，支持string，list，set，sorted set，hash

### 缓存有那些类型

缓存是高并发场景下**提高热点数据访问性能**的一个有效手段，在开发项目时会经常使用到。

缓存的类型分为：

- 本地缓存：通常使用HashMap
- 分布式缓存:Rides数据库
- 多级缓存

#### 本地缓存

**本地缓存**就是在**进程的内存**中进行缓存，比如我们的 **JVM** 堆中，可以用 **LRUMap** 来实现，也可以使用 **Ehcache** 这样的工具来实现。

本地缓存是**内存访问**，没有远程交互开销，性能最好，但是受限于单机容量，一般缓存较小且无法扩展。

#### 分布式缓存

**分布式缓存**可以很好得解决这个问题。

分布式缓存一般都具有良好的**水平扩展能力**，对较大数据量的场景也能应付自如。

缺点就是需要进行远程请求，性能不如本地缓存。

#### 多级缓存

为了平衡这种情况，实际业务中一般采用**多级缓存**，本地缓存只**保存访问频率最高的部分热点数据**，其他的热点数据放在分布式缓存中。

在目前的一线大厂中，这也是最常用的缓存方案，单考单一的缓存方案往往难以撑住很多高并发的场景。

### 你为什么需要使用Rides

> 这里回答在实时数仓中为什么使用Rides缓存。

因为我们在做实时计算的时候，数据一般是存储在Hbase数据库中，向一些维度表，如果我们实时计算的时候，需要使用维度表，如果这个时候取Hbase数据库中查询数据的时候，他是基于mr计算模型的，延迟很高，而我们实时计算需要低延迟，所以这个时候就不得不考虑使用一个缓存，将一些热点数据存储在缓存中，这样效率更高。

### 为什么redis需要把所有数据放到内存中?

**Redis为了达到最快的读写速度将数据都读到内存中，并通过异步的方式将数据写入磁盘**。所以redis具有**快速和数据持久化**的特征。如果不将数据放在内存中，磁盘I/O速度为严重影响redis的性能。在内存越来越便宜的今天，redis将会越来越受欢迎。

如果设置了最大使用的内存，则数据已有记录数达到内存限值后不能继续插入新值。

### 缓存数据淘汰算法

不管是本地缓存还是分布式缓存，为了保证较高性能，都是使用内存来保存数据，由于成本和内存限制，当存储的数据超过缓存容量时，需要对缓存的数据进行剔除。

#### 不可能实现的算法 OPT

OPT（OPTimal Replacement，OPT）算法，其所选择的被淘汰的数据将是以后永不使用的，或是在最长（未来）时间内不再被访问的数据。

未来发生的事情是无法预测的，所以该算法从根本上来说是无法实现的，OPT算法对于内存缓存来说，能够提供最高的cache命中（cache hite）率，通过OPT算法也可以衡量其他缓存淘汰的算法的优劣。

#### 无脑算法 FIFO

FIFO（First Input First Output，FIFO）算法算是一种很无脑的淘汰算法，实现起来也很简单，即每次淘汰最先被缓存的数据。

FIFO算法很少会应用在实际项目中，因为该算法并未考虑数据的 “热度”，一般来说，应该是越热的数据越应该晚点淘汰出去，而FIFO算法并未考虑到这一点，所以，该算法的cache命中率一般会比较低。

#### 常见算法 LRU

LRU（Least Recently Used，LRU）算法根据数据的历史访问记录来进行淘汰数据，其核心思想是“如果数据最近被访问过，那么将来被访问的几率也更高”。

LRU最友好的数据模型为具有**时间局部性**的请求队列，每访问一个已缓存的节点，就将该节点转移到队列头部，每次淘汰时，以此淘汰队列尾部节点

采用队列实现的话，每转移一个节点，都需要遍历该队列，为了提高查找效率，通常会采用**Hashmap+双向链表**来实现LRU算法。

使用双向链表记录访问的时间，因为链表的插入效率比较高，所以新插入的元素在前面，旧的数据存储在后面，使用哈希表记录缓存（key,value)，哈希表的查找效率近似于o(1)，发生冲突最坏查询效率也是o(n)，同时哈希表中得记录 (key, (value, key_ptr))，key_ptr 是key在链表中的地址，为了能在O(1)时间内找到该节点，并把节点提升到表头。链表中的key，能快速找到hash中的value，并删除。

#### LFU算法

为了解决LRU算法未考虑频率因素的问题，人们在此基础上又提出了**LRU-K算法**，其中，K代表最近使用的次数，因此LRU可以认为是LRU-1算法，其核心思想是将 **“最近使用过1次”的判断标准扩展为“最近使用过K次”**。

相比LRU，LRU-K需要多维护一个访问历史队列，用于记录所有缓存数据被访问的历史。只有当数据的访问次数达到K次的时候，才将数据放入缓存。当需要淘汰数据时，LRU-K会淘汰第K次访问时间距当前时间最大的数据。

> LFU算法是LRU算法的改进
>
> LRU对于循环出现的数据，缓存命中不高
> 比如，这样的数据，1，1，1，2，2，2，3，4，1，1，1，2，2，2.....
> 当走到3，4的时候，1，2会被淘汰掉，但是后面还有很多1，2
>
> LFU对于交替出现的数据，缓存命中不高
>  比如，1，1，1，2，2，3，4，3，4，3，4，3，4，3，4，3，4......
>  由于前面被（1(3次)，2(2次)）
>  3加入把2淘汰，4加入把3淘汰，3加入把4淘汰，然而3，4才是最需要缓存的，1去到了3次，谁也淘汰不了它了。

一般的剔除策略有 **FIFO** 淘汰最早数据、**LRU** 剔除最近最少使用、和 **LFU** 剔除最近使用频率最低的数据几种策略。

- **noeviction**:返回错误，当内存限制达到并且客户端尝试执行会让更多内存被使用的命令（大部分的写入指令，但DEL和几个例外）

- **allkeys-lru**: 尝试回收最少使用的键（LRU），使得新添加的数据有空间存放。
  
- **volatile-lru**: 尝试回收最少使用的键（LRU），但仅限于在过期集合的键,使得新添加的数据有空间存放。
  
- **allkeys-random**: 回收随机的键使得新添加的数据有空间存放。
  
- **volatile-random**: 回收随机的键使得新添加的数据有空间存放，但仅限于在过期集合的键。
  
- **volatile-ttl**: 回收在过期集合的键，并且优先回收存活时间（TTL）较短的键,使得新添加的数据有空间存放

如果没有键满足回收的前提条件的话，策略**volatile-lru**, **volatile-random**以及**volatile-ttl**就和noeviction 差不多了。

### Memcache和Rides对比

#### Memcache

注意后面会把 **Memcache** 简称为 MC。

先来看看 MC 的特点：

- MC 处理请求时使用**多线程异步 IO 的方式**，可以合理利用 CPU 多核的优势，性能非常优秀；
- MC 功能简单，使用内存存储数据；
- MC 的内存结构以及钙化问题我就不细说了，大家可以查看[官网](https://link.zhihu.com/?target=http%3A//www.memcached.org/about)了解下；
- MC 对缓存的数据可以设置失效期，过期后的数据会被清除；
- 失效的策略采用延迟失效，就是当再次使用数据时检查是否失效；
- 当容量存满时，会对缓存中的数据进行剔除，剔除时除了会对过期 key 进行清理，还会按 LRU 策略对数据进行剔除。

另外，使用 MC 有一些限制，这些限制在现在的互联网场景下很致命，成为大家选择**Redis**、**MongoDB**的重要原因：

- key 不能超过 250 个字节；
- value 不能超过 1M 字节；
- key 的最大失效时间是 30 天；
- 只支持 K-V 结构，不提供持久化和主从同步功能。

#### Redis

先简单说一下 **Redis** 的特点，方便和 MC 比较。

- 与 MC 不同的是，Redis 采用单线程模式处理请求。这样做的原因有 2 个：
  - 一个是因为采用了非阻塞的异步事件处理机制；
  - 另一个是缓存数据都是内存操作 IO 时间不会太长，单线程可以避免线程上下文切换产生的代价。
- **Redis** 支持持久化，所以 Redis 不仅仅可以用作缓存，也可以用作 NoSQL 数据库。
- 相比 MC，**Redis** 还有一个非常大的优势，就是除了 K-V 之外，还支持多种数据格式，例如 list、set、sorted set、hash 等。
- **Redis** 提供主从同步机制，以及 **Cluster** 集群部署能力，能够提供高可用服务。

#### 两者对比

对于 redis 和 memcached 的区别有下面四点。

1.  **redis支持更丰富的数据类型（支持更复杂的应用场景） **：Redis不仅仅支持简单的k/v类型的数据，同时还提供list，set，zset，hash等数据结构的存储。memcache支持简单的数据类型，String。
2.  **Redis支持数据的持久化，可以将内存中的数据保持在磁盘中，重启的时候可以再次加载进行使用,而Memecache把数据全部存在内存之中。**
3.  **集群模式**：memcached没有原生的集群模式，需要依靠客户端来实现往集群中分片写入数据；但是 redis 目前是原生支持 cluster 模式的.
4.  **Memcached是多线程，非阻塞IO复用的网络模型；Redis使用单线程的多路 IO 复用模型。**

![1640848524876](https://tprzfbucket.oss-cn-beijing.aliyuncs.com/hadoop/202112/30/151526-870105.png)

### 为什么要用 redis 而不用 map/guava 做缓存?

缓存分为本地缓存和分布式缓存。以 Java 为例，使用自带的 map 或者 guava 实现的是本地缓存，最主要的特点是轻量以及快速，生命周期随着 jvm 的销毁而结束，**并且在多实例的情况下，每个实例都需要各自保存一份缓存，缓存不具有一致性**。

使用 redis 或 memcached 之类的称为分布式缓存，在多实例的情况下，各实例共用一份缓存数据，缓存具有一致性。**缺点是需要保持 redis 或 memcached服务的高可用，整个程序架构上较为复杂**。

> 这也是在Flink流式处理项目种使用Rides作为缓存的原因，为了保证数据的一致性。

### Rides有那些数据结构

Rides中基础的数据结构有：**String**、**Hash**、**List**、**Set**、**SortedSet**。

但是还有一些高级的数据类型，比如Bitmaps，HyperLogLog，GEO。

通常还会使用**BloomFilter**。

### 如果有大量的key需要设置同一时间过期，一般需要注意什么？

如果大量的key过期时间设置的过于集中，到过期的那个时间点，**Redis**可能会出现短暂的卡顿现象。严重的话会出现缓存雪崩，**我们一般需要在时间上加一个随机值，使得过期时间分散一些**。

**电商首页经常会使用定时任务刷新缓存，可能大量的数据失效时间都十分集中，如果失效时间一样，又刚好在失效的时间点大量用户涌入，就有可能造成缓存雪崩**

### 使用过Redis分布式锁么，它是什么回事？ 

分布式锁的实现方案有：

- 基于mysql的乐观锁
- 基于Rides的分布式锁
- 基于zookeeper的分布式锁。

首先，为了确保分布式锁可用，我们至少要确保锁的实现同时满足以下四个条件：

1. **互斥性**，在任意时刻，只有一个客户端能持有锁。
2. **不会发生死锁**。即使有一个客户端在持有锁的期间崩溃而没有主动解锁，也能保证后续其他客户端能加锁。
3. **具有容错性**。只要大部分的Redis节点正常运行，客户端就可以加锁和解锁。
4. **解铃还须系铃人**：加锁和解锁必须是同一个客户端，客户端自己不能把别人加的锁给解了。
5. 锁最好还是一把**公平锁**
6. 获取锁和释放锁的性能需要好。

**setnx:**将 key 的值设为 value，当且仅当 key 不存在。 若给定的 key 已经存在，则 SETNX 不做任何动作。 SETNX 是SET if Not eXists的简写。 

~~~ java
127.0.0.1:6379> expire lock 10
(integer) 1
127.0.0.1:6379> ttl lock
8
127.0.0.1:6379> get lock
(nil)
~~~

**基于Rides的分布式锁**

![1640431577210](https://tprzfbucket.oss-cn-beijing.aliyuncs.com/hadoop/202112/25/192618-433400.png)

**redis实现分布式锁问题**

如果出现了这么一个问题：如果`setnx`是成功的，但是`expire`设置失败，那么后面如果出现了释放锁失败的问题，那么这个锁永远也不会被得到，业务将被锁死？

之所以产生这样的情况，是因为这两个命令的执行不是原子操作的，如果是原子操作，就不会发生这样的问题。

解决的办法：使用`set`的命令，同时设置锁和过期时间

`set`参数：

```twxt
set key value [EX seconds] [PX milliseconds] [NX|XX]
EX seconds：设置失效时长，单位秒
PX milliseconds：设置失效时长，单位毫秒
NX：key不存在时设置value，成功返回OK，失败返回(nil)
XX：key存在时设置value，成功返回OK，失败返回(nil)
```

这个命令相当于把上面获取锁和释放锁的命令组成一个原子操作。

### 假如Redis里面有1亿个key，其中有10w个key是以某个固定的已知的前缀开头的，如何将它们全部找出来？

使用**keys**指令可以扫出指定模式的key列表。

### 如果这个redis正在给线上的业务提供服务，那使用keys指令会有什么问题？ 

这个时候你要回答Redis关键的一个特性：Redis的**单线程**的。keys指令会导致线程阻塞一段时间，线上服务会停顿，直到指令执行完毕，服务才能恢复。

这个时候可以使用**scan**指令，**scan**指令可以无阻塞的提取出指定模式的key列表，但是会有一定的重复概率，在客户端做一次去重就可以了，但是整体所花费的时间会比直接用keys指令长。

**不过，增量式迭代命令也不是没有缺点的： 举个例子， 使用 SMEMBERS 命令可以返回集合键当前包含的所有元素， 但是对于 SCAN 这类增量式迭代命令来说， 因为在对键进行增量式迭代的过程中， 键可能会被修改， 所以增量式迭代命令只能对被返回的元素提供有限的保证 。**

### 使用过Redis做异步队列么，你是怎么用的？ 

一般使用list结构作为队列，**rpush**生产消息，**lpop**消费消息。当lpop没有消息的时候，要适当sleep一会再重试。

### 如果对方追问可不可以不用sleep呢？ 

list还有个指令叫**blpop**，在没有消息的时候，它会阻塞住直到消息到来。

### 如果对方接着追问能不能生产一次消费多次呢？ 

使用pub/sub主题订阅者模式，可以实现 1:N 的消息队列。

### 如果对方继续追问 pub/sub有什么缺点？ 

在消费者下线的情况下，生产的消息会丢失，得使用专业的消息队列如**RocketMQ**等。

### Redis是怎么持久化的？服务主从数据怎么交互的？ 

RDB做镜像全量持久化，AOF做增量持久化。因为RDB会耗费较长时间，不够实时，在停机的时候会导致大量丢失数据，所以需要AOF来配合使用。

在redis实例重启时，会使用RDB持久化文件重新构建内存，再使用AOF重放近期的操作指令来实现完整恢复重启之前的状态。

**这里很好理解，把RDB理解为一整个表全量的数据，AOF理解为每次操作的日志就好了，服务器重启的时候先把表的数据全部搞进去，但是他可能不完整，你再回放一下日志，数据不就完整了嘛。不过Redis本身的机制是 AOF持久化开启且存在AOF文件时，优先加载AOF文件；AOF关闭或者AOF文件不存在时，加载RDB文件；加载AOF/RDB文件城后，Redis启动成功； AOF/RDB文件存在错误时，Redis启动失败并打印错误信息**

### 那如果突然机器掉电会怎样？ 

取决于AOF日志sync属性的配置，如果不要求性能，在每条写指令时都sync一下磁盘，就不会丢失数据。但是在高性能的要求下每次都sync是不现实的，一般都使用定时sync，比如1s1次，这个时候最多就会丢失1s的数据。

在aof这种方式持久化时候，追加写日志的方式有三种：

- always(每次）
  - 每次写入操作均同步到AOF文件中，**数据零误差，性能较低**，不建议使用。
- everysec（每秒）
  - 每秒将缓冲区中的指令同步到AOF文件中，**数据准确性较高，性能较高在系统突然宕机的情况下丢失1秒内的数据**，，建议使用，也是默认配置
- no（系统控制）
  - 由操作系统控制每次同步到AOF文件的周期，整体**过程不可控**

### RDB的原理是什么？ 

你给出两个词汇就可以了，**fork和cow**。fork是指redis通过创建子进程来进行RDB操作，cow指的是**copy on write**，子进程创建后，父子进程共享数据段，父进程继续提供读写服务，写脏的页面数据会逐渐和子进程分离开来。

### Redis的同步机制了解么？ 

Redis可以使用主从同步，从从同步。第一次同步时，主节点做一次**bgsave**，并同时将后续修改操作记录到内存buffer，待完成后将RDB文件全量同步到复制节点，复制节点接受完成后将RDB镜像加载到内存。加载完成后，再通知主节点将期间修改的操作记录同步到复制节点进行重放就完成了同步过程。

后续的增量数据通过AOF日志同步即可，有点类似数据库的binlog。

### 是否使用过Redis集群，集群的高可用怎么保证，集群的原理是什么？ 

**Redis Sentinal** 着眼于高可用，在master宕机时会自动将slave提升为master，继续提供服务。

**Redis Cluster** 着眼于扩展性，在单个redis内存不足时，使用Cluster进行分片存储。

### Redis雪崩了解么？

1. 系统平稳运行过程中，忽然数据库连接量激增
2. 应用服务器无法及时处理请求
3. 大量408，500错误页面出现
4. 客户反复刷新页面获取数据
5. 数据库崩溃
6. 应用服务器崩溃
7. 重启应用服务器无效
8. Redis服务器崩溃
9. Redis集群崩溃
10. 重启数据库后再次被瞬间流量放倒

**举个简单的例子**：如果所有首页的Key失效时间都是12小时，中午12点刷新的，我零点有个秒杀活动大量用户涌入，假设当时每秒 6000 个请求，本来缓存在可以扛住每秒 5000 个请求，但是缓存当时所有的Key都失效了。此时 1 秒 6000 个请求全部落数据库，数据库必然扛不住，它会报一下警，真实情况可能DBA都没反应过来就直接挂了。

![1640432503225](https://tprzfbucket.oss-cn-beijing.aliyuncs.com/hadoop/202112/25/194144-423893.png)

处理缓存雪崩简单，在批量往**Redis**存数据的时候，把每个Key的失效时间都加个随机值就好了，这样可以保证数据不会在同一时间大面积失效

~~~ java
setRedis（Key，value，time + Math.random() * 10000）；
~~~

或者设置热点数据永远不过期，有更新操作就更新缓存就好了（比如运维更新了首页商品，那你刷下缓存就完事了，不要设置过期时间），电商首页的数据也可以用这个操作，保险。

如果**Redis**是集群部署，将热点数据均匀分布在不同的**Redis**库中也能避免全部失效的问题

### 缓存穿透

缓存穿透是指缓存和数据库中都没有的数据，而用户不断发起请求，我们数据库的 id 都是1开始自增上去的，如发起为id值为 -1 的数据或 id 为特别大不存在的数据。这时的用户很可能是攻击者，攻击会导致数据库压力过大，严重会击垮数据库。

![1640432778786](https://tprzfbucket.oss-cn-beijing.aliyuncs.com/hadoop/202112/25/194619-978168.png)

**像这种你如果不对参数做校验，数据库id都是大于0的，我一直用小于0的参数去请求你，每次都能绕开Redis直接打到数据库，数据库也查不到，每次都这样，并发高点就容易崩掉了。**

### 缓存击穿

- 系统平稳运行过程中
- 数据库连接量瞬间激增
- Redis服务器无大量key过期
- Redis内存平稳，无波动
- Redis服务器CPU正常
- 数据库崩溃

缓存雪崩是因为大面积的缓存失效，打崩了DB，而缓存击穿不同的是**缓存击穿**是指一个Key非常热点，在不停的扛着大并发，大并发集中对这一个点进行访问，当这个Key在失效的瞬间，持续的大并发就穿破缓存，直接请求数据库，就像在一个完好无损的桶上凿开了一个洞。

> 缓存穿透类似偷袭，绕过radis，袭击数据库。缓存击穿类似正面硬刚，一直进攻一个地方，直到失效时一起涌入攻击数据库。缓存雪崩类似鬼子进村。

### 如何解决上面遇到的问题

**缓存穿透**我会在接口层增加校验，比如用户鉴权校验，参数做校验，不合法的参数直接代码Return，比如：id 做基础校验，id <=0的直接拦截等。

还有我记得**Redis**还有一个高级用法**布隆过滤器（Bloom Filter）**这个也能很好的防止**缓存穿透**的发生，他的原理也很简单就是利用高效的数据结构和算法快速判断出你这个Key是否在数据库中存在，不存在你return就好了，存在你就去查了DB刷新KV再return。

**缓存击穿**的话，设置热点数据永远不过期。或者加上互斥锁就能搞定了

### Rides为什么那么快

关系型数据库跟Redis本质上的区别

![1640433477178](https://tprzfbucket.oss-cn-beijing.aliyuncs.com/hadoop/202112/25/195757-651161.png)

**Redis**采用的是基于内存，采用的是单进程单线程模型的 KV 数据库，由C语言编写，官方提供的数据是可以达到100000+的**QPS（每秒内查询次数）**。

- 完全基于内存，绝大部分请求是纯粹的**内存操作**，非常快速。它的，数据存在内存中，类似于**HashMap**，**HashMap**的优势就是查找和操作的时间复杂度都是O(1)；
- 数据结构简单，对数据操作也简单，**Redis**中的数据结构是专门进行设计的；
- 采用单线程，避免了不必要的**上下文切换和竞争条件**，也不存在多进程或者多线程导致的切换而消耗 **CPU**，不用去考虑各种锁的问题，不存在加锁释放锁操作，没有因为可能出现死锁而导致的性能消耗；
- 使用多路I/O复用模型，非阻塞IO；
- 使用底层模型不同，它们之间底层实现方式以及与客户端之间通信的应用协议不一样，**Redis**直接自己构建了VM 机制 ，因为一般的系统调用系统函数的话，会浪费一定的时间去移动和请求；

Rides既然是单线程的，那么现在服务器都是多核心的，会浪费性能吧

是的他是单线程的，但是，我们可以通过在单机开多个**Redis实例**

### 既然提到了单机会有瓶颈，那你们是怎么解决这个瓶颈的？ 

我们用到了集群的部署方式也就是**Redis cluster**，并且是主从同步读写分离，类似**Mysql**的主从同步，**Redis cluster** 支撑 N 个 **Redis master node**，每个**master node**都可以挂载多个 **slave node**。

这样整个 **Redis** 就可以横向扩容了。如果你要支撑更大数据量的缓存，那就横向扩容更多的 **master** 节点，每个 **master** 节点就能存放更多的数据了。

### 他们之间是怎么进行数据交互的？以及Redis是怎么进行持久化的？Redis数据都在内存中，一断电或者重启不就没有了嘛？ 

是的，持久化的话是**Redis**高可用中比较重要的一个环节，因为**Redis**数据在内存的特性，持久化必须得有，我了解到的持久化是有两种方式的。

- RDB：**RDB** 持久化机制，是对 **Redis** 中的数据执行**周期性**的持久化。
- AOF：**AOF** 机制对每条写入命令作为日志，以 **append-only** 的模式写入一个日志文件中，因为这个模式是只追加的方式，所以没有任何磁盘寻址的开销，所以很快，有点像Mysql中的**binlog**。

两种方式都可以把**Redis**内存中的数据持久化到磁盘上，然后再将这些数据备份到别的地方去，**RDB**更适合做**冷备**，**AOF**更适合做**热备**，比如我杭州的某电商公司有这两个数据，我备份一份到我杭州的节点，再备份一个到上海的，就算发生无法避免的自然灾害，也不会两个地方都一起挂吧，这**灾备**也就是**异地容灾**。

**tip：两种机制全部开启的时候，Redis在重启的时候会默认使用AOF去重新构建数据，因为AOF的数据是比RDB更完整的。**

### 那这两种机制各自优缺点是啥？ 

我先说**RDB**吧

#### 优点：

他会生成多个数据文件，每个数据文件分别都代表了某一时刻**Redis**里面的数据，这种方式，有没有觉得很适合做**冷备**，完整的数据运维设置定时任务，定时同步到远端的服务器，比如阿里的云服务，这样一旦线上挂了，你想恢复多少分钟之前的数据，就去远端拷贝一份之前的数据就好了。

**RDB**对**Redis**的性能影响非常小，是因为在同步数据的时候他只是**fork**了一个子进程去做持久化的，而且他在数据恢复的时候速度比**AOF**来的快。

#### 缺点：

**RDB**都是快照文件，都是默认五分钟甚至更久的时间才会生成一次，这意味着你这次同步到下次同步这中间五分钟的数据都很可能全部丢失掉。**AOF**则最多丢一秒的数据，**数据完整性**上高下立判。

还有就是**RDB**在生成数据快照的时候，如果文件很大，客户端可能会暂停几毫秒甚至几秒，你公司在做秒杀的时候他刚好在这个时候**fork**了一个子进程去生成一个大快照，哦豁，出大问题。

我们再来说说**AOF**

#### 优点：

上面提到了，**RDB**五分钟一次生成快照，但是**AOF**是一秒一次去通过一个后台的线程`fsync`操作，那最多丢这一秒的数据。

**AOF**在对日志文件进行操作的时候是以`append-only`的方式去写的，他只是追加的方式写数据，自然就少了很多磁盘寻址的开销了，写入性能惊人，文件也不容易破损。

**AOF**的日志是通过一个叫**非常可读**的方式记录的，这样的特性就适合做**灾难性数据误删除**的紧急恢复了，比如公司的实习生通过**flushall**清空了所有的数据，只要这个时候后台重写还没发生，你马上拷贝一份**AOF**日志文件，把最后一条**flushall**命令删了就完事了。

**tip：我说的命令你们别真去线上系统操作啊，想试去自己买的服务器上装个Redis试，别到时候来说，敖丙真是个渣男，害我把服务器搞崩了，Redis官网上的命令都去看看，不要乱试！！！**

#### 缺点：

一样的数据，**AOF**文件比**RDB**还要大。

**AOF**开启后，**Redis**支持写的**QPS**会比**RDB**支持写的要低，他不是每秒都要去异步刷新一次日志嘛**fsync**，当然即使这样性能还是很高，我记得**ElasticSearch**也是这样的，异步刷新缓存区的数据去持久化，为啥这么做呢，不直接来一条怼一条呢，那我会告诉你这样性能可能低到没办法用的，大家可以思考下为啥哟。

### 那两者怎么选择？

**我全都要**，你单独用**RDB**你会丢失很多数据，你单独用**AOF**，你数据恢复没**RDB**来的快，真出什么时候第一时间用**RDB**恢复，然后**AOF**做数据补全。

### 你提到了高可用，Redis还有其他保证集群高可用的方式么？

还有哨兵集群**sentinel**。

**哨兵的作用**

- 监控 
  - 不断的检查master和slave是否正常运行。 
  - master存活检测、master与slave运行情况检测
- 通知（提醒） 
  - 当被监控的服务器出现问题时，向其他（哨兵间，客户端）发送通知
- 自动故障转移 
  - 断开master与slave连接，选取一个slave作为master，将其他slave连接到新的master，并告知客户端新的服务器地址

哨兵必须用三个实例去保证自己的健壮性的，哨兵+主从并**不能保证数据不丢失**，但是可以保证集群的**高可用**。

为啥必须要三个实例呢？我们先看看两个哨兵会咋样。

![1640433980129](https://tprzfbucket.oss-cn-beijing.aliyuncs.com/hadoop/202112/25/200723-746157.png)

master宕机了 s1和s2两个哨兵只要有一个认为你宕机了就切换了，并且会选举出一个哨兵去执行故障，但是这个时候也需要大多数哨兵都是运行的。

那这样有啥问题呢？M1宕机了，S1没挂那其实是OK的，但是整个机器都挂了呢？哨兵就只剩下S2个裸屌了，没有哨兵去允许故障转移了，虽然另外一个机器上还有R1，但是故障转移就是不执行。

经典的哨兵集群是这样的：

![1640434055277](https://tprzfbucket.oss-cn-beijing.aliyuncs.com/hadoop/202112/25/200737-351997.png)

M1所在的机器挂了，哨兵还有两个，两个人一看他不是挂了嘛，那我们就选举一个出来执行故障转移不就好了。

总结下哨兵组件的主要功能：

- 集群监控：负责监控 Redis master 和 slave 进程是否正常工作。
- 消息通知：如果某个 **Redis** 实例有故障，那么哨兵负责发送消息作为报警通知给管理员。
- 故障转移：如果 master node 挂掉了，会自动转移到 slave node 上。
- 配置中心：如果故障转移发生了，通知 client 客户端新的 master 地址。

### 能说一下主从之间的数据怎么同步的么？

主从同步总的来说分为三步骤：

1. 建立连接阶段：建立socket连接
2. 数据同步阶段：
   1. 第一部分是rdb全量数据复制过程
   2. 第二部是缓冲区的部分复制过程
3. 命令传播阶段：就是master将接收到的命令发送给slave进行执行，保证数据的同步性。

主从同步和前面提到的数据持久化的**RDB**和**AOF**有着比密切的关系了。

我先说下为啥要用主从这样的架构模式，前面提到了单机**QPS**是有上限的，而且**Redis**的特性就是必须支撑读高并发的，那你一台机器又读又写，**这谁顶得住啊**，不当人啊！但是你让这个master机器去写，数据同步给别的slave机器，他们都拿去读，分发掉大量的请求那是不是好很多，而且扩容的时候还可以轻松实现水平扩容。

![1640434174172](https://tprzfbucket.oss-cn-beijing.aliyuncs.com/hadoop/202112/25/201002-536261.png)

**他们数据怎么同步的呢？**

你启动一台slave 的时候，他会发送一个**psync**命令给master ，如果是这个slave第一次连接到master，他会触发一个全量复制。master就会启动一个线程，生成**RDB**快照，还会把新的写请求都缓存在内存中，**RDB**文件生成后，master会将这个**RDB**发送给slave的，slave拿到之后做的第一件事情就是写进本地的磁盘，然后加载进内存，然后master会把内存里面缓存的那些新命名都发给slave。

### 数据传输的时候断网了或者服务器挂了怎么办啊？ 

传输过程中有什么网络问题啥的，会自动重连的，并且连接之后会把缺少的数据补上的。

**大家需要记得的就是，RDB快照的数据生成的时候，缓存区也必须同时开始接受新请求，不然你旧的数据过去了，你在同步期间的增量数据咋办？是吧？**

### 那说了这么多你能说一下他的内存淘汰机制么，来手写一下LRU代码？

Rides中数据的删除方案，定时删除，惰性删除，定期删除三种，其中定期删除是定时删除和惰性删除的折中方案。

**Redis**的过期策略，是有**定期删除+惰性删除**两种。

定期好理解，默认100ms就随机抽一些设置了过期时间的key，去检查是否过期，过期了就删了。

### 为啥不扫描全部设置了过期时间的key呢？ 

假如Redis里面所有的key都有过期时间，都扫描一遍？那太恐怖了，而且我们线上基本上也都是会设置一定的过期时间的。全扫描跟你去查数据库不带where条件不走索引全表扫描一样，100ms一次，Redis累都累死了。

### 如果一直没随机到很多key，里面不就存在大量的无效key了？ 

好问题，**惰性删除**，见名知意，惰性嘛，我不主动删，我懒，我等你来查询了我看看你过期没，过期就删了还不给你返回，没过期该怎么样就怎么样。

### 最后就是如果的如果，定期没删，我也没查询，那可咋整？ 

**内存淘汰机制**！

作为缓存系统都要定期清理无效数据，就需要一个主键失效和淘汰策略.

在Redis当中，有生存期的key被称为volatile。在创建缓存时，要为给定的key设置生存期，当key过期的时候（生存期为0），它可能会被删除。

**1、影响生存时间的一些操作**

生存时间可以通过使用 DEL 命令来删除整个 key 来移除，或者被 SET 和 GETSET 命令覆盖原来的数据，也就是说，修改key对应的value和使用另外相同的key和value来覆盖以后，当前数据的生存时间不同。

比如说，对一个 key 执行INCR命令，对一个列表进行LPUSH命令，或者对一个哈希表执行HSET命令，这类操作都不会修改 key 本身的生存时间。另一方面，如果使用RENAME对一个 key 进行改名，那么改名后的 key的生存时间和改名前一样。

RENAME命令的另一种可能是，尝试将一个带生存时间的 key 改名成另一个带生存时间的 another_key ，这时旧的 another_key (以及它的生存时间)会被删除，然后旧的 key 会改名为 another_key ，因此，新的 another_key 的生存时间也和原本的 key 一样。使用PERSIST命令可以在不删除 key 的情况下，移除 key 的生存时间，让 key 重新成为一个persistent key 。

**2、如何更新生存时间**

可以对一个已经带有生存时间的 key 执行EXPIRE命令，新指定的生存时间会取代旧的生存时间。过期时间的精度已经被控制在1ms之内，主键失效的时间复杂度是O（1），

EXPIRE和TTL命令搭配使用，TTL可以查看key的当前生存时间。设置成功返回 1；当 key 不存在或者不能为 key 设置生存时间时，返回 0 。

最大缓存配置 在 redis 中，允许用户设置最大使用内存大小 server.maxmemory 默认为0，没有指定最大缓存，如果有新的数据添加，超过最大内存，则会使redis崩溃，所以一定要设置。redis 内存数据集大小上升到一定大小的时候，就会实行数据淘汰策略。redis 提供 6种数据淘汰策略：

**volatile-lru：** 从已设置过期时间的数据集（ `server.db\[i\].expires`）中挑选最近最少使用的数据淘汰

**volatile-ttl：** 从已设置过期时间的数据集（ `server.db\[i\].expires`）中挑选将要过期的数据淘汰

**volatile-random：** 从已设置过期时间的数据集（ `server.db\[i\].expires`）中任意选择数据淘汰

**allkeys-lru：** 从数据集（ `server.db\[i\].dict`）中挑选最近最少使用的数据淘汰

**allkeys-random：** 从数据集（ `server.db\[i\].dict`）中任意选择数据淘汰

**no-enviction（驱逐）：** 禁止驱逐数据

注意这里的6种机制，volatile和allkeys规定了是对已设置过期时间的数据集淘汰数据还是从全部数据集淘汰数据，后面的lru、ttl以及random是三种不同的淘汰策略，再加上一种no-enviction永不回收的策略。

使用策略规则：

**1、** 如果数据呈现幂律分布，也就是一部分数据访问频率高，一部分数据访问频率低，则使用allkeys-lru**2、** 如果数据呈现平等分布，也就是所有的数据访问频率都相同，则使用allkeys-random

三种数据淘汰策略：

ttl和random比较容易理解，实现也会比较简单。主要是Lru最近最少使用淘汰策略，设计上会对key 按失效时间排序，然后取最先失效的key进行淘汰

官网上给到的内存淘汰机制是以下几个：

- **noeviction**:返回错误当内存限制达到并且客户端尝试执行会让更多内存被使用的命令（大部分的写入指令，但DEL和几个例外）

- **allkeys-lru**: 尝试回收最少使用的键（LRU），使得新添加的数据有空间存放。

- **volatile-lru**: 尝试回收最少使用的键（LRU），但仅限于在过期集合的键,使得新添加的数据有空间存放。

- **allkeys-random**: 回收随机的键使得新添加的数据有空间存放。

- **volatile-random**: 回收随机的键使得新添加的数据有空间存放，但仅限于在过期集合的键。

- **volatile-ttl**: 回收在过期集合的键，并且优先回收存活时间（TTL）较短的键,使得新添加的数据有空间存放。

  如果没有键满足回收的前提条件的话，策略**volatile-lru**, **volatile-random**以及**volatile-ttl**就和noeviction 差不多了。

### redis的并发竞争问题如何解决?

Redis为单进程单线程模式，采用队列模式将并发访问变为串行访问。Redis本身没有锁的概念，Redis对于多个客户端连接并不存在竞争，但是在Jedis客户端对Redis进行并发访问时会发生连接超时、数据转换错误、阻塞、客户端关闭连接等问题，这些问题均是

由于客户端连接混乱造成。对此有2种解决方法：

- 客户端角度，为保证每个客户端间正常有序与Redis进行通信，对连接进行池化，同时对客户端读写Redis操作采用内部锁synchronized。
- 服务器角度，利用setnx实现锁。注：对于第一种，需要应用程序自己处理资源的同步，可以使用的方法比较通俗，可以使用synchronized也可以使用lock；第二种需要用到Redis的setnx命令，但是需要注意一些问题。

这个也是线上非常常见的一个问题，就是多客户端同时并发写一个key，可能本来应该先到的数据后到了，导致数据版本错了。或者是多客户端同时获取一个key，修改值之后再写回去，只要顺序错了，数据就错了。

而且redis自己就有天然解决这个问题的CAS类的乐观锁方案

![1640852898342](https://tprzfbucket.oss-cn-beijing.aliyuncs.com/hadoop/202112/30/162819-520419.png)

### redis常见性能问题和解决方案

Master写内存快照，save命令调度rdbSave函数，会阻塞主线程的工作，当快照比较大时对性能影响是非常大的，会间断性暂停服务，所以Master最好不要写内存快照。

Master AOF持久化，如果不重写AOF文件，这个持久化方式对性能的影响是最小的，但是AOF文件会不断增大，AOF文件过大会影响Master重启的恢复速度。

Master最好不要做任何持久化工作，包括内存快照和AOF日志文件，特别是不要启用内存快照做持久化,如果数据比较关键，某个Slave开启AOF备份数据，策略为每秒同步一次。

Master调用BGREWRITEAOF重写AOF文件，AOF在重写的时候会占大量的CPU和内存资源，导致服务load过高，出现短暂服务暂停现象。

Redis主从复制的性能问题，为了主从复制的速度和连接的稳定性，Slave和Master最好在同一个局域网内。

### Rides是单线程的还是多线程的

#### 为什么在最开始Rides被设计为单线程

Redis作为一个成熟的分布式缓存框架，它由很多个模块组成，如网络请求模块、索引模块、存储模块、高可用集群支撑模块、数据操作模块等。

很多人说Redis是单线程的，就认为Redis中所有模块的操作都是单线程的，其实这是不对的。

我们所说的Redis单线程，指的是"其网络IO和键值对读写是由一个线程完成的"，也就是说，**Redis中只有网络请求模块和数据操作模块是单线程的。而其他的如持久化存储模块、集群支撑模块等是多线程的。**

所以说，Redis中并不是没有多线程模型的，早在Redis 4.0的时候就已经针对部分命令做了多线程化。

**那么，为什么网络操作模块和数据存储模块最初并没有使用多线程呢？**

这个问题的答案比较简单！因为："没必要！"

为什么没必要呢？我们先来说一下，什么情况下要使用多线程？

##### 多线程的使用场景

一个计算机程序在执行的过程中，主要需要进行两种操作分别是**读写操作和计算操作**。

**其中读写操作主要是涉及到的就是I/O操作，其中包括网络I/O和磁盘I/O。计算操作主要涉及到CPU**。

**而多线程的目的，就是通过并发的方式来提升I/O的利用率和CPU的利用率。**

那么，Redis需不需要通过多线程的方式来提升提升I/O的利用率和CPU的利用率呢？

首先，我们可以肯定的说，Redis不需要提升CPU利用率，因为**Redis的操作基本都是基于内存的，CPU资源根本就不是Redis的性能瓶颈。**

**所以，通过多线程技术来提升Redis的CPU利用率这一点是完全没必要的。**

那么，使用多线程技术来提升Redis的I/O利用率呢？是不是有必要呢？

Redis确实是一个I/O操作密集的框架，他的数据操作过程中，会有大量的网络I/O和磁盘I/O的发生。要想提升Redis的性能，是一定要提升Redis的I/O利用率的，这一点毋庸置疑。

但是，**提升I/O利用率，并不是只有采用多线程技术这一条路可以走！**、

#### 多线程的弊端

Java中的多线程技术，如内存模型、锁、CAS等，这些都是Java中提供的一些在多线程情况下保证线程安全的技术。

线程安全：是编程中的术语，指某个函数、函数库在并发环境中被调用时，能够正确地处理多个线程之间的共享变量，使程序功能正确完成。

和Java类似，所有支持多线程的编程语言或者框架，都不得不面对的一个问题，那就是如何解决多线程编程模式带来的共享资源的并发控制问题。

**虽然，采用多线程可以帮助我们提升CPU和I/O的利用率，但是多线程带来的并发问题也给这些语言和框架带来了更多的复杂性。而且，多线程模型中，多个线程的互相切换也会带来一定的性能开销。**

所以，在提升I/O利用率这个方面上，Redis并没有采用多线程技术，而是选择了**多路复用 I/O**技术。

**小结**

Redis并没有在网络请求模块和数据操作模块中使用多线程模型，主要是基于以下四个原因：

- Redis 操作基于内存，绝大多数操作的性能瓶颈不在 CPU
- 使用单线程模型，可维护性更高，开发，调试和维护的成本更低
- 单线程模型，避免了线程间切换带来的性能开销
- 在单线程中使用多路复用 I/O技术也能提升Redis的I/O利用率

还是要记住：Redis并不是完全单线程的，只是有关键的网络IO和键值对读写是由一个线程完成的。

#### Rides多路复用

多路复用这个词，相信很多人都不陌生。我之前的很多文章中也够提到过这个词。

其中在介绍Linux IO模型的时候我们提到过它、在介绍HTTP/2的原理的时候，我们也提到过他。

那么，Redis的多路复用技术和我们之前介绍的又有什么区别呢？

这里先讲讲**Linux多路复用技术，就是多个进程的IO可以注册到同一个管道上，这个管道会统一和内核进行交互。当管道中的某一个请求需要的数据准备好之后，进程再把对应的数据拷贝到用户空间中。**

![1640853692277](https://tprzfbucket.oss-cn-beijing.aliyuncs.com/hadoop/202112/30/164132-927037.png)

也就是说，通过一个线程来处理多个IO流。

IO多路复用在Linux下包括了三种，select、poll、epoll，抽象来看，他们功能是类似的，但具体细节各有不同。

其实，Redis的IO多路复用程序的所有功能都是通过包装操作系统的IO多路复用函数库来实现的。每个IO多路复用函数库在Redis源码中都有对应的一个单独的文件。

![1640853762838](https://tprzfbucket.oss-cn-beijing.aliyuncs.com/hadoop/202112/30/164243-110547.png)

在Redis 中，每当一个套接字准备好执行连接应答、写入、读取、关闭等操作时，就会产生一个文件事件。因为一个服务器通常会连接多个套接字，所以多个文件事件有可能会并发地出现。

![1640853801916](https://tprzfbucket.oss-cn-beijing.aliyuncs.com/hadoop/202112/30/164322-812795.png)

一旦有请求到达，就会交给 Redis 线程处理，这就实现了一个 Redis 线程处理多个 IO 流的效果。

所以，Redis选择使用多路复用IO技术来提升I/O利用率。

而之所以Redis能够有这么高的性能，不仅仅和采用多路复用技术和单线程有关，此外还有以下几个原因：

1、完全基于内存，绝大部分请求是纯粹的内存操作，非常快速。

2、数据结构简单，对数据操作也简单，如哈希表、跳表都有很高的性能。

3、采用单线程，避免了不必要的上下文切换和竞争条件，也不存在多进程或者多线程导致的切换而消耗 CPU

4、使用多路I/O复用模型

#### 为什么Redis 6.0 引入多线程

2020年5月份，Redis正式推出了6.0版本，这个版本中有很多重要的新特性，其中多线程特性引起了广泛关注。

但是，需要提醒大家的是，**Redis 6.0中的多线程，也只是针对处理网络请求过程采用了多线程，而数据的读写命令，仍然是单线程处理的。**

但是，不知道会不会有人有这样的疑问：

**Redis不是号称单线程也有很高的性能么？**

**不是说多路复用技术已经大大的提升了IO利用率了么，为啥还需要多线程？**

主要是因为我们对Redis有着更高的要求。

根据测算，Redis 将所有数据放在内存中，内存的响应时长大约为 100 纳秒，对于小数据包，Redis 服务器可以处理 80,000 到 100,000 QPS，这么高的对于 80% 的公司来说，单线程的 Redis 已经足够使用了。

但随着越来越复杂的业务场景，有些公司动不动就上亿的交易量，因此需要更大的 QPS。

为了提升QPS，很多公司的做法是部署Redis集群，并且尽可能提升Redis机器数。但是这种做法的资源消耗是巨大的。

而经过分析，限制Redis的性能的主要瓶颈出现在网络IO的处理上，虽然之前采用了多路复用技术。但是我们前面也提到过，**多路复用的IO模型本质上仍然是同步阻塞型IO模型**。

下面是多路复用IO中select函数的处理过程：

![1640853983372](https://tprzfbucket.oss-cn-beijing.aliyuncs.com/hadoop/202202/05/103158-746825.png)

从上图我们可以看到，**在多路复用的IO模型中，在处理网络请求时，调用 select （其他函数同理）的过程是阻塞的，也就是说这个过程会阻塞线程，如果并发量很高，此处可能会成为瓶颈。**

虽然现在很多服务器都是多个CPU核的，但是对于Redis来说，因为使用了单线程，在一次数据操作的过程中，有大量的CPU时间片是耗费在了网络IO的同步处理上的，并没有充分的发挥出多核的优势。

**如果能采用多线程，使得网络处理的请求并发进行，就可以大大的提升性能。多线程除了可以减少由于网络 I/O 等待造成的影响，还可以充分利用 CPU 的多核优势。**

所以，Redis 6.0采用多个IO线程来处理网络请求，网络请求的解析可以由其他线程完成，然后把解析后的请求交由主线程进行实际的内存读写。提升网络请求处理的并行度，进而提升整体性能。

但是，Redis 的多 IO 线程只是用来处理网络请求的，对于读写命令，Redis 仍然使用单线程来处理。

**那么，在引入多线程之后，如何解决并发带来的线程安全问题呢？**

这就是为什么我们前面多次提到的"Redis 6.0的多线程只用来处理网络请求，而数据的读写还是单线程"的原因。

Redis 6.0 只有在网络请求的接收和解析，以及请求后的数据通过网络返回给时，使用了多线程。而数据读写操作还是由单线程来完成的，所以，这样就不会出现并发问题了。