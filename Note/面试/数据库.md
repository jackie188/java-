<!-- TOC -->

- [数据库](#数据库)
  - [什么是Mysql数据库](#什么是mysql数据库)
  - [mysql架构](#mysql架构)
  - [Mysql常用的存储引擎有哪些，他们都有什么特点？](#mysql常用的存储引擎有哪些他们都有什么特点)
    - [查看存储引擎](#查看存储引擎)
    - [设置存储引擎](#设置存储引擎)
    - [常见的存储引擎](#常见的存储引擎)
      - [文件存储结构对比](#文件存储结构对比)
  - [数据类型](#数据类型)
  - [数据库的三大范式](#数据库的三大范式)
    - [第一范式](#第一范式)
    - [第二范式](#第二范式)
    - [第三范式](#第三范式)
  - [Mysql的数据类型都有哪些？](#mysql的数据类型都有哪些)
  - [索引](#索引)
    - [什么是索引](#什么是索引)
    - [创建索引](#创建索引)
    - [索引的优缺点](#索引的优缺点)
    - [索引分类](#索引分类)
      - [从数据结构角度](#从数据结构角度)
      - [从物理存储角度](#从物理存储角度)
      - [从逻辑角度](#从逻辑角度)
    - [Mysql索引](#mysql索引)
      - [B+Tree索引](#btree索引)
        - [B-Tree：](#b-tree)
        - [B+Tree](#btree)
        - [MyISAM主键索引与辅助索引的结构](#myisam主键索引与辅助索引的结构)
        - [InnoDB主键索引与辅助索引的结构](#innodb主键索引与辅助索引的结构)
        - [主键索引：](#主键索引)
        - [辅助（非主键）索引：](#辅助非主键索引)
        - [**InnoDB 索引结构需要注意的点**](#innodb-索引结构需要注意的点)
      - [Hash索引](#hash索引)
      - [full-text全文索引](#full-text全文索引)
      - [R-Tree空间索引](#r-tree空间索引)
      - [为什么Mysql索引要用B+树不是B树？](#为什么mysql索引要用b树不是b树)
      - [面试官：为何不采用Hash方式？](#面试官为何不采用hash方式)
    - [哪些情况需要创建索引](#哪些情况需要创建索引)
    - [哪些情况不要创建索引](#哪些情况不要创建索引)
    - [MySQL覆盖索引](#mysql覆盖索引)
    - [索引的类型有哪些](#索引的类型有哪些)
    - [索引的种类有哪些？](#索引的种类有哪些)
    - [索引的数据结构](#索引的数据结构)
      - [**B+树索引**](#b树索引)
      - [**哈希索引**](#哈希索引)
    - [Hash索引和B+树的区别？](#hash索引和b树的区别)
    - [B树和B+树的区别？](#b树和b树的区别)
    - [数据库为什么使用B+树而不是B树？](#数据库为什么使用b树而不是b树)
    - [面试官：为何不采用Hash方式？](#面试官为何不采用hash方式-1)
    - [什么是聚簇索引，什么是非聚簇索引？](#什么是聚簇索引什么是非聚簇索引)
    - [非聚簇索引一定会进行回表查询吗？](#非聚簇索引一定会进行回表查询吗)
    - [索引的使用场景有哪些？](#索引的使用场景有哪些)
    - [索引的设计原则有哪些？](#索引的设计原则有哪些)
    - [如何对索引进行优化](#如何对索引进行优化)
    - [如何创建删除索引？](#如何创建删除索引)
    - [使用索引查询时性能一定会提升吗？](#使用索引查询时性能一定会提升吗)
    - [什么是前缀索引](#什么是前缀索引)
    - [什么是最左匹配原则](#什么是最左匹配原则)
    - [索引在什么情况下会失效？](#索引在什么情况下会失效)
  - [Mysql查询](#mysql查询)
    - [SQL执行顺序](#sql执行顺序)
    - [join图](#join图)
  - [数据库事务](#数据库事务)
    - [什么是数据库事务？](#什么是数据库事务)
    - [事务的四大特性是什么？（ACID特性）](#事务的四大特性是什么acid特性)
    - [数据库的并发一致性问题](#数据库的并发一致性问题)
    - [数据库的隔离级别有哪些？](#数据库的隔离级别有哪些)
      - [Read uncommitted](#read-uncommitted)
      - [Read committed](#read-committed)
      - [Repeatable read](#repeatable-read)
      - [Serializable 序列化](#serializable-序列化)
      - [比较](#比较)
    - [隔离级别是如何实现的？](#隔离级别是如何实现的)
      - [什么是MVCC](#什么是mvcc)
      - [MVCC实现原理](#mvcc实现原理)
        - [事务版本号](#事务版本号)
        - [隐士字段](#隐士字段)
        - [undo log](#undo-log)
        - [版本链](#版本链)
        - [当前读和快照读](#当前读和快照读)
        - [Read View](#read-view)
        - [mvcc实现原理分析](#mvcc实现原理分析)
        - [读已提交（RC）隔离级别，存在不可重复读问题的分析历程](#读已提交rc隔离级别存在不可重复读问题的分析历程)
        - [可重复读（RR）隔离级别，解决不可重复读问题的分析](#可重复读rr隔离级别解决不可重复读问题的分析)
  - [数据库锁](#数据库锁)
    - [什么是数据库锁](#什么是数据库锁)
    - [锁的分类](#锁的分类)
      - [**从对数据操作的类型分类**：](#从对数据操作的类型分类)
      - [**从对数据操作的粒度分类**：](#从对数据操作的粒度分类)
    - [MyISAM 表锁](#myisam-表锁)
    - [InnoDB 行锁](#innodb-行锁)
    - [如何理解锁](#如何理解锁)
    - [加锁机制](#加锁机制)
    - [锁模式(InnoDB有三种行锁的算法)](#锁模式innodb有三种行锁的算法)
    - [死锁](#死锁)
      - [**死锁产生**：](#死锁产生)
      - [**MyISAM避免死锁**：](#myisam避免死锁)
      - [**InnoDB避免死锁**：](#innodb避免死锁)
    - [数据库锁与隔离级别的关系](#数据库锁与隔离级别的关系)
    - [数据库锁类型有哪些？](#数据库锁类型有哪些)
    - [MySQL中InnoDB引擎的行锁模式及其是如何实现的？](#mysql中innodb引擎的行锁模式及其是如何实现的)
    - [什么是数据库的乐观锁和悲观锁，如何实现？](#什么是数据库的乐观锁和悲观锁如何实现)
    - [什么是死锁？如何避免？](#什么是死锁如何避免)
  - [Sql基础](#sql基础)
    - [SQL语句主要分为哪几类](#sql语句主要分为哪几类)
    - [SQL约束有哪些](#sql约束有哪些)
    - [什么是子查询](#什么是子查询)
    - [了解MySQL的几种连接查询吗？](#了解mysql的几种连接查询吗)
    - [mysql中in和exists的区别？](#mysql中in和exists的区别)
    - [varchar和char的区别？](#varchar和char的区别)
    - [MySQL中int(10)和char(10)和varchar(10)的区别？](#mysql中int10和char10和varchar10的区别)
    - [drop、delete和truncate的区别？](#dropdelete和truncate的区别)
    - [UNION和UNION ALL的区别？](#union和union-all的区别)
    - [什么是临时表，什么时候会使用到临时表，什么时候删除临时表？](#什么是临时表什么时候会使用到临时表什么时候删除临时表)
    - [大表数据查询如何进行优化？](#大表数据查询如何进行优化)
    - [了解慢日志查询吗？统计过慢查询吗？对慢查询如何优化？](#了解慢日志查询吗统计过慢查询吗对慢查询如何优化)
    - [为什么要设置主键？](#为什么要设置主键)
      - [主键一般用自增ID还是UUID？](#主键一般用自增id还是uuid)
    - [字段为什么要设置成not null?](#字段为什么要设置成not-null)
    - [如何优化查询过程中的数据访问？](#如何优化查询过程中的数据访问)
    - [如何优化长难的查询语句？](#如何优化长难的查询语句)
    - [如何优化LIMIT分页？](#如何优化limit分页)
    - [如何优化UNION查询](#如何优化union查询)
    - [如何优化WHERE子句](#如何优化where子句)
    - [SQL语句执行的很慢原因是什么？](#sql语句执行的很慢原因是什么)
    - [SQL语句的执行顺序?](#sql语句的执行顺序)
  - [Mysql调优](#mysql调优)
    - [MySQL常见性能分析手段](#mysql常见性能分析手段)
      - [性能瓶颈定位](#性能瓶颈定位)
      - [Explain(执行计划)](#explain执行计划)
      - [慢查询日志](#慢查询日志)
      - [Show Profile 分析查询](#show-profile-分析查询)
  - [性能优化](#性能优化)
    - [索引优化](#索引优化)
    - [查询优化](#查询优化)
    - [数据类型优化](#数据类型优化)
  - [分区，分库分表](#分区分库分表)
    - [Mysql分区](#mysql分区)
    - [MySQL分表](#mysql分表)
    - [MySQL分库](#mysql分库)
  - [主从复制](#主从复制)
    - [复制的基本原理](#复制的基本原理)
    - [复制的基本原则](#复制的基本原则)
    - [复制的最大问题](#复制的最大问题)
  - [百万级别或以上的数据如何删除](#百万级别或以上的数据如何删除)
  - [数据库优化](#数据库优化)
    - [大表如何优化？](#大表如何优化)
    - [什么是垂直分表、垂直分库、水平分表、水平分库？](#什么是垂直分表垂直分库水平分表水平分库)
    - [分库分表后，ID键如何处理？](#分库分表后id键如何处理)
    - [MySQL的复制原理及流程？如何实现主从复制？](#mysql的复制原理及流程如何实现主从复制)
    - [了解读写分离吗？](#了解读写分离吗)
  - [常见面试题目](#常见面试题目)
    - [一张表，里面有ID自增主键，当insert了17条记录之后，删除了第15,16,17条记录，再把Mysql重启，再insert一条记录，这条记录的ID是18还是15 ？](#一张表里面有id自增主键当insert了17条记录之后删除了第151617条记录再把mysql重启再insert一条记录这条记录的id是18还是15-)
    - [Mysql服务器默认端口是什么？](#mysql服务器默认端口是什么)
    - [与Oracle相比，Mysql有什么优势？](#与oracle相比mysql有什么优势)
    - [如何区分FLOAT和DOUBLE？](#如何区分float和double)
    - [区分CHAR_LENGTH和LENGTH？](#区分char_length和length)
    - [请简洁描述Mysql中InnoDB支持的四种事务隔离级别名称，以及逐级之间的区别？](#请简洁描述mysql中innodb支持的四种事务隔离级别名称以及逐级之间的区别)
    - [CHAR和VARCHAR的区别？](#char和varchar的区别)
    - [主键和候选键有什么区别？](#主键和候选键有什么区别)
    - [BLOB 和 TEXT 有什么区别？](#blob-和-text-有什么区别)
    - [MySQL 的关键字](#mysql-的关键字)
    - [数据库备份](#数据库备份)

<!-- /TOC -->

## 数据库



### 什么是Mysql数据库

MySQL是一种开放源代码的关系型数据库管理系统（RDBMS），使用最常用的数据库管理语言--**结构化查询语言（SQL）**进行数据库管理。MySQL是开放源代码的，因此任何人都可以在General Public License的许可下下载并根据个性化的需要对其进行修改。 

### mysql架构

和其它数据库相比，MySQL有点与众不同，它的架构可以在多种不同场景中应用并发挥良好作用。主要体现在存储引擎的架构上，**插件式的存储引擎架构将查询处理和其它的系统任务以及数据的存储提取相分离**。这种架构可以根据业务的需求和实际需要选择合适的存储引擎。

![1640582860809](https://tprzfbucket.oss-cn-beijing.aliyuncs.com/hadoop/202112/27/132741-789613.png)

**连接层**：最上层是一些客户端和连接服务。**主要完成一些类似于连接处理、授权认证、及相关的安全方案**。在该层上引入了线程池的概念，为通过认证安全接入的客户端提供线程。同样在该层上可以实现基于SSL的安全链接。服务器也会为安全接入的每个客户端验证它所具有的操作权限。

**服务层**：第二层服务层，主要完成大部分的核心服务功能， 包括**查询解析、分析、优化、缓存、以及所有的内置函数**，所有跨存储引擎的功能也都在这一层实现，包括触发器、存储过程、视图等

**引擎层**：第三层存储引擎层，存储引擎真正的负责了MySQL中数据的**存储和提取**，服务器通过API与存储引擎进行通信。不同的存储引擎具有的功能不同，这样我们可以根据自己的实际需要进行选取

**存储层**：第四层为数据存储层，**主要是将数据存储在运行于该设备的文件系统之上，并完成与存储引擎的交互**

> MySQL 的查询流程具体是？or 一条SQL语句在MySQL中如何执行的？

客户端请求 ---> 连接器（验证用户身份，给予权限）  ---> 查询缓存（存在缓存则直接返回，不存在则执行后续操作） ---> 分析器（对SQL进行词法分析和语法分析操作）  ---> 优化器（主要对执行的sql优化选择最优的执行方案方法）  ---> 执行器（执行时会先看用户是否有执行权限，有才去使用这个引擎提供的接口） ---> 去引擎层获取数据返回（如果开启查询缓存则会缓存查询结果）

![1640583028230](https://tprzfbucket.oss-cn-beijing.aliyuncs.com/hadoop/202112/27/133029-35472.png)

### Mysql常用的存储引擎有哪些，他们都有什么特点？

存储引擎是MySQL的组件，用于处理不同表类型的SQL操作。不同的存储引擎提供不同的**存储机制、索引技巧、锁定水平**等功能，使用不同的存储引擎，还可以获得特定的功能。

使用哪一种引擎可以灵活选择，**一个数据库中多个表可以使用不同引擎以满足各种性能和实际需求**，使用合适的存储引擎，将会提高整个数据库的性能 。

MySQL服务器使用**可插拔**的存储引擎体系结构，可以从运行中的 MySQL 服务器加载或卸载存储引擎 。

目前通常使用的有两种存储引擎：

**InnoDB**

- InnoDB是MySQL的默认存储引擎，支持事务、行锁和外键等操作。

**MyISAM**

- MyISAM是MySQL5.1版本前的默认存储引擎，MyISAM的并发性比较差，不支持事务和外键等操作，默认的锁的粒度为表级锁。 

#### 查看存储引擎

~~~ java
-- 查看支持的存储引擎
SHOW ENGINES

-- 查看默认存储引擎
SHOW VARIABLES LIKE 'storage_engine'

--查看具体某一个表所使用的存储引擎，这个默认存储引擎被修改了！
show create table tablename

--准确查看某个数据库中的某一表所使用的存储引擎
show table status like 'tablename'
show table status from database where name="tablename"
~~~

#### 设置存储引擎

我们在进阿里一张表的时候，可以设置表使用不同的存储引擎。

~~~ java
-- 建表时指定存储引擎。默认的就是INNODB，不需要设置
CREATE TABLE t1 (i INT) ENGINE = INNODB;
CREATE TABLE t2 (i INT) ENGINE = CSV;
CREATE TABLE t3 (i INT) ENGINE = MEMORY;

-- 修改存储引擎
ALTER TABLE t ENGINE = InnoDB;

-- 修改默认存储引擎，也可以在配置文件my.cnf中修改默认引擎
SET default_storage_engine=NDBCLUSTER;
~~~

默认情况下，每当 `CREATE TABLE` 或 `ALTER TABLE` 不能使用默认存储引擎时，都会生成一个警告。为了防止在所需的引擎不可用时出现令人困惑的意外行为，可以启用 `NO_ENGINE_SUBSTITUTION SQL` 模式。如果所需的引擎不可用，则此设置将产生错误而不是警告，并且不会创建或更改表

#### 常见的存储引擎

常见的存储引擎就 InnoDB、MyISAM、Memory、NDB。

InnoDB 现在是 MySQL 默认的存储引擎，支持**事务、行级锁定和外键**

##### 文件存储结构对比

在 MySQL中建立任何一张数据表，在其数据目录对应的数据库目录下都有对应表的 `.frm` 文件，`.frm` 文件是用来保存每个数据表的元数据(meta)信息，包括表结构的定义等，与数据库存储引擎无关，也就是任何存储引擎的数据表都必须有`.frm`文件，命名方式为 数据表名.frm，如user.frm。

查看MySQL 数据保存在哪里：`show variables like 'data%'`

MyISAM 物理文件结构为：

- `.frm`文件：与表相关的元数据信息都存放在frm文件，包括表结构的定义信息等
- `.MYD` (`MYData`) 文件：MyISAM 存储引擎专用，用于存储MyISAM 表的数据
- `.MYI` (`MYIndex`)文件：MyISAM 存储引擎专用，用于存储MyISAM 表的索引相关信息

InnoDB 物理文件结构为：

- `.frm` 文件：与表相关的元数据信息都存放在frm文件，包括表结构的定义信息等
- `.ibd` 文件或 `.ibdata` 文件： 这两种文件都是存放 InnoDB 数据的文件，之所以有两种文件形式存放 InnoDB 的数据，是因为 InnoDB 的数据存储方式能够通过配置来决定是使用**共享表空间**存放存储数据，还是用**独享表空间**存放存储数据。
- 独享表空间存储方式使用`.ibd`文件，并且每个表一个`.ibd`文件， 共享表空间存储方式使用`.ibdata`文件，所有表共同使用一个`.ibdata`文件（或多个，可自己配置）

> 面试中如何回答这些问题？

**事务方面**

InnoDB 支持事务，MyISAM 不支持事务。这是 MySQL 将默认存储引擎从 MyISAM 变成 InnoDB 的重要原因之一；

**是否支持外键**

InnoDB 支持外键，而 MyISAM 不支持。对一个包含外键的 InnoDB 表转为 MYISAM 会失败；

**聚簇索引和非聚簇索引**

InnoDB 是聚簇索引，MyISAM 是非聚簇索引。聚簇索引的文件存放在主键索引的叶子节点上，因此 InnoDB 必须要有主键，通过主键索引效率很高。但是辅助索引需要两次查询，先查询到主键，然后再通过主键查询到数据。因此，主键不应该过大，因为主键太大，其他索引也都会很大。而 MyISAM 是非聚集索引，数据文件是分离的，索引保存的是数据文件的指针。主键索引和辅助索引是独立的。

**是否保存表的行数**

InnoDB 不保存表的具体行数，执行`select count(*) from table` 时需要全表扫描。而 MyISAM 用一个变量保存了整个表的行数，执行上述语句时只需要读出该变量即可，速度很快；

**锁粒度**

InnoDB 最小的锁粒度是行锁，MyISAM 最小的锁粒度是表锁。一个更新语句会锁住整张表，导致其他查询和更新都会被阻塞，因此并发访问受限。这也是 MySQL 将默认存储引擎从 MyISAM 变成 InnoDB 的重要原因之一；

**是否支持数据库异常崩溃后的安全恢复**

MyISAM 不支持，而 InnoDB 支持。

使用 InnoDB 的数据库在异常崩溃后，数据库重新启动的时候会保证数据库恢复到崩溃前的状态。这个恢复的过程依赖于 `redo log` 。

🌈 拓展一下：

- MySQL InnoDB 引擎使用 **redo log(重做日志)** 保证事务的**持久性**，使用 **undo log(回滚日志)** 来保证事务的**原子性**。
- MySQL InnoDB 引擎通过 **锁机制**、**MVCC** 等手段来保证事务的隔离性（ 默认支持的隔离级别是 **`REPEATABLE-READ`** ）。
- 保证了事务的持久性、原子性、隔离性之后，一致性才能得到保障。

两种引擎对比：

![1631753040455](https://tprzfbucket.oss-cn-beijing.aliyuncs.com/hadoop/202109/16/084403-805112.png)

![1640656100727](https://tprzfbucket.oss-cn-beijing.aliyuncs.com/hadoop/202112/28/094822-164211.png)

> 一张表，里面有ID自增主键，当insert了17条记录之后，删除了第15,16,17条记录，再把Mysql重启，再insert一条记录，这条记录的ID是18还是15 ？

如果表的类型是MyISAM，那么是18。因为MyISAM表会把自增主键的最大ID 记录到**数据文件中**，重启MySQL自增主键的最大ID也不会丢失；

如果表的类型是InnoDB，那么是15。因为InnoDB 表只是把自增主键的最大ID记录到**内存中**，所以重启数据库或对表进行OPTION操作，都会导致最大ID丢失。

> 哪个存储引擎执行 select count(*) 更快，为什么?

MyISAM更快，因为MyISAM内部维护了一个计数器，可以直接调取。

- 在 MyISAM 存储引擎中，把表的总行数存储在磁盘上，当执行 select count(*) from t 时，直接返回总数据。
- 在 InnoDB 存储引擎中，跟 MyISAM 不一样，没有将总行数存储在磁盘上，当执行 select count(*) from t 时，会先把数据读出来，一行一行的累加，最后返回总数量。

InnoDB 中 count(*) 语句是在执行的时候，全表扫描统计总数量，所以当数据越来越大时，语句就越来越耗时了，为什么 InnoDB 引擎不像 MyISAM 引擎一样，将总行数存储到磁盘上？这跟 InnoDB 的事务特性有关，由于多版本并发控制（MVCC）的原因，InnoDB 表“应该返回多少行”也是不确定的。

### 锁机制与 InnoDB 锁算法

**MyISAM 和 InnoDB 存储引擎使用的锁：**

- MyISAM 采用表级锁(table-level locking)。
- InnoDB 支持行级锁(row-level locking)和表级锁,默认为行级锁

**表级锁和行级锁对比：**

- **表级锁：** MySQL 中锁定 **粒度最大** 的一种锁，对当前操作的整张表加锁，实现简单，资源消耗也比较少，加锁快，不会出现死锁。其锁定粒度最大，触发锁冲突的概率最高，并发度最低，MyISAM 和 InnoDB 引擎都支持表级锁。
- **行级锁：** MySQL 中锁定 **粒度最小** 的一种锁，只针对当前操作的行进行加锁。 行级锁能大大减少数据库操作的冲突。其加锁粒度最小，并发度高，但加锁的开销也最大，加锁慢，会出现死锁。

**InnoDB 存储引擎的锁的算法有三种：**

- Record lock：记录锁，单个行记录上的锁
- Gap lock：间隙锁，锁定一个范围，不包括记录本身
- Next-key lock：record+gap 临键锁，锁定一个范围，包含记录本身

### 数据类型

主要包括以下五大类：

- 整数类型：BIT、BOOL、TINY INT、SMALL INT、MEDIUM INT、 INT、 BIG INT
- 浮点数类型：FLOAT、DOUBLE、DECIMAL
- 字符串类型：CHAR、VARCHAR、TINY TEXT、TEXT、MEDIUM TEXT、LONGTEXT、TINY BLOB、BLOB、MEDIUM BLOB、LONG BLOB
- 日期类型：Date、DateTime、TimeStamp、Time、Year
- 其他数据类型：BINARY、VARBINARY、ENUM、SET、Geometry、Point、MultiPoint、LineString、MultiLineString、Polygon、GeometryCollection等

![1640656310144](C:\Users\MrR\AppData\Roaming\Typora\typora-user-images\1640656310144.png)

![1640656330188](https://tprzfbucket.oss-cn-beijing.aliyuncs.com/hadoop/202112/28/095211-484648.png)

![1640656346954](https://tprzfbucket.oss-cn-beijing.aliyuncs.com/hadoop/202112/28/095239-888739.png)

> CHAR 和 VARCHAR 的区别？

char是固定长度，varchar长度可变：

char(n) 和 varchar(n) 中括号中 n 代表**字符**的个数，并不代表字节个数，比如 CHAR(30) 就可以存储 30 个字符。

存储时，前者不管实际存储数据的长度，直接按 char 规定的长度分配存储空间；而后者会根据实际存储的数据分配最终的存储空间

相同点：

1. char(n)，varchar(n)中的n都代表字符的个数
2. 超过char，varchar最大长度n的限制后，字符串会被截断。

不同点：

1. char不论实际存储的字符数都会占用n个字符的空间，而varchar只会占用实际字符应该占用的字节空间加1（实际长度length，0<=length<255）或加2（length>255）。因为varchar保存数据时除了要保存字符串之外还会加一个字节来记录长度（如果列声明长度大于255则使用两个字节来保存长度）。
2. 能存储的最大空间限制不一样：char的存储上限为255字节。
3. char在存储时会截断尾部的空格，而varchar不会。

char是适合存储很短的、一般固定长度的字符串。例如，char非常适合存储密码的MD5值，因为这是一个定长的值。对于非常短的列，char比varchar在存储空间上也更有效率。

> 列的字符串类型可以是什么？

字符串类型是：SET、BLOB、ENUM、CHAR、TEXT、VARCHAR

> BLOB和TEXT有什么区别？

BLOB是一个二进制对象，可以容纳可变数量的数据。有四种类型的BLOB：TINYBLOB、BLOB、MEDIUMBLO和 LONGBLOB

TEXT是一个不区分大小写的BLOB。四种TEXT类型：TINYTEXT、TEXT、MEDIUMTEXT 和 LONGTEXT。

BLOB 保存二进制数据，TEXT 保存字符数据。

### 数据库的三大范式

数据冗余直观上可以说就是一张表里不同位置有大量重复的数据，这种冗余不仅仅增加了存储量，也使得我们会更容易遇到三种异常（**插入异常，更新异常和删除异常**）。

#### 第一范式

- 第一范式：确保每列保持原子性，数据表中的所有字段值都是不可分解的原子值。在任何一个关系型数据库中，满足第一范式是最基本的要求，
  - 1NF是对属性的**原子性**，要求属性具有原子性，不可再分解；
  - 如学生（学号，姓名，性别，出生日期），可以看到每一个列属性都是不可在分割的单位，这就是原子性的含义。
  - 解决方法：对可以再分的列字段，进行拆分，划分为多个表。

![1640651441705](https://tprzfbucket.oss-cn-beijing.aliyuncs.com/hadoop/202112/28/083043-534139.png)

但是，就算是这样符合1NF的表仍然会有很多，因为1NF其实是最为基本的要求，不满足1NF的数据库甚至不一定能建立成功。

比如，上面提到的三个异常:

1. 插入异常。如果学校建了新系，但还没有招生，这个系就不能被插入数据表里
2. 更新异常。如果Akon转系了，那在上表中需要更改两行院系&课程记录
3. 删除异常。如果所有学生记录被删除，院系记录和课程也就不复存在了

> 1NF解决的是数据冗余问题。

#### 第二范式

我们先来看看什么是依赖：

对于一个表来说，如果通过其中一个属性可以找到唯一对应的一条记录，那么我们可以说它为本表的主键(Primary Key)。 比如下表中，每个学生的学号是存在且唯一的，但是名字可能会有重名存在，学号为主键（Primary Key），而姓名就不是。 同时，我可以通过【学号】查到任何一行的任何一列属性，比如通过【学号】查【院系】，通过【学号】查【课程】，通过【学号】查【姓名】。这时我们可以说，其他的这三个属性**依赖**于学号。

**那什么是部分依赖呢？**
 候选键（Candidate Key）就是，当两个属性结合在一起可以唯一确定任何一条记录的情况。比如在一张学生成绩表中。

![1640655170465](https://tprzfbucket.oss-cn-beijing.aliyuncs.com/hadoop/202112/28/093301-442493.png)

【学号+课程号】 一起可以确定任何一条分数或是学号或是教师，所以 【学号+课程号】 就是本表的候选键。
 一张表可以有多个键（key），一般我们会选择其中一个作为主键。
 这个时候我们可以看到，教师这一属性其实只由课程号决定，而课程号只是 候选键 的一部分，因此这时我们就说，教师属性存在部分函数依赖。

- 第二范式：确保表中的每列都和主键相关
  - 2NF是对记录的**唯一性**，要求记录有唯一标识，即实体的唯一性，即**不存在部分依赖，必须是完全依赖，也就是所有的非主属性必须完全依赖于主属性**；
  - 如表：（学号，课程号，姓名，学分），这个表明显说明了两个事务:学生信息, 课程信息;由于非主键字段必须依赖主键，这里**学分依赖课程号**，**姓名依赖与学号**，所以不符合二范式。所以我们要对表进行拆分，让其符合第二范式，学生：`Student`(学号, 姓名)；课程：`Course`(课程号, 学分)；选课关系：`StudentCourse`(学号, 课程号, 成绩)。
  - 解决方法：一般是把表拆分为两个表，一张表只管理一件事。
  - 如果不符合第二范式，可能会存在的问题：
    - `数据冗余:`，每条记录都含有相同信息；
    - `删除异常：`删除所有学生成绩，就把课程信息全删除了；
    - `插入异常：`学生未选课，无法记录进数据库；
    - `更新异常：`调整课程学分，所有行都调整。

**拆分表**

1. 先找出所有的非主属性（不是主键也不是候选键包含部分的属性），在这个例子里，键为【学号+课程号】，那么他俩为主属性，剩下的都是非主属性
2. 检查这些非主属性是否存在部分函数依赖。【姓名】只依赖于【学号】，存在；【分数】非得要【学号+课程号】一起才能确定，不存在；【教师】只依赖于【课程】号，存在
   1. 将这些存在部分函数依赖的属性分出去建立满足2NF的新表，切分方法并不唯一。

**分数表去掉 【姓名】 和 【教师】 属性：**

![1640655497010](https://tprzfbucket.oss-cn-beijing.aliyuncs.com/hadoop/202112/28/093817-893822.png)

**为 姓名 建立学生表：**

![1640655526626](https://tprzfbucket.oss-cn-beijing.aliyuncs.com/hadoop/202112/28/093848-181211.png)

**为 教师 建立 课程表：**

![1640655547943](https://tprzfbucket.oss-cn-beijing.aliyuncs.com/hadoop/202112/28/093913-281644.png)

第二范式存在的异常：

- 插入异常。招新生的话，学生信息可以单独插入，有改进。
- 更新异常。如果L1号课换老师了，只用修改一次，有改进。
- **删除异常**。如果删除所有的学生信息，教师信息还在，分数信息也还在；但是如果我从教师表里删掉课程L1的记录，教师Mr.x以及CS院系信息就不复存在了，这是个大问题。

> 满足2NF的前提是必须满足1NF。
>
> 2NF解决的是部分函数依赖问题。
>
> 数据冗余问题变少了。

#### 第三范式

比如上面一节提到，如果删除教师表里课程L1的信息，教师Mr.x以及CS院系信息就不复存在了，同时，如果一名新来的教师还没有被分配到任何课，他就不能被加入到教师表里。

这是因为，在教师表里：

1. 课程号可以决定教师. A → B
2. 教师不能决定课程号，因为一个教师可以教多门课. B not→ A
3. 教师决定院系，因为一个教师只能属于一个院系. B → C

这时我们就发现，非主属性 【院系】，也依赖于另一个非主属性 【教师】，这种情况就叫做传递依赖。
而3NF的条件，就是要去除这种传递依赖。

- 第三范式：确保每列都和主键列直接相关而不是间接相关 
  - 3NF是对字段的**冗余性**，要求任何字段不能由其他字段派生出来，它要求字段没有冗余，即**不存在传递依赖**，不存在属性对主键的**传递依赖**。；
  - 表: 学号, 姓名, 年龄, 学院名称, 学院电话，因为存在**依赖传递**: (学号) → (学生)→(所在学院) → (学院电话) 。所以对表进行拆分，消除传递函数依赖，学生：(学号, 姓名, 年龄, 所在学院)；学院：(学院, 电话)。
  - **可能会存在问题：**
    - `数据冗余:`有重复值；
    - `更新异常：`有重复的冗余信息，修改时需要同时修改多条记录，否则会出现**数据不一致的情况** 。
    - `插入异常`：学生未选课，无法记录进数据库；
    - `删除异常`:删除所有学生成绩，就把课程信息全删除了；

**拆分表**

 解决方法有多种，这里可以将院系信息分表。

 课程表只有课程号和教师信息：

![1640655793724](https://tprzfbucket.oss-cn-beijing.aliyuncs.com/hadoop/202112/28/094315-520507.png)

而教师表 只有教师和院系信息：

![1640655818425](https://tprzfbucket.oss-cn-beijing.aliyuncs.com/hadoop/202112/28/094347-409638.png)

这样我们再检查上面的问题， 删除L1课程信息，Mr.X老师的信息仍然保存的很好，有改进。 新老师Mr.Z可以被插入教师表，哪怕他还没有被分配任何课程。

> 3NF解决的是传递依赖关系
>
> 满足3NF的前提是必须满足2NF。
>
> 3NF解决了插入异常。

### Mysql的数据类型都有哪些？

**整数**

- TINYINT、SMALLINT、MEDIUMINT、INT、BIGINT分别占用8、16、24、32、64位存储空间。值得注意的是，INT(10)中的10只是表示显示字符的个数，并无实际意义。一般和UNSIGNED ZEROFILL配合使用才有实际意义，例如，数据类型INT(3)，属性为UNSIGNED ZEROFILL，如果插入的数据为3的话，实际存储的数据为003。

**浮点数**

- FLOAT、DOUBLE及DECIMAL为浮点数类型，DECIMAL是利用字符串进行处理的，能存储精确的小数。相比于FLOAT和DOUBLE，DECIMAL的效率更低些。FLOAT、DOUBLE及DECIMAL都可以指定列宽，例如FLOAT(5,2)表示一共5位，两位存储小数部分，三位存储整数部分。

**字符串**

- 字符串常用的主要有CHAR和VARCHAR，VARCHAR主要用于存储可变长字符串，相比于定长的CHAR更节省空间。CHAR是定长的，根据定义的字符串长度分配空间。
  - 应用场景：对于经常变更的数据使用CHAR更好，CHAR不容易产生碎片。对于非常短的列也是使用CHAR更好些，CHAR相比于VARCHAR在效率上更高些。**一般避免使用TEXT/BLOB等类型，因为查询时会使用临时表，造成严重的性能开销。**

**日期**

- 比较常用的有year、time、date、datetime、timestamp等，datetime保存从1000年到9999年的时间，精度位秒，使用8字节的存储空间，与时区无关。timestamp和UNIX的时间戳相同，保存从1970年1月1日午夜到2038年的时间，精度到秒，使用四个字节的存储空间，并且与时区相关。
  - 应用场景：尽量使用timestamp，相比于datetime它有着更高的空间效率。 

### 索引

> 说说你对 MySQL 索引的理解？
>
> 数据库索引的原理，为什么要用 B+树，为什么不用二叉树？
>
> 聚集索引与非聚集索引的区别？
>
> InnoDB引擎中的索引策略，了解过吗？
>
> 创建索引的方式有哪些？
>
> 聚簇索引/非聚簇索引，mysql索引底层实现，为什么不用B-tree，为什么不用hash，叶子结点存放的是数据还是指向数据的内存地址，使用索引需要注意的几个地方？

#### 什么是索引

- MYSQL官方对索引的定义为：索引（Index）是帮助MySQL高效获取数据的数据结构，所以说**索引的本质是：数据结构**
- 索引的目的在于提高查询效率，可以类比字典、 火车站的车次表、图书的目录等 。
- 可以简单的理解为“**排好序的快速查找数据结构**”，数据本身之外，**数据库还维护者一个满足特定查找算法的数据结构**，这些数据结构以某种方式引用（指向）数据，这样就可以在这些数据结构上实现高级查找算法。这种数据结构，就是索引。下图是一种可能的索引方式示例。

![1640656571077](https://tprzfbucket.oss-cn-beijing.aliyuncs.com/hadoop/202112/28/095612-18437.png)

左边的数据表，一共有两列七条记录，最左边的是数据记录的物理地址

为了加快Col2的查找，可以维护一个右边所示的二叉查找树，每个节点分别包含索引键值，和一个指向对应数据记录物理地址的指针，这样就可以运用二叉查找在一定的复杂度内获取到对应的数据，从而快速检索出符合条件的记录。

索引本身也很大，不可能全部存储在内存中，**一般以索引文件的形式存储在磁盘上**

平常说的索引，没有特别指明的话，就是**B+树（多路搜索树，不一定是二叉树）**结构组织的索引。其中聚集索引，次要索引，覆盖索引，复合索引，前缀索引，唯一索引默认都是使用B+树索引，统称索引。此外还有哈希索引等。

> 索引是对数据库表中一列或多列的值进行排序的一种结构，使用索引可快速访问数据库表中的特定信息。索引的一个主要目的就是加快检索表中数据，亦即能协助信息搜索者尽快的找到符合限制条件的记录ID的辅助数据结构。

#### 创建索引

创建：

- 创建索引：`CREATE [UNIQUE] INDEX indexName ON mytable(username(length));`

  如果是CHAR，VARCHAR类型，length可以小于字段实际长度；如果是BLOB和TEXT类型，必须指定 length。

- 修改表结构(添加索引)：`ALTER table tableName ADD [UNIQUE] INDEX indexName(columnName)`

删除：`DROP INDEX [indexName] ON mytable;`

查看：`SHOW INDEX FROM table_name\G`             --可以通过添加 \G 来格式化输出信息。

使用ALERT命令：

- `ALTER TABLE tbl_name ADD PRIMARY KEY (column_list):` 该语句添加一个主键，这意味着索引值必须是唯一的，且不能为NULL。
- `ALTER TABLE tbl_name ADD UNIQUE index_name (column_list` 这条语句创建索引的值必须是唯一的（除了NULL外，NULL可能会出现多次）。
- `ALTER TABLE tbl_name ADD INDEX index_name (column_list)` 添加普通索引，索引值可出现多次。
- `ALTER TABLE tbl_name ADD FULLTEXT index_name (column_list)`该语句指定了索引为 FULLTEXT ，用于全文索引。，

> 1. 直接创建索引和间接创建索引
>    - 直接创建索引： `CREATE INDEX mycolumn_index ON mytable (myclumn)`,直接在某一张表的列上面建立索引。
>    - 间接创建索引：  定义主键约束或者唯一性键约束，可以间接创建索引。
> 2. 普通索引和唯一性索引
>    - 普通索引：`CREATE INDEX mycolumn_index ON mytable (myclumn)`
>    - 唯一性索引：保证在索引列中的全部数据是唯一的，对聚簇索引和非聚簇索引都可以使用
>
> ​         　`CREATE UNIQUE COUSTERED INDEX myclumn_cindex ON mytable(mycolumn)`
>
> 3. 单个索引和复合索引
>    - 单个索引：即非复合索引,通常使用一个字段创建索引。
>    - 复合索引：又叫组合索引，在索引建立语句中同时包含多个字段名，最多16个字段
>
> 　　　　`CREATE INDEX name_index ON username(firstname,lastname)`
>
> 4. 聚簇索引和非聚簇索引(聚集索引，群集索引)
>
>    - 聚簇索引：物理索引，与基表的物理顺序相同，数据值的顺序总是按照顺序排列
>
>      `CREATE CLUSTERED INDEX mycolumn_cindex ON mytable(mycolumn) WITH`
>
>      　　　　`ALLOW_DUP_ROW(允许有重复记录的聚簇索引)`
>
>    - 非聚簇索引：
>
> 　　　　`CREATE UNCLUSTERED INDEX mycolumn_cindex ON mytable(mycolumn)`

**分 类：** 聚簇索引 、非聚簇索引

**目 的：** 加快对表中记录的查找或排序

#### 索引的优缺点

**索引的特点：**

1. 索引可以加快数据库的检索速度
2. 索引降低了数据库插入、修改、删除等维护任务的速度
3. 索引创建在表上，不能创建在视图上
4. 索引既可以直接创建，也可以间接创建
5. 可以在优化隐藏中，使用索引

**优点：**

- 大大加快数据检索的速度，这个是建立索引的主要原因。
- 创建唯一性索引，保证数据库表中每一行数据的唯一性
- 将随机I/O变成顺序I/O(因为B+树的叶子节点是连接在一起的)
- 加速表与表之间的连接 
- 索引降低了数据库插入、修改、删除等维护任务的速度、
- 在使用分组和排序子句进行数据检索时，同样可以显著减少查询中分组和排序的时间。
- 索引创建在表上，不能创建在视图上
- 索引既可以直接创建，也可以间接创建。

> 总之建立索引就是为了提高数据库的性能。

**缺点：**

1. 从时间角度来考虑：建立索引和维护索引都需要时间开销，会影响数据库的性能，特别是随着数据量增加的时候。
2. 从空间考虑：索引需要占物理空间，除了数据表占数据空间之外，每一个索引还要占一定的物理空间，如果要建立聚簇索引，那么需要的空间就会更大
3. 当对表中的数据进行增加、删除和修改的时候，索引也要动态的维护，降低了数据的维护速度

#### 索引分类

##### 从数据结构角度

- B+树索引
- Hash索引
- Full-Text全文索引
- R-Tree索引

##### 从物理存储角度

- 聚集索引（clustered index）
- 非聚集索引（non-clustered index），也叫辅助索引（secondary index）聚集索引和非聚集索引都是B+树结构

##### 从逻辑角度

- 主键索引：主键索引是一种特殊的唯一索引，不允许有空值，在 MySQL 的 InnoDB 的表中，当没有显示的指定表的主键时，InnoDB 会自动先检查表中是否有唯一索引的字段，如果有，则选择该字段为默认的主键，否则 InnoDB 将会自动创建一个 6Byte 的自增主键。
- **普通索引(Index)** ，单列索引：**普通索引的唯一作用就是为了快速查询数据，一张表允许创建多个普通索引，并允许数据重复和 NULL。**
- 多列索引（复合索引、联合索引）：复合索引指多个字段上创建的索引，只有在查询条件中使用了创建索引时的第一个字段，索引才会被使用。**使用复合索引时遵循最左前缀集合**
- **唯一索引(Unique Key)** ：唯一索引也是一种约束。**唯一索引的属性列不能出现重复的数据，但是允许数据为 NULL，一张表允许创建多个唯一索引。** 建立唯一索引的目的大部分时候都是为了该属性列的数据的唯一性，而不是为了查询效率。
- **前缀索引(Prefix)** ：前缀索引只适用于字符串类型的数据。前缀索引是对文本的前几个字符创建索引，相比普通索引建立的数据更小，因为只取前几个字符。
- **全文索引(Full Text)** ：全文索引主要是为了检索大文本数据中的关键字的信息，是目前搜索引擎数据库使用的一种技术。Mysql5.6 之前只有 MYISAM 引擎支持全文索引，5.6 之后 InnoDB 也支持了全文索引。

> 为什么MySQL 索引中用B+tree，不用B-tree 或者其他树，为什么不用 Hash 索引
>
> 聚簇索引/非聚簇索引，MySQL 索引底层实现，叶子结点存放的是数据还是指向数据的内存地址，使用索引需要注意的几个地方？
>
> 使用索引查询一定能提高查询的性能吗？为什么?

#### Mysql索引

**首先要明白索引（index）是在存储引擎（storage engine）层面实现的，而不是server层面**。不是所有的存储引擎都支持所有的索引类型。即使多个存储引擎支持某一索引类型，它们的实现和行为也可能有所差别。

##### B+Tree索引

MyISAM 和 InnoDB 存储引擎，都使用 B+Tree的数据结构，它相对与 B-Tree结构，所有的数据都存放在叶子节点上，且把叶子节点通过指针连接到一起，形成了一条数据链表，以加快相邻数据的检索效率。

**先了解下 B-Tree 和 B+Tree 的区别**

###### B-Tree：

B-Tree是为磁盘等外存储设备设计的一种平衡查找树。

系统从磁盘读取数据到内存时是以磁盘块（block）为基本单位的，位于同一个磁盘块中的数据会被一次性读取出来，而不是需要什么取什么。

InnoDB 存储引擎中有页（Page）的概念，页是其磁盘管理的最小单位。InnoDB 存储引擎中默认每个页的大小为16KB，可通过参数 `innodb_page_size` 将页的大小设置为 4K、8K、16K，在 MySQL 中可通过如下命令查看页的大小：`show variables like 'innodb_page_size';`

而系统一个磁盘块的存储空间往往没有这么大，因此 InnoDB 每次申请磁盘空间时都会是若干地址连续磁盘块来达到页的大小 16KB。InnoDB 在把磁盘数据读入到磁盘时会以页为基本单位，在查询数据时如果一个页中的每条数据都能有助于定位数据记录的位置，这将会减少磁盘I/O次数，提高查询效率。

B-Tree 结构的数据可以让系统高效的找到数据所在的磁盘块。为了描述 B-Tree，首先定义一条记录为一个二元组[key, data] ，key为记录的键值，对应表中的主键值，data 为一行记录中除主键外的数据。对于不同的记录，key值互不相同。

一棵m阶的B-Tree有如下特性：

1. 每个节点最多有m个孩子。
2. 除了根节点和叶子节点外，其它每个节点至少有Ceil(m/2)个孩子。
3. 若根节点不是叶子节点，则至少有2个孩子
4. 所有叶子节点都在同一层，且不包含其它关键字信息
5. 每个非终端节点包含n个关键字信息（P0,P1,…Pn, k1,…kn）
6. 关键字的个数n满足：ceil(m/2)-1 <= n <= m-1
7. ki(i=1,…n)为关键字，且关键字升序排序
8. Pi(i=1,…n)为指向子树根节点的指针。P(i-1)指向的子树的所有节点关键字均小于ki，但都大于k(i-1)

> B-Tree 中的每个节点根据实际情况可以包含大量的**关键字信息和分支**，如下图所示为一个 3 阶的 B-Tree：

![1640657071545](https://tprzfbucket.oss-cn-beijing.aliyuncs.com/hadoop/202112/28/100432-406269.png)

每个节点占用一个盘块的磁盘空间，一个节点上有两个升序排序的关键字和三个指向子树根节点的指针，指针存储的是子节点所在磁盘块的地址。两个关键词划分成的三个范围域对应三个指针指向的子树的数据的范围域。以根节点为例，关键字为17和35，P1指针指向的子树的数据范围为小于17，P2指针指向的子树的数据范围为17~35，P3指针指向的子树的数据范围为大于35。

模拟查找关键字29的过程：

1. 根据根节点找到磁盘块1，读入内存。【磁盘I/O操作第1次】
2. 比较关键字29在区间（17,35），找到磁盘块1的指针P2。
3. 根据P2指针找到磁盘块3，读入内存。【磁盘I/O操作第2次】
4. 比较关键字29在区间（26,30），找到磁盘块3的指针P2。
5. 根据P2指针找到磁盘块8，读入内存。【磁盘I/O操作第3次】
6. 在磁盘块8中的关键字列表中找到关键字29。

分析上面过程，发现需要3次磁盘I/O操作，和3次内存查找操作。由于内存中的关键字是一个有序表结构，可以利用二分法查找提高效率。而3次磁盘I/O操作是影响整个B-Tree查找效率的决定因素。B-Tree相对于AVLTree缩减了节点个数，使每次磁盘I/O取到内存的数据都发挥了作用，从而提高了查询效率。

###### B+Tree

B+Tree 是在 B-Tree 基础上的一种优化，使其更适合实现外存储索引结构，**InnoDB 存储引擎就是用 B+Tree 实现其索引结构。**

从上一节中的B-Tree结构图中可以看到每个节点中不仅包含数据的key值，还有data值。而每一个页的存储空间是有限的，如果data数据较大时将会导致每个节点（即一个页）能存储的key的数量很小，当存储的数据量很大时同样会导致B-Tree的深度较大，增大查询时的磁盘I/O次数，进而影响查询效率。在B+Tree中，**所有数据记录节点都是按照键值大小顺序存放在同一层的叶子节点上**，**而非叶子节点上只存储key值信息，这样可以大大加大每个节点存储的key值数量，降低B+Tree的高度。**

B+Tree相对于B-Tree有几点不同：

1. 非叶子节点只存储键值信息；
2. 所有叶子节点之间都有一个链指针；
3. 数据记录都存放在叶子节点中

将上一节中的B-Tree优化，由于B+Tree的非叶子节点只存储键值信息，假设每个磁盘块能存储4个键值及指针信息，则变成B+Tree后其结构如下图所示： 

![1640657101315](https://tprzfbucket.oss-cn-beijing.aliyuncs.com/hadoop/202112/28/100503-278380.png)

**通常在B+Tree上有两个头指针，一个指向根节点，另一个指向关键字最小的叶子节点，而且所有叶子节点（即数据节点）之间是一种链式环结构**。因此可以对B+Tree进行两种查找运算：**一种是对于主键的范围查找和分页查找，另一种是从根节点开始，进行随机查找。**

可能上面例子中只有22条数据记录，看不出B+Tree的优点，下面做一个推算：

InnoDB存储引擎中页的大小为16KB，一般表的主键类型为INT（占用4个字节）或BIGINT（占用8个字节），指针类型也一般为4或8个字节，也就是说一个页（B+Tree中的一个节点）中大概存储16KB/(8B+8B)=1K个键值（因为是估值，为方便计算，这里的K取值为10^3）。也就是说一个深度为3的B+Tree索引可以维护10^3 * 10^3 * 10^3 = 10亿 条记录。

实际情况中每个节点可能不能填充满，因此在数据库中，B+Tree的高度一般都在2-4层。MySQL的InnoDB存储引擎在设计时是将根节点常驻内存的，也就是说查找某一键值的行记录时最多只需要1~3次磁盘I/O操作。

B+Tree性质

1. 通过上面的分析，我们知道IO次数取决于b+数的高度h，假设当前数据表的数据为N，每个磁盘块的数据项的数量是m，则有h=㏒(m+1)N，当数据量N一定的情况下，m越大，h越小；而m = 磁盘块的大小 / 数据项的大小，磁盘块的大小也就是一个数据页的大小，是固定的，如果数据项占的空间越小，数据项的数量越多，树的高度越低。**这就是为什么每个数据项，即索引字段要尽量的小**，比如int占4字节，要比bigint8字节少一半。这也是为什么b+树要求把真实的数据放到叶子节点而不是内层节点，一旦放到内层节点，磁盘块的数据项会大幅度下降，导致树增高。当数据项等于1时将会退化成线性表。
2. 当b+树的数据项是复合的数据结构，比如(name,age,sex)的时候，b+数是按照从左到右的顺序来建立搜索树的，比如当(张三,20,F)这样的数据来检索的时候，b+树会优先比较name来确定下一步的所搜方向，如果name相同再依次比较age和sex，最后得到检索的数据；但当(20,F)这样的没有name的数据来的时候，b+树就不知道下一步该查哪个节点，因为建立搜索树的时候name就是第一个比较因子，必须要先根据name来搜索才能知道下一步去哪里查询。比如当(张三,F)这样的数据来检索时，b+树可以用name来指定搜索方向，但下一个字段age的缺失，所以只能把名字等于张三的数据都找到，然后再匹配性别是F的数据了， 这个是非常重要的性质，即**索引的最左匹配特性**。

###### MyISAM主键索引与辅助索引的结构

MyISAM引擎的索引文件和数据文件是分离的。**MyISAM引擎索引结构的叶子节点的数据域，存放的并不是实际的数据记录，而是数据记录的地址**。索引文件与数据文件分离，这样的索引称为"**非聚簇索引**"。MyISAM的主索引与辅助索引区别并不大，只是主键索引不能有重复的关键字。

![1640657556602](https://tprzfbucket.oss-cn-beijing.aliyuncs.com/hadoop/202112/28/101237-759092.png)

在MyISAM中，索引（含叶子节点）存放在单独的.myi文件中，叶子节点存放的是数据的物理地址偏移量（**通过偏移量访问就是随机访问，速度很快**）。

**主索引是指主键索引，键值不可能重复；辅助索引则是普通索引，键值可能重复。**

通过索引查找数据的流程：先从索引文件中查找到索引节点，从中拿到数据的文件指针，再到数据文件中通过文件指针定位了具体的数据。辅助索引类似。

###### InnoDB主键索引与辅助索引的结构

**InnoDB引擎索引结构的叶子节点的数据域，存放的就是实际的数据记录**（对于主索引，此处会存放表中所有的数据记录；对于辅助索引此处会引用主键，检索的时候通过主键到主键索引中找到对应数据行），或者说，**InnoDB的数据文件本身就是主键索引文件**，这样的索引被称为"“聚簇索引”，一个表只能有一个聚簇索引。

###### 主键索引：

我们知道InnoDB索引是聚集索引，它的索引和数据是存入同一个.idb文件中的，**因此它的索引结构是在同一个树节点中同时存放索引和数据**，如下图中最底层的叶子节点有三行数据，对应于数据表中的id、stu_id、name数据项。

![1640657731717](https://tprzfbucket.oss-cn-beijing.aliyuncs.com/hadoop/202112/28/101532-24937.png)

在Innodb中，索引分叶子节点和非叶子节点，非叶子节点就像新华字典的目录，单独存放在索引段中，叶子节点则是顺序排列的，在数据段中。Innodb的数据文件可以按照表来切分（只需要开启`innodb_file_per_table)`，切分后存放在`xxx.ibd`中，默认不切分，存放在`xxx.ibdata`中。

###### 辅助（非主键）索引：

这次我们以示例中学生表中的name列建立辅助索引，它的索引结构跟主键索引的结构有很大差别，在最底层的叶子结点有两行数据，第一行的字符串是辅助索引，按照ASCII码进行排序，第二行的整数是主键的值。

这就意味着，对name列进行条件搜索，需要两个步骤：

① 在辅助索引上检索name，到达其叶子节点获取对应的主键；

② 使用主键在主索引上再进行对应的检索操作

这也就是所谓的“**回表查询**”

![1640657775830](https://tprzfbucket.oss-cn-beijing.aliyuncs.com/hadoop/202112/28/101626-186268.png)

###### **InnoDB 索引结构需要注意的点**

1. **数据文件本身就是索引文件**
2. 表数据文件本身就是按 B+Tree 组织的一个索引结构文件
3. **聚集索引中叶节点包含了完整的数据记录**
4. InnoDB 表必须要有**主键**，并且推荐使用整型自增主键

正如我们上面介绍 InnoDB 存储结构，索引与数据是共同存储的，不管是主键索引还是辅助索引，在查找时都是通过先查找到索引节点才能拿到相对应的数据，**如果我们在设计表结构时没有显式指定索引列的话，MySQL 会从表中选择数据不重复的列建立索引，如果没有符合的列，则 MySQL 自动为 InnoDB 表生成一个隐含字段作为主键，并且这个字段长度为6个字节，类型为整型。**

> 那为什么推荐使用整型自增主键而不是选择UUID？

- UUID是字符串，比整型消耗更多的存储空间；
- 在B+树中进行查找时需要跟经过的节点值比较大小，整型数据的比较运算比字符串更快速；
- 自增的整型索引在磁盘中会连续存储，在读取一页数据时也是连续；UUID是随机产生的，读取的上下两行数据存储是分散的，不适合执行where id > 5 && id < 20的条件查询语句。
- 在插入或删除数据时，整型自增主键会在叶子结点的末尾建立新的叶子节点，不会破坏左侧子树的结构；UUID主键很容易出现这样的情况，B+树为了维持自身的特性，有可能会进行结构的重构，消耗更多的时间。

> 为什么非主键索引结构叶子节点存储的是主键值？

保证数据一致性和节省存储空间，可以这么理解：商城系统订单表会存储一个用户ID作为关联外键，而不推荐存储完整的用户信息，因为当我们用户表中的信息（真实名称、手机号、收货地址···）修改后，不需要再次维护订单表的用户数据，同时也节省了存储空间。

##### Hash索引

- 主要就是通过Hash算法（常见的Hash算法有**直接定址法、平方取中法、折叠法、除数取余法、随机数法**），将数据库字段数据转换成定长的Hash值，与这条数据的行指针一并存入Hash表的对应位置；如果发生Hash碰撞（两个不同关键字的Hash值相同），则在对应Hash键下以链表形式存储。
- 检索算法：在检索查询时，就再次对待查关键字再次执行相同的Hash算法，得到Hash值，到对应Hash表对应位置取出数据即可，如果发生Hash碰撞，则需要在取值时进行筛选。目前使用Hash索引的数据库并不多，主要有Memory等。
- MySQL目前有Memory引擎和NDB引擎支持Hash索引。

##### full-text全文索引

- 全文索引也是MyISAM的一种特殊索引类型，主要用于全文索引，InnoDB从MYSQL5.6版本提供对全文索引的支持。
- **它用于替代效率较低的LIKE模糊匹配操作，而且可以通过多字段组合的全文索引一次性全模糊匹配多个字段。**
- 同样使用B-Tree存放索引数据，但使用的是特定的算法，将字段数据分割后再进行索引（一般每4个字节一次分割），索引文件存储的是分割前的索引字符串集合，与分割后的索引信息，对应Btree结构的节点存储的是分割后的词信息以及它在分割前的索引字符串集合中的位置。

##### R-Tree空间索引

空间索引是MyISAM的一种特殊索引类型，主要用于地理空间数据类型

##### 为什么Mysql索引要用B+树不是B树？

用B+树不用B树考虑的是**IO对性能的影响**，B树的每个节点都存储数据，而B+树只有叶子节点才存储数据，所以查找相同数据量的情况下，B树的高度更高，IO更频繁。数据库索引是存储在磁盘上的，当数据量大时，就不能把整个索引全部加载到内存了，只能逐一加载每一个磁盘页（对应索引树的节点）。其中在MySQL底层对B+树进行进一步优化：在叶子节点中是双向链表，且在链表的头结点和尾节点也是循环指向的。

##### 面试官：为何不采用Hash方式？

因为Hash索引底层是哈希表，哈希表是一种以key-value存储数据的结构，所以多个数据在存储关系上是完全没有任何顺序关系的，所以，对于区间查询是无法直接通过索引查询的，就需要全表扫描。

所以，哈希索引只适用于**等值查询**的场景。而B+ Tree是一种多路平衡查询树，所以他的节点是天然有序的（左子节点小于父节点、父节点小于右子节点），所以对于范围查询的时候不需要做全表扫描。

哈希索引不支持多列联合索引的最左匹配规则，如果有大量重复键值得情况下，哈希索引的效率会很低，因为存在哈希碰撞问题。

#### 哪些情况需要创建索引

1. 主键自动建立唯一索引
2. 频繁作为查询条件的字段
3. 查询中与其他表关联的字段，外键关系建立索引
4. 单键/组合索引的选择问题，高并发下倾向创建组合索引
5. 查询中排序的字段，排序字段通过索引访问大幅提高排序速度
6. 查询中统计或分组字段

#### 哪些情况不要创建索引

1. 表记录太少
2. 经常增删改的表
3. 数据重复且分布均匀的表字段，只应该为最经常查询和最经常排序的数据列建立索引（如果某个数据类包含太多的重复数据，建立索引没有太大意义）
4. 频繁更新的字段不适合创建索引（会加重IO负担）
5. where条件里用不到的字段不创建索引

#### MySQL覆盖索引

**覆盖索引**（Covering Index）,或者叫索引覆盖， 也就是平时所说的不需要回表操作

- 就是select的数据列只用从索引中就能够取得，不必读取数据行，MySQL可以利用索引返回select列表中的字段，而不必根据索引再次读取数据文件，换句话说**查询列要被所建的索引覆盖**。

- 索引是高效找到行的一个方法，但是一般数据库也能使用索引找到一个列的数据，因此它不必读取整个行。毕竟索引叶子节点存储了它们索引的数据，当能通过读取索引就可以得到想要的数据，那就不需要读取行了。一个索引包含（覆盖）满足查询结果的数据就叫做覆盖索引。

- **判断标准**

  使用explain，可以通过输出的extra列来判断，对于一个索引覆盖查询，显示为**using index**，MySQL查询优化器在执行查询前会决定是否有索引覆盖查询

#### 索引的类型有哪些

MySQL主要的索引类型主要有FULLTEXT，HASH，BTREE，RTREE。
**FULLTEXT**

- FULLTEXT即全文索引，MyISAM存储引擎和InnoDB存储引擎在MySQL5.6.4以上版本支持全文索引，一般用于查找文本中的关键字，而不是直接比较是否相等，多在CHAR，VARCHAR，TAXT等数据类型上创建全文索引。全文索引主要是用来解决WHERE name LIKE "%zhang%"等针对文本的模糊查询效率低的问题。

**HASH**

- HASH即哈希索引，哈希索引多用于等值查询，时间复杂夫为o(1)，效率非常高，但不支持排序、范围查询及模糊查询等。

**BTREE**

- BTREE即B+树索引，INnoDB存储引擎默认的索引，支持排序、分组、范围查询、模糊查询等，并且性能稳定。

**RTREE**

- RTREE即空间数据索引，多用于地理数据的存储，相比于其他索引，空间数据索引的优势在于范围查找 

#### 索引的种类有哪些？

1. 主键索引：数据列不允许重复，不能为NULL，一个表只能有一个主键索引
2. 组合索引：由多个列值组成的索引。
3. 唯一索引：数据列不允许重复，可以为NULL，索引列的值必须唯一的，如果是组合索引，则列值的组合必须唯一。
4. 全文索引：对文本的内容进行搜索。
5. 普通索引：基本的索引类型，可以为NULL 。

#### 索引的数据结构

索引的数据结构主要有**B+树和哈希表，对应的索引分别为B+树索引和哈希索引**。InnoDB引擎的索引类型有B+树索引和哈希索引，默认的索引类型为B+树索引 。

##### **B+树索引**

熟悉数据结构的同学都知道，B+树、平衡二叉树、红黑树都是经典的数据结构。在B+树中，所有的记录节点都是按照键值大小的顺序放在叶子节点上，如下图。 

![1631755572547](https://tprzfbucket.oss-cn-beijing.aliyuncs.com/hadoop/202109/16/092644-99595.png)

关于B树B+树这种数据结构，请参考文章：[数据结构-（2-3树，2-3-4树，B-树，B+树）](https://blog.csdn.net/qq_38163244/article/details/109704712)

从上图可以看出 ，因为B+树具有有序性，并且所有的数据都存放在叶子节点，所以查找的效率非常高，并且支持排序和范围查找。

B+树的索引又可以分为**主索引和辅助索引**。其中主索引为聚簇索引，辅助索引为非聚簇索引。聚簇索引是以主键作为B+ 树索引的键值所构成的B+树索引，聚簇索引的叶子节点存储着完整的数据记录；

非聚簇索引是以非主键的列作为B+树索引的键值所构成的B+树索引，非聚簇索引的叶子节点存储着主键值。所以使用非聚簇索引进行查询时，会先找到主键值，然后到根据聚簇索引找到主键对应的数据域。上图中叶子节点存储的是数据记录，为聚簇索引的结构图，非聚簇索引的结构图如下: 

![1631755805924](https://tprzfbucket.oss-cn-beijing.aliyuncs.com/hadoop/202112/29/093929-374473.png)

上图中的字母为数据的非主键的列值，假设要查询该列值为B的信息，则需先找到主键7，在到聚簇索引中查询主键7所对应的数据域。

##### **哈希索引**

哈希索引是基于哈希表实现的，对于每一行数据，存储引擎会对索引列通过哈希算法进行哈希计算得到哈希码，并且哈希算法要尽量保证不同的列值计算出的哈希码值是不同的，将哈希码的值作为哈希表的key值，将指向数据行的指针作为哈希表的value值。这样查找一个数据的时间复杂度就是o(1)，一般多用于精确查找 。

#### Hash索引和B+树的区别？

因为两者数据结构上的差异导致它们的使用场景也不同，哈希索引一般多用于**精确的等值查找**，B+索引则多用于除了精确的等值查找外的其他查找。在大多数情况下，会选择使用B+树索引。

- 哈希索引不支持排序，因为哈希表是无序的。
- 哈希索引不支持范围查找。
- 哈希索引不支持模糊查询及多列索引的最左前缀匹配。
- 因为哈希表中会存在哈希冲突，所以哈希索引的性能是不稳定的，而B+树索引的性能是相对稳定的，每次查询都是从根节点到叶子节点 。

#### B树和B+树的区别？

B树和B+树最主要的区别主要有两点：

- B树中的内部节点和叶子节点均存放键和值，而B+树的内部节点只有键没有值，叶子节点存放所有的键和值。
- B＋树的叶子节点是通过相连在一起的，方便顺序检索。

两者的结构图如下：

**B树**

![1631756434279](https://tprzfbucket.oss-cn-beijing.aliyuncs.com/hadoop/202109/16/094038-927137.png)

**B+树**

![1631756460901](https://tprzfbucket.oss-cn-beijing.aliyuncs.com/hadoop/202109/16/094111-18813.png)

关于B树B+树这种数据结构，请参考文章：[数据结构-（2-3树，2-3-4树，B-树，B+树）](https://blog.csdn.net/qq_38163244/article/details/109704712)

#### 数据库为什么使用B+树而不是B树？ 

1. B树适用于随机检索，因为B树中非叶子节点存储的有键对应的值，而B+树适用于随机检索和顺序检索，因为B+树中所有的叶子节点都连接在一起，可以顺序查找。
2. B+树的空间利用率更高，因为B树每个节点要存储键和值，而B+树的内部节点只存储键，这样B+树的一个节点就可以存储更多的索引，从而使树的高度变低，减少了I/O次数，使得数据检索速度更快。相反B+树中，每一个节点存储的数据是有限的，这也就导致了相同的数据量，使用B树高度会更高，导致IO次数更多。
3. B+树的叶子节点都是连接在一起的，所以范围查找，顺序查找更加方便
4. B+树的性能更加稳定，因为在B+树中，每次查询都是从根节点到叶子节点，而在B树中，要查询的值可能不在叶子节点，在内部节点就已经找到。

那在什么情况适合使用B树呢，因为B树的内部节点也可以存储值，所以可以把一些频繁访问的值放在距离根节点比较近的地方，这样就可以提高查询效率。综上所述，B+树的性能更加适合作为数据库的索引 

> 用B+树不用B树考虑的是**IO对性能的影响**，B树的每个节点都存储数据，而B+树只有叶子节点才存储数据，所以查找相同数据量的情况下，B树的高度更高，IO更频繁。数据库索引是存储在磁盘上的，当数据量大时，就不能把整个索引全部加载到内存了，只能逐一加载每一个磁盘页（对应索引树的节点）。其中在MySQL底层对B+树进行进一步优化：在叶子节点中是双向链表，且在链表的头结点和尾节点也是循环指向的。

#### 面试官：为何不采用Hash方式？

因为Hash索引底层是哈希表，哈希表是一种以key-value存储数据的结构，所以多个数据在存储关系上是完全没有**任何顺序关系**的，所以，对于**区间查询**是无法直接通过索引查询的，就需要全表扫描。

所以，哈希索引只适用于**等值查询**的场景。而B+ Tree是一种多路平衡查询树，所以他的节点是天然有序的（左子节点小于父节点、父节点小于右子节点），所以对于范围查询的时候不需要做全表扫描。

哈希索引不支持多列联合索引的最左匹配规则，如果有大量重复键值得情况下，哈希索引的效率会很低，因为存在哈希碰撞问题。

#### 什么是聚簇索引，什么是非聚簇索引？

聚簇索引和非聚簇索引最主要的区别是**数据和索引是否分开存储**。

- 聚簇索引：将数据和索引放到一起存储，索引结构的叶子节点保留了数据行。
- 非聚簇索引：将数据进和索引分开存储，索引叶子节点存储的是指向数据行的地址。

在InnoDB存储引擎中，默认的索引为B+树索引，利用主键创建的索引为主索引，也是聚簇索引，在主索引之上创建的索引为辅助索引，也是非聚簇索引。为什么说辅助索引是在主索引之上创建的呢，因为辅助索引中的叶子节点存储的是主键。

在MyISAM存储引擎中，默认的索引也是B+树索引，但主索引和辅助索引都是非聚簇索引，**也就是说索引结构的叶子节点存储的都是一个指向数据行的地址。并且使用辅助索引检索无需访问主键的索引**。可以从非常经典的两张图看看它们的区别(图片来源于网络)： 

> 在MyISAM引擎中，不管使用的是主键索引，还是非主键索引，那么叶子节点中存储的都是数据的偏移量，所以根据这个偏移量，可以直接取查找数据，但是在Innodb中，如果使用的是非主键索引，那么还需要定位主键索引才能够找到数据。

![1631756839489](https://tprzfbucket.oss-cn-beijing.aliyuncs.com/hadoop/202109/16/094730-925250.png)

![1631756868658](https://tprzfbucket.oss-cn-beijing.aliyuncs.com/hadoop/202109/16/094750-68141.png)

##### 聚集索引的优点

聚集索引的查询速度非常的快，因为整个 B+树本身就是一颗多叉平衡树，叶子节点也都是有序的，定位到索引的节点，就相当于定位到了数据。

##### 聚集索引的缺点

1. **依赖于有序的数据** ：因为 B+树是多路平衡树，如果索引的数据不是有序的，那么就需要在插入时排序，如果数据是整型还好，否则类似于字符串或 UUID 这种又长又难比较的数据，插入或查找的速度肯定比较慢。
2. **更新代价大** ： 如果对索引列的数据被修改时，那么对应的索引也将会被修改，
   而且况聚集索引的叶子节点还存放着数据，修改代价肯定是较大的，
   所以对于主键索引来说，主键一般都是不可被修改的。

非聚集索引的优点

**更新代价比聚集索引要小** 。非聚集索引的更新代价就没有聚集索引那么大了，非聚集索引的叶子节点是不存放数据的

##### 非聚集索引的缺点

1. 跟聚集索引一样，非聚集索引也依赖于有序的数据
2. **可能会二次查询(回表)** :这应该是非聚集索引最大的缺点了。 当查到索引对应的指针或主键后，可能还需要根据指针或主键再到数据文件或表中查询。

这是 MySQL 的表的文件截图:

![](https://img-blog.csdnimg.cn/20210420165311654.png)

聚集索引和非聚集索引:

![](https://img-blog.csdnimg.cn/20210420165326946.png)

#### 非聚簇索引一定会进行回表查询吗？

上面是说了非聚簇索引的叶子节点存储的是主键，也就是说要先通过非聚簇索引找到主键，再通过聚簇索引找到主键所对应的数据，**后面这个再通过聚簇索引找到主键对应的数据的过程就是回表查询**，那么非聚簇索引就一定会进行回表查询吗 ？

答案是不一定的，这里涉及到一个索引覆盖的问题，如果查询的数据再辅助索引上完全能获取到便不需要回表查询。例如有一张表存储着个人信息包括id、name、age等字段。假设聚簇索引是以ID为键值构建的索引，非聚簇索引是以name为键值构建的索引， `select id,name from user where name =zhangsan`; 这个查询便不需要进行回表查询因为，通过非聚簇索引已经能全部检索出数据，这就是索引覆盖的情况。如果查询语句是这样， `select id,name,age from user where name ='zhangsan`; 则需要进行回表查询，因为通过非聚簇索引不能检索出age的值。那应该如何解决那呢？只需要将索引覆盖即可，建立age和name的联合索引再使用 `select id,name,age from user where name = 'zhangsan`; 进行查询即可。所以通过索引覆盖能解决非聚簇索引回表查询的问题。 

#### 覆盖索引

如果一个索引包含（或者说覆盖）所有需要查询的字段的值，我们就称之为“覆盖索引”。我们知道在 InnoDB 存储引擎中，如果不是主键索引，叶子节点存储的是主键+列值。最终还是要“回表”，也就是要通过主键再查找一次。这样就会比较慢覆盖索引就是把要查询出的列和索引是对应的，不做回表操作！

**覆盖索引即需要查询的字段正好是索引的字段，那么直接根据该索引，就可以查到数据了，
而无需回表查询。**

> 如主键索引，如果一条 SQL 需要查询主键，那么正好根据主键索引就可以查到主键。
>
> 再如普通索引，如果一条 SQL 需要查询 name，name 字段正好有索引，
> 那么直接根据这个索引就可以查到数据，也无需回表。

覆盖索引:
![](https://img-blog.csdnimg.cn/20210420165341868.png)

#### 索引的使用场景有哪些？

- 对于中大型表建立索引非常有效，对于非常小的表，一般全部表扫描速度更快些。
- 对于超大型的表，建立和维护索引的代价也会变高，这时可以考虑分区技术。
- 如果表的增删改非常多，而查询需求非常少的话，那就没有必要建立索引了，因为维护索引也是需要代价的。
- 一般不会出现再where条件中的字段就没有必要建立索引了。
- 多个字段经常被查询的话可以考虑联合索引。
- 字段多且字段值没有重复的时候考虑唯一索引。
- 字段多且有重复的时候考虑普通索引 

#### 索引的设计原则有哪些？

1. 最适合索引的列是在***where*后面出现的列或者连接句子中指定的列**，而不是出现在SELECT关键字后面的选择列表中的列。
2. **索引列的基数越大，索引的效果越好**，换句话说就是索引列的区分度越高，索引的效果越好。比如使用性别这种区分度很低的列作为索引，效果就会很差，因为列的基数最多也就是三种，大多不是男性就是女性。
3. 尽量使用短索引，对于较长的字符串进行索引时应该指定一个较短的前缀长度，因为较小的索引涉及到的磁盘I/O较少，并且索引高速缓存中的块可以容纳更多的键值，会使得查询速度更快。尽量利用最左前缀。
4. 不要过度索引，每个索引都需要额外的物理空间，维护也需要花费时间，所以索引不是越多越好。 

#### 如何对索引进行优化

1. 对索引的优化其实最关键的就是要符合索引的设计原则和应用场景，将不符合要求的索引优化成符合索引设计原则和应用场景的索引。
2. 除了索引的设计原则和应用场景那几点外，还可以从以下两方面考虑。
3. 在进行查询时，索引列不能是表达式的一部分，也不能是函数的参数，因为这样无法使用索引。例如 `select * from table_name where a + 1 = 2`。
4. 将区分度最高的索引放在前面
5. 尽量少使用`select*`。

索引的使用场景、索引的设计原则和如何对索引进行优化可以看成一个问题。 

#### 如何创建删除索引？

**创建索引：**

1. 使用CREATE INDEX 语句

```sql
CREATE INDEX index_name ON table_name (column_list);
```

2. 在CREATE TABLE时创建 

```sql
CREATE TABLE user(
  id INT PRIMARY KEY,
  information text,
  FULLTEXT KEY (information)
);
```

3. 使用ALTER TABLE创建索引 

```sql
ALTER TABLE table_name ADD INDEX index_name (column_list);
```

**删除索引**

1. 删除主键索引 

```sql
alter table 表名 drop primary key
```

2. 删除其他索引

```sql
alter table 表名 drop key 索引名
```

#### 使用索引查询时性能一定会提升吗？

不一定，前面在索引的使用场景和索引的设计原则中已经提到了如何合理地使用索引，因为创建和维护索引需要花费空间和时间上的代价，如果不合理地使用索引反而会使查询性能下降 。

#### 什么是前缀索引

**前缀索引是指对文本或者字符串的前几个字符建立索引**，这样索引的长度更短，查询速度更快。

- 使用场景：前缀的区分度比较高的情况下。
- 建立前缀索引的方式

```sql
ALTER TABLE table_name ADD KEY(column_name(prefix_length));
```

这里面有个prefix_length参数很难确定，这个参数就是前缀长度的意思。通常可以使用以下方法进行确定，先计算全列的区分度。

```sql
SELECT COUNT(DISTINCT column_name) / COUNT(*) FROM table_name;
```

然后在计算前缀长度为多少时和全列的区分度最相似。

```sql
SELECT COUNT(DISTINCT LEFT(column_name, prefix_length)) / COUNT(*) FROM table_name
```

不断地调整`prefix_length`的值，直到和全列计算出区分度相近。 

#### 什么是最左匹配原则

最左匹配原则：从最左边为起点开始连续匹配，遇到范围查询（<、>、between、like）会停止匹配。

例如建立索引(a,b,c)，大家可以猜测以下几种情况是否用到了索引 

**第一种**

```sql
select * from table_name where a = 1 and b = 2 and c = 3
select * from table_name where b = 2 and a = 1 and c = 3 -- 调动索引字段顺序不会影响查询效率
```

上面两次查询过程中所有值都用到了索引，where后面字段调换不会影响查询结果，因为MySQL中的优化器会自动优化查询顺序。 

**第二种**

```sql
select * from table_name where a = 1
select * from table_name where a = 1 and b = 2
select * from table_name where a = 1 and b = 2 and c = 3
```

答案是三个查询语句都用到了索引，因为三个语句都是从最左开始匹配的。 

**第三种**

```sql
select * from table_name where b = 1
select * from table_name where b = 1 and c = 2
```

答案是这两个查询语句都没有用到索引，因为不是从最左边开始匹配的 ,建立的索引a没有生效，所以索引b,c都失效。

**第四种**

```sql
select * from table_name where a = 1 and c = 2
```

这个查询语句只有a列用到了索引，c列没有用到索引，因为中间跳过了b列，不是从最左开始连续匹配的,这里索引c失效。

**第五种**

```sql 
select * from table_name where a = 1 and b < 3 and c < 1
```

这个查询中只有a列和b列使用到了索引，而c列没有使用索引，因为根据最左匹配查询原则，遇到范围查询会停止。

**第六种**

```sql 
select * from table_name where a like 'ab%';
select * from table_name where a like '%ab'
select * from table_name where a like '%ab%'
```

对于列为字符串的情况，只有前缀匹配可以使用索引，中缀匹配和后缀匹配只能进行全表扫描 .

> 对于字符串两端都有%的情况，可以使用覆盖索引。

#### 索引在什么情况下会失效？

在上面介绍了几种不符合最左匹配原则的情况会导致索引失效，除此之外，以下这几种情况也会导致索引失效。

1. 条件中有or，例如 `select * from table_name where a = 1 or b = 3`
2. 在索引上进行计算会导致索引失效，例如 `select * from table_name where a + 1 = 2`
3. 在索引的类型上进行数据类型的隐形转换，会导致索引失效，例如字符串一定要加引号，假设`select * from table_name where a = '1' `会使用到索引，如果写成 `select * from table_name where a = 1 `则会导致索引失效。
4. 在索引中使用函数会导致索引失效，例如 `select * from table_name where abs(a) = 1`
5. 在使用like查询时以%开头会导致索引失效
6. 索引上使用`！、=、<>`进行判断时会导致索引失效，例如` select * from table_name where a!= 1`
7. 索引字段上使用` is null/is not null`判断时会导致索引失效，例如 `select * from table_namewhere a is null `

### Mysql查询

> count(*) 和 count(1)和count(列名)区别   ps：这道题说法有点多

执行效果上：

- count(*)包括了所有的列，相当于行数，在统计结果的时候，不会忽略列值为NULL
- count(1)包括了所有列，用1代表代码行，在统计结果的时候，不会忽略列值为NULL
- count(列名)只包括列名那一列，在统计结果的时候，会忽略列值为空（这里的空不是只空字符串或者0，而是表示null）的计数，即某个字段值为NULL时，不统计。

执行效率上：

- 列名为主键，count(列名)会比count(1)快
- 列名不为主键，count(1)会比count(列名)快
- 如果表多个列并且没有主键，则 count(1) 的执行效率优于 count(*)
- 如果有主键，则 select count（主键）的执行效率是最优的
- 如果表只有一个字段，则 select count(*) 最优。

> MySQL中 in和 exists 的区别？

- exists：exists对外表用loop逐条查询，每次查询都会查看exists的条件语句，当exists里的条件语句能够返回记录行时（无论记录行是的多少，只要能返回），条件就为真，返回当前loop到的这条记录；反之，如果exists里的条件语句不能返回记录行，则当前loop到的这条记录被丢弃，exists的条件就像一个bool条件，当能返回结果集则为true，不能返回结果集则为false
- in：in查询相当于多个or条件的叠加

```sql
SELECT * FROM A WHERE A.id IN (SELECT id FROM B);
SELECT * FROM A WHERE EXISTS (SELECT * from B WHERE B.id = A.id);
```

**如果查询的两个表大小相当，那么用in和exists差别不大**。

如果两个表中一个较小，一个是大表，则子查询表大的用exists，子查询表小的用in：

> UNION和UNION ALL的区别?

UNION和UNION ALL都是将两个结果集合并为一个，**两个要联合的SQL语句 字段个数必须一样，而且字段类型要“相容”（一致）；**

- UNION在进行表连接后会筛选掉重复的数据记录（效率较低），而UNION ALL则不会去掉重复的数据记录；
- UNION会按照字段的顺序进行排序，而UNION ALL只是简单的将两个结果合并就返回；

#### SQL执行顺序

- 手写

  ```sql
  SELECT DISTINCT <select_list>
  FROM  <left_table> <join_type>
  JOIN  <right_table> ON <join_condition>
  WHERE  <where_condition>
  GROUP BY  <group_by_list>
  HAVING <having_condition>
  ORDER BY <order_by_condition>
  LIMIT <limit_number>
  复制代码
  ```

- 机读

  ```sql
  FROM  <left_table>
  ON <join_condition>
  <join_type> JOIN  <right_table> 
  WHERE  <where_condition>
  GROUP BY  <group_by_list>
  HAVING <having_condition>
  SELECT
  DISTINCT <select_list>
  ORDER BY <order_by_condition>
  LIMIT <limit_number>
  复制代码
  ```

- 总结

![1640658451255](https://tprzfbucket.oss-cn-beijing.aliyuncs.com/hadoop/202112/28/102732-201961.png)

> mysql 的内连接、左连接、右连接有什么区别？
>
> 什么是内连接、外连接、交叉连接、笛卡尔积呢？

#### join图

![1640658483243](https://tprzfbucket.oss-cn-beijing.aliyuncs.com/hadoop/202112/31/082650-591926.png)





### 数据库事务

> 事务的隔离级别有哪些？MySQL的默认隔离级别是什么？
>
> 什么是幻读，脏读，不可重复读呢？
>
> MySQL事务的四大特性以及实现原理
>
> MVCC熟悉吗，它的底层原理？

#### 什么是数据库事务？

百度百科的解释：数据库事务( transaction)是访问并可能操作各种数据项的一个数据库操作序列，这些操作要么全部执行,要么全部不执行，是一个不可分割的工作单位。事务由事务开始与事务结束之间执行的全部数据库操作组成 

#### 事务的四大特性是什么？（ACID特性）

事务是由一组SQL语句组成的逻辑处理单元，具有4个属性，通常简称为事务的ACID属性。

- **A (Atomicity) 原子性**：整个事务中的所有操作，要么全部完成，要么全部不完成，不可能停滞在中间某个环节。事务在执行过程中发生错误，会被回滚（Rollback）到事务开始前的状态，就像这个事务从来没有执行过一样
- **C (Consistency) 一致性**：在事务开始之前和事务结束以后，数据库的完整性约束没有被破坏
- **I (Isolation)隔离性**：一个事务的执行不能其它事务干扰。即一个事务内部的操作及使用的数据对其它并发事务是隔离的，并发执行的各个事务之间不能互相干扰
- **D (Durability) 持久性**：在事务完成以后，该事务所对数据库所作的更改便持久的保存在数据库之中，并不会被回滚

![1640658625559](https://tprzfbucket.oss-cn-beijing.aliyuncs.com/hadoop/202112/28/103027-450235.png)

> 上面的四个特性中，底层的实现原理是mvcc

#### 数并发事务带来哪些问题?

在典型的应用程序中，多个事务并发运行，经常会操作相同的数据来完成各自的任务（多个用户对同一数据进行操作）。并发虽然是必须的，但可能会导致以下的问题。

- 脏读(Dirty Reads)：事务A更新了数据，但还没有提交，这时事务B读取到事务A更新后的数据，然后事务A回滚了，事务B读取到的数据就成为脏数据了。

![1640754623409](https://tprzfbucket.oss-cn-beijing.aliyuncs.com/hadoop/202112/29/131029-647685.png)

> 因为事务A读取到事务B**未提交的数据**,这就是脏读。

- 不可重复读（Non-Repeatable Reads)：事务A对数据进行多次读取，事务B在事务A多次读取的过程中执行了更新操作并提交了，导致事务A多次读取到的数据并不一致。

![1640754660315](https://tprzfbucket.oss-cn-beijing.aliyuncs.com/hadoop/202112/31/082912-262048.png)

> 事务A被事务B干扰到了！在事务A范围内，两个相同的查询，读取同一条记录，却返回了不同的数据，这就是**不可重复读**。

- 幻读（Phantom Reads)：幻读与不可重复读类似。它发生在一个事务A读取了几行数据，接着另一个并发事务B插入了一些数据时。在随后的查询中，事务A就会发现多了一些原本不存在的记录，就好像发生了幻觉一样，所以称为幻读。

![1640754695756](https://tprzfbucket.oss-cn-beijing.aliyuncs.com/hadoop/202112/31/082908-401624.png)

> 事务A查询一个范围的结果集，另一个并发事务B往这个范围中插入新的数据，并提交事务，然后事务A再次查询相同的范围，两次读取到的结果集却不一样了，这就是幻读。

- 丢失修改（Lost Update)：事务A和事务B都对同一个数据进行修改，事务A先修改，事务B随后修改，事务B的修改覆盖了事务A的修改。

> 不可重复度和幻读看起来比较像，它们主要的区别是：在不可重复读中，发现数据不一致主要是数据被更新了。在幻读中，发现数据不一致主要是数据增多或者减少了。

**幻读和不可重复读的区别：**

- **不可重复读的重点是修改**：在同一事务中，同样的条件，第一次读的数据和第二次读的数据不一样。（因为中间有其他事务提交了修改）
- **幻读的重点在于新增或者删除**：在同一事务中，同样的条件,，第一次和第二次读出来的记录数不一样。（因为中间有其他事务提交了插入/删除）

**并发事务处理带来的问题的解决办法：**

- “丢失修改”通常是应该完全避免的。但防止更新丢失，并不能单靠数据库事务控制器来解决，需要应用程序对要更新的数据加必要的锁来解决，因此，防止更新丢失应该是应用的责任。
- “脏读” 、 “不可重复读”和“幻读” ，其实都是数据库读一致性问题，必须由数据库提供一定的事务隔离机制来解决：
  - 一种是加锁：在读取数据前，对其加锁，阻止其他事务对数据进行修改。
  - 另一种是数据多版本并发控制（MultiVersion Concurrency Control，简称 **MVCC** 或 MCC），也称为多版本数据库：不用加任何锁， 通过一定机制生成一个数据请求时间点的一致性数据快照 （Snapshot)， 并用这个快照来提供一定级别 （语句级或事务级） 的一致性读取。从用户的角度来看，好象是数据库可以提供同一数据的多个版本。

#### 数据库的隔离级别有哪些？

数据库事务的隔离级别有4种，由低到高分别为

- **READ-UNCOMMITTED(读未提交)：** 最低的隔离级别，允许读取尚未提交的数据变更，**可能会导致脏读、幻读或不可重复读**。
- **READ-COMMITTED(读已提交)：** 允许读取并发事务已经提交的数据，**可以阻止脏读，但是幻读或不可重复读仍有可能发生**。
- **REPEATABLE-READ(可重复读)：** 对同一字段的多次读取结果都是一致的，除非数据是被本身事务自己所修改，**可以阻止脏读和不可重复读，但幻读仍有可能发生**。
- **SERIALIZABLE(可串行化)：** 最高的隔离级别，完全服从ACID的隔离级别。所有的事务依次逐个执行，这样事务之间就完全不可能产生干扰，也就是说，**该级别可以防止脏读、不可重复读以及幻读**。

![1640754804193](https://tprzfbucket.oss-cn-beijing.aliyuncs.com/hadoop/202112/29/131325-67317.png)

查看当前数据库的事务隔离级别：

```sql
show variables like 'tx_isolation'  
```

数据库的隔离级别可以解决数据库的脏读、不可重复读、幻读等问题。 

![1631760013652](https://tprzfbucket.oss-cn-beijing.aliyuncs.com/hadoop/202109/16/104026-432676.png)

![1640754087059](https://tprzfbucket.oss-cn-beijing.aliyuncs.com/hadoop/202112/29/130128-454830.png)

> MySQL的默认隔离级别是可重复读。 
>
> ~~这里需要注意的是：与 SQL 标准不同的地方在于 InnoDB 存储引擎在 **REPEATABLE-READ（可重读）** 事务隔离级别下使用的是 Next-Key Lock 锁算法，因此可以避免幻读的产生，这与其他数据库系统(如 SQL Server)是不同的。所以说 InnoDB 存储引擎的默认支持的隔离级别是 **REPEATABLE-READ（可重读）** 已经可以完全保证事务的隔离性要求，即达到了 SQL 标准的 **SERIALIZABLE(可串行化)** 隔离级别。~~
>
> MySQL InnoDB 的 REPEATABLE-READ（可重读）并不保证避免幻读，需要应用使用加锁读来保证。而这个加锁度使用到的机制就是 Next-Key Locks。

因为隔离级别越低，事务请求的锁越少，所以大部分数据库系统的隔离级别都是 **READ-COMMITTED(读取提交内容)** ，但是你要知道的是 InnoDB 存储引擎默认使用 **REPEATABLE-READ（可重读）** 并不会有任何性能损失。

InnoDB 存储引擎在 **分布式事务** 的情况下一般会用到 **SERIALIZABLE(可串行化)** 隔离级别。

下面通过事例一一阐述在事务的并发操作中可能会出现脏读，不可重复读，幻读和事务隔离级别的联系。

数据库的事务隔离越严格，并发副作用越小，但付出的代价就越大，因为事务隔离实质上就是使事务在一定程度上“串行化”进行，这显然与“并发”是矛盾的。同时，不同的应用对读一致性和事务隔离程度的要求也是不同的，比如许多应用对“不可重复读”和“幻读”并不敏感，可能更关心数据并发访问的能力。

> 那怎么解决脏读呢？Read committed！读提交，能解决脏读问题。
>
> 那怎么解决可能的不可重复读问题？Repeatable read ！
>
> 重复读，就是在开始读取数据（事务开启）时，不再允许修改操作。 **MySQL的默认事务隔离级别** 
>
> 分析：重复读可以解决不可重复读问题。写到这里，应该明白的一点就是，**不可重复读对应的是修改，即UPDATE操作。但是可能还会有幻读问题。因为幻读问题对应的是插入INSERT操作，而不是UPDATE操作**。
>
> 那怎么解决幻读问题？Serializable！
>
> Serializable 是最高的事务隔离级别，在该级别下，事务串行化顺序执行，可以避免脏读、不可重复读与幻读。简单来说，Serializable会在读取的每一行数据上都加锁，所以可能导致大量的超时和锁争用问题。这种事务隔离级别效率低下，比较耗数据库性能，一般不使用。

**比较**

![1640659354436](https://tprzfbucket.oss-cn-beijing.aliyuncs.com/hadoop/202112/28/104236-231465.png)

需要说明的是，**事务隔离级别和数据访问的并发性是对立的，事务隔离级别越高并发性就越差**。所以要根据具体的应用来确定合适的事务隔离级别，这个地方没有万能的原则。

MySQL InnoDB 存储引擎的默认支持的隔离级别是 **REPEATABLE-READ（可重读）**。我们可以通过`SELECT @@tx_isolation;`命令来查看，MySQL 8.0 该命令改为`SELECT @@transaction_isolation;`

这里需要注意的是：与 SQL 标准不同的地方在于InnoDB 存储引擎在 **REPEATABLE-READ（可重读）**事务隔离级别下使用的是Next-Key Lock 算法，**因此可以避免幻读的产生**，这与其他数据库系统(如 SQL Server)是不同的。所以说InnoDB 存储引擎的默认支持的隔离级别是 REPEATABLE-READ（可重读）已经可以完全保证事务的隔离性要求，即达到了 SQL标准的 **SERIALIZABLE(可串行化)**隔离级别，而且保留了比较好的并发性能。

因为隔离级别越低，事务请求的锁越少，所以大部分数据库系统的隔离级别都是**READ-COMMITTED(读已提交):**，但是你要知道的是InnoDB 存储引擎默认使用 **REPEATABLE-READ（可重读）**并不会有任何性能损失。

> InnoDB 存储引擎提供了对 XA 事务的支持，并通过 XA 事务来支持分布式事务的实现。分布式事务指的是允许多个独立的事务资源（transactional resources）参与到一个全局的事务中。事务资源通常是关系型数据库系统，但也可以是其他类型的资源。全局事务要求在其中的所有参与的事务要么都提交，要么都回滚，这对于事务原有的 ACID 要求又有了提高。另外，在使用分布式事务时，InnoDB 存储引擎的事务隔离级别必须设置为 SERIALIZABLE。

#### 数据库的事务是如何实现的？

我们这里以 MySQL 的 InnoDB 引擎为例来简单说一下。

MySQL InnoDB 引擎使用 **redo log(重做日志)** 保证事务的**持久性**，使用 **undo log(回滚日志)** 来保证事务的**原子性**。

MySQL InnoDB 引擎通过 **锁机制**、**MVCC** 等手段来保证事务的隔离性（ 默认支持的隔离级别是 **`REPEATABLE-READ`** ）。

保证了事务的持久性、原子性、隔离性之后，一致性才能得到保障。

#### 隔离级别是如何实现的？

事务的隔离机制主要是依靠**锁机制和MVCC(多版本并发控制)实现**的，**提交读和可重复读可以通过MVCC实现**，**串行化可以通过锁机制实现。**

数据库是通过**加锁**，来实现事务的隔离性的。这就好像，如果你想一个人静静，不被别人打扰，你就可以在房门上加上一把锁。

加锁确实好使，可以保证隔离性。比如**串行化隔离级别就是加锁实现的**。但是频繁的加锁，导致读数据时，没办法修改，修改数据时，没办法读取，大大**降低了数据库性能**。

**那么，如何解决加锁后的性能问题的？**

答案就是,**MVCC多版本并发控制**！它实现读取数据不用加锁，可以让读取数据同时修改。修改数据时同时可读取。

##### 什么是MVCC

MVCC(multiple version concurrent control)是一种控制并发的方法，主要用来提高数据库的并发性能。

MVCC，即**Multi-Version  Concurrency Control （多版本并发控制）**。它是一种并发控制的方法，一般在数据库管理系统中，实现对数据库的并发访问，在编程语言中实现事务内存。

> 通俗的讲，数据库中同时存在多个版本的数据，并不是整个数据库的多个版本，而是某一条记录的多个版本同时存在，在某个事务对其进行操作的时候，需要查看这一条记录的隐藏列事务版本id，比对事务id并根据事物隔离级别去判断读取哪个版本的数据。

数据库隔离级别读**已提交、可重复读** 都是基于MVCC实现的，相对于加锁简单粗暴的方式，它用更好的方式去处理读写冲突，能有效提高数据库并发性能。

在了解MVCC时应该先了解当前读和快照读。

- 当前读：读取的是数据库的最新版本，并且在读取时要保证其他事务不会修该当前记录，所以会对读取的记录加锁。
- 快照读：不加锁读取操作即为快照读，使用MVCC来读取快照中的数据，避免加锁带来的性能损耗。  

可以看到MVCC的作用就是在不加锁的情况下，解决数据库读写冲突问题，并且解决脏读、幻读、不可重复读等问题，但是不能解决丢失修改问题。 

##### MVCC实现原理

###### 事务版本号

事务每次开启前，都会从数据库获得一个**自增**长的事务ID，可以从事务ID判断事务的执行先后顺序。这就是事务版本号。

###### 隐士字段

对于InnoDB存储引擎，每一行记录都有两个隐藏列**trx_id**、**roll_pointer**，如果表中没有主键和非NULL唯一键时，则还会有第三个隐藏的主键列**row_id**。

![1640755088832](https://tprzfbucket.oss-cn-beijing.aliyuncs.com/hadoop/202112/29/131813-870378.png)

###### undo log

undo log，**回滚日志**，用于记录数据被修改前的信息。在表记录修改之前，会先把数据拷贝到undo log里，如果事务回滚，即可以通过undo log来还原数据。

可以这样认为，当delete一条记录时，undo log 中会记录一条对应的insert记录，当update一条记录时，它记录一条对应相反的update记录。

undo log有什么**用途**呢？

1. 事务回滚时，保证原子性和一致性。
2. 用于MVCC**快照读**。

###### 版本链

多个事务并行操作某一行数据时，不同事务对该行数据的修改会产生多个版本，然后通过回滚指针（roll_pointer），连成一个链表，这个链表就称为**版本链**。如下：

![1640755225922](https://tprzfbucket.oss-cn-beijing.aliyuncs.com/hadoop/202112/29/132028-838898.png)

其实，通过版本链，我们就可以看出**事务版本号、表格隐藏的列和undo log**它们之间的关系。我们再来小分析一下。

1. 假设现在有一张core_user表，表里面有一条数据,id为1，名字为孙权：

![1640755360940](https://tprzfbucket.oss-cn-beijing.aliyuncs.com/hadoop/202112/29/132243-125964.png)

2. 现在开启一个事务A：对core_user表执行`update core_user set name ="曹操" where id=1`,会进行如下流程操作
3. 首先获得一个事务ID=100
4. 把core_user表修改前的数据,拷贝到undo log
5. 修改core_user表中，id=1的数据，名字改为曹操
6. 把修改后的数据事务Id=101改成当前事务版本号，并把**roll_pointer**指向undo log数据地址。

###### 当前读和快照读

**快照读：** 读取的是记录数据的可见版本（有旧的版本）。不加锁,普通的select语句都是快照

**当前读**：读取的是记录数据的最新版本，显式加锁的都是当前读

###### Read View

- **Read View是什么呢？** 它就是事务执行SQL语句时，产生的读视图。实际上在innodb中，每个SQL语句执行前都会得到一个Read View。
- **Read View有什么用呢？** 它主要是用来做**可见性判断的，即判断当前事务可见哪个版本的数据**~

Read View是如何保证可见性判断的呢？我们先看看Read view 的几个重要属性

- m_ids:当前系统中那些活跃(未提交)的读写事务ID, 它数据结构为一个List。
- min_limit_id:表示在生成Read View时，当前系统中活跃的读写事务中最小的事务id，即m_ids中的最小值。
- max_limit_id:表示生成Read View时，系统中应该分配给下一个事务的id值。
- creator_trx_id: 创建当前Read View的事务ID

**Read view 匹配条件规则**如下：

1. 如果数据事务ID `trx_id < min_limit_id`，表明生成该版本的事务在生成Read View前，已经提交(因为事务ID是递增的)，所以该版本可以被当前事务访问。
2. 如果`trx_id>= max_limit_id`，表明生成该版本的事务在生成ReadView后才生成，所以该版本不可以被当前事务访问。
3. 如果 `min_limit_id =<trx_id< max_limit_id`,需腰分3种情况讨论

> - （1）.如果`m_ids`包含`trx_id`,则代表Read View生成时刻，这个事务还未提交，但是如果数据的`trx_id`等于`creator_trx_id`的话，表明数据是自己生成的，因此是**可见**的。
> - （2）如果`m_ids`包含`trx_id`，并且`trx_id`不等于`creator_trx_id`，则Read   View生成时，事务未提交，并且不是自己生产的，所以当前事务也是**看不见**的；
> - （3）.如果`m_ids`不包含`trx_id`，则说明你这个事务在Read View生成之前就已经提交了，修改的结果，当前事务是能看见的。

###### mvcc实现原理分析

查询一条记录，基于MVCC，是怎样的流程

1. 获取事务自己的版本号，即事务ID
2. 获取Read View
3. 查询得到的数据，然后Read View中的事务版本号进行比较。
4. 如果不符合Read View的可见性规则， 即就需要Undo log中历史快照;
5. 最后返回符合规则的数据

InnoDB 实现MVCC，是通过`Read View+ Undo Log` 实现的，Undo Log 保存了历史快照，Read View可见性规则帮助判断当前版本的数据是否可见。

###### 读已提交（RC）隔离级别，存在不可重复读问题的分析历程

1. 创建core_user表，插入一条初始化数据,如下：

![1640755806546](https://tprzfbucket.oss-cn-beijing.aliyuncs.com/hadoop/202112/31/085213-985907.png)

2. 隔离级别设置为读已提交（RC），事务A和事务B同时对core_user表进行查询和修改操作。

~~~ sql
事务A: select * fom core_user where id=1
事务B: update core_user set name =”曹操”
~~~

最后事务A查询到的结果是，**name=曹操**的记录，我们**基于MVCC**，来分析一下执行流程：

(1). A开启事务，首先得到一个事务ID为100

(2).B开启事务，得到事务ID为101

(3).事务A生成一个Read View，read view对应的值如下

![1640755899356](https://tprzfbucket.oss-cn-beijing.aliyuncs.com/hadoop/202112/29/133158-138722.png)

然后回到版本链：开始从版本链中挑选可见的记录：

![1640755936750](https://tprzfbucket.oss-cn-beijing.aliyuncs.com/hadoop/202112/29/133231-851687.png)

由图可以看出，最新版本的列name的内容是`孙权`，该版本的`trx_id`值为100。开始执行read view可见性规则校验：

~~~sql
min_limit_id(100)=<trx_id（100）<102;
creator_trx_id = trx_id =100;
~~~

由此可得，trx_id=100的这个记录，当前事务是可见的。所以查到是name为`孙权`的记录。

（4). 事务B进行修改操作，把名字改为曹操。把原数据拷贝到undo log,然后对数据进行修改，标记事务ID和上一个数据版本在undo log的地址。

(5) 提交事务

(6) 事务A再次执行查询操作，**新生成一个Read View**，Read View对应的值如下

![1640756039298](https://tprzfbucket.oss-cn-beijing.aliyuncs.com/hadoop/202112/29/133405-884332.png)

然后再次回到版本链：从版本链中挑选可见的记录：

![1640756089939](https://tprzfbucket.oss-cn-beijing.aliyuncs.com/hadoop/202112/29/133456-359037.png)

从图可得，最新版本的列name的内容是`曹操`，该版本的`trx_id`值为101。开始执行Read View可见性规则校验：

~~~sql
min_limit_id(100)=<trx_id（101）<max_limit_id（102);
但是,trx_id=101，不属于m_ids集合
~~~

因此，`trx_id=101`这个记录，对于当前事务是可见的。所以SQL查询到的是name为`曹操`的记录。

###### 可重复读（RR）隔离级别，解决不可重复读问题的分析

在RR隔离级别下，是如何解决不可重复读问题的呢？我们一起再来看下，

还是4.2小节那个流程，还是这个事务A和事务B，如下：

![1640756232248](https://tprzfbucket.oss-cn-beijing.aliyuncs.com/hadoop/202112/29/133720-437265.png)

实际上，各种事务隔离级别下的Read view工作方式，是不一样的，RR可以解决不可重复读问题，就是跟**Read view工作方式有关**。

- 在读已提交（RC）隔离级别下，同一个事务里面，**每一次查询都会产生一个新的Read View副本**，这样就可能造成同一个事务里前后读取数据可能不一致的问题（不可重复读并发问题）。

![1640756293346](https://tprzfbucket.oss-cn-beijing.aliyuncs.com/hadoop/202112/29/133815-145077.png)

- 在可重复读（RR）隔离级别下，**一个事务里只会获取一次read view**，都是副本共用的，从而保证每次查询的数据都是一样的。

![1640756329334](https://tprzfbucket.oss-cn-beijing.aliyuncs.com/hadoop/202112/29/133911-223001.png)

**实例分析**

事务A再次执行查询操作，复用老的Read View副本，Read View对应的值如下

![1640756409008](https://tprzfbucket.oss-cn-beijing.aliyuncs.com/hadoop/202112/29/134019-11096.png)

然后再次回到版本链：从版本链中挑选可见的记录：

![1640756469116](https://tprzfbucket.oss-cn-beijing.aliyuncs.com/hadoop/202112/29/134113-750406.png)

从图可得，最新版本的列name的内容是`曹操`，该版本的`trx_id`值为101。开始执行read view可见性规则校验：

~~~sql
min_limit_id(100)=<trx_id（101）<max_limit_id（102);
因为m_ids{100,101}包含trx_id（101），
并且creator_trx_id (100) 不等于trx_id（101）
~~~

所以，`trx_id=101`这个记录，对于当前事务是**不可见**的。这时候呢，版本链`roll_pointer`跳到下一个版本，`trx_id=100`这个记录，再次校验是否可见：

~~~ sql
min_limit_id(100)=<trx_id（100）< max_limit_id（102);
因为m_ids{100,101}包含trx_id（100），
并且creator_trx_id (100) 等于trx_id（100）
~~~

所以，`trx_id=100`这个记录，对于当前事务是**可见**的，所以两次查询结果，都是**name=孙权**的那个记录。即在可重复读（RR）隔离级别下，复用老的Read View副本，解决了**不可重复读**的问题。

**MVCC的实现原理：**

- 版本号
  - 系统版本号：是一个自增的ID，每开启一个事务，系统版本号都会递增。
  - 事务版本号：事务版本号就是事务开始时的系统版本号，可以通过事务版本号的大小判断事务的时间顺序。
- 行记录隐藏的列
  - DB_ROW_ID：所需空间6byte，隐含的自增ID，用来生成聚簇索引，如果数据表没有指定聚簇索引，InnoDB会利用这个隐藏ID创建聚簇索引。
  - DB_TRX_ID：所需空间6byte，最近修改的事务ID，记录创建这条记录或最后一次修改这条记录的事务ID。
  - DB_ROLL_PTR：所需空间7byte，回滚指针，指向这条记录的上一个版本。

它们大致长这样，省略了具体字段的值。 

![1631766785769](https://tprzfbucket.oss-cn-beijing.aliyuncs.com/hadoop/202109/16/123308-756365.png)

- undo日志
  - MVCC使用到的快照会存储在Undo日志中，该日志通过回滚指针将一个一个数据行的所有快照连接起来。它们大致长这样。 

![1631766852666](https://tprzfbucket.oss-cn-beijing.aliyuncs.com/hadoop/202109/16/123415-295865.png)

举一个简单的例子说明下，比如最开始的某条记录长这样 

![1631766895125](https://tprzfbucket.oss-cn-beijing.aliyuncs.com/hadoop/202112/29/134541-863966.png)

现在来了一个事务对他的年龄字段进行了修改，变成了这样 

![1631766934174](https://tprzfbucket.oss-cn-beijing.aliyuncs.com/hadoop/202109/16/123537-241262.png)

现在又来了一个事务2对它的性别进行了修改，它又变成了这样

![1631766991560](https://tprzfbucket.oss-cn-beijing.aliyuncs.com/hadoop/202112/13/201713-874040.png)

从上面的分析可以看出，事务对同一记录的修改，记录的各个会在Undo日志中连接成一个线性表，在表头的就是最新的旧纪录。

在重复读的隔离级别下，InnoDB的工作流程： 

**SELECT**
作为查询的结果要满足两个条件：

1. 当前事务所要查询的数据行快照的创建版本号必须小于当前事务的版本号，这样做的目的是保证当前事务读取的数据行的快照要么是在当前事务开始前就已经存在的，要么就是当前事务自身插入或者修改过的。
2. 当前事务所要读取的数据行快照的删除版本号必须是大于当前事务的版本号，如果是小于等于的话，表示该数据行快照已经被删除，不能读取。 

**INSERT**

1. 将当前系统版本号作为数据行快照的创建版本号。

**DELETE**

1. 将当前系统版本号作为数据行快照的删除版本号。

**UPDATE**

1. 保存当前系统版本号为更新前的数据行快照创建行版本号，并保存当前系统版本号为更新后的数据行快照的删除版本号，其实就是，先删除在插入即为更新。

总结一下，MVCC的作用就是在避免加锁的情况下最大限度解决读写并发冲突的问题，它可以实现提交读和可重复度两个隔离级 

### 数据库锁

> 数据库的乐观锁和悲观锁？
>
> MySQL 中有哪几种锁，列举一下？
>
> MySQL中InnoDB引擎的行锁是怎么实现的？
>
> MySQL 间隙锁有没有了解，死锁有没有了解，写一段会造成死锁的 sql 语句，死锁发生了如何解决，MySQL 有没有提供什么机制去解决死锁

#### 什么是数据库锁

当数据库有并发事务的时候，保证数据访问顺序的机制称为锁机制。

锁是计算机协调多个进程或线程并发访问某一资源的机制。

在数据库中，除传统的计算资源（如CPU、RAM、I/O等）的争用以外，数据也是一种供许多用户共享的资源。数据库锁定机制简单来说，**就是数据库为了保证数据的一致性，而使各种共享资源在被并发访问变得有序所设计的一种规则。**

> 打个比方，我们到淘宝上买一件商品，商品只有一件库存，这个时候如果还有另一个人买，那么如何解决是你买到还是另一个人买到的问题？这里肯定要用到事物，我们先从库存表中取出物品数量，然后插入订单，付款后插入付款表信息，然后更新商品数量。在这个过程中，使用锁可以对有限的资源进行保护，解决隔离和并发的矛盾。

#### 锁的分类

##### **从对数据操作的类型分类**：

- **读锁**（共享锁）：针对同一份数据，多个读操作可以同时进行，不会互相影响
- **写锁**（排他锁）：当前写操作没有完成前，它会阻断其他写锁和读锁

##### **从对数据操作的粒度分类**：

为了尽可能提高数据库的并发度，每次锁定的数据范围越小越好，理论上每次只锁定当前操作的数据的方案会得到最大的并发度，但是管理锁是很耗资源的事情（涉及获取，检查，释放锁等动作），**因此数据库系统需要在高并发响应和系统性能两方面进行平衡**，这样就产生了“锁粒度（Lock granularity）”的概念。

- **表级锁**：开销小，加锁快；不会出现死锁；锁定粒度大，发生锁冲突的概率最高，并发度最低（MyISAM 和 MEMORY 存储引擎采用的是表级锁）；
- **行级锁**：开销大，加锁慢；会出现死锁；锁定粒度最小，发生锁冲突的概率最低，并发度也最高（InnoDB 存储引擎既支持行级锁也支持表级锁，但默认情况下是采用行级锁）；
- **页面锁**：开销和加锁时间界于表锁和行锁之间；会出现死锁；锁定粒度界于表锁和行锁之间，并发度一般。

> 适用：从锁的角度来说，
>
> 表级锁更适合于以**查询**为主，只有少量按索引条件更新数据的应用，如Web应用；
>
> 而行级锁则更适合于有大量按索引条件并发更新少量不同数据，同时又有并发查询的应用，如一些在线事务处理（OLTP）系统。

![1640662968976](https://tprzfbucket.oss-cn-beijing.aliyuncs.com/hadoop/202112/28/114249-509383.png)

#### MyISAM 表锁

MyISAM 的表锁有两种模式：

- **表共享读锁** （Table Read Lock）：不会阻塞其他用户对同一表的读请求，但会阻塞对同一表的写请求；
- **表独占写锁** （Table Write Lock）：会阻塞其他用户对同一表的读和写操作；

MyISAM 表的读操作与写操作之间，以及写操作之间是串行的。当一个线程获得对一个表的写锁后， 只有持有锁的线程可以对表进行更新操作。 其他线程的读、 写操作都会等待，直到锁被释放为止。

默认情况下，**写锁比读锁具有更高的优先级**：当一个锁释放时，这个锁会优先给写锁队列中等候的获取锁请求，然后再给读锁队列中等候的获取锁请求。

#### InnoDB 行锁

InnoDB 实现了以下两种类型的**行锁**：

- 共享锁（S）：允许事务读一行数据，具有锁兼容性质，允许多个事务同时获得该锁。
- 排他锁（X）：允许事务删除或更新一行数据，具有排它性，某个事务要想获得锁，必须要等待其他事务释放该对象的锁。

![1640744690235](https://tprzfbucket.oss-cn-beijing.aliyuncs.com/hadoop/202112/29/102502-433141.png)

X锁和其他锁都不兼容，S锁之和S锁兼容，S锁和X锁都是行级别锁，兼容是指对同一条记录（row）锁的兼容性情况。

 此外，innodb支持多粒度锁定，这种锁允许事务在行级别和表级别上的锁同时存在，称之为意向锁（Intention 
Lock），意向锁将锁定的对象分为多个层次，意味着事务在更细粒度上进行加锁。意向锁设计的目的主要是为了在一个事务中揭示下一行将被请求的锁类型。

实现多粒度锁机制，InnoDB 还有两种内部使用的意向锁（Intention Locks），这两种意向锁都是**表锁**：

- 意向共享锁（IS）：事务打算给数据行加行共享锁，事务在给一个数据行加共享锁前必须先取得该表的 IS 锁。（也就是说事务准备给表中的某几行添加共享锁）
- 意向排他锁（IX）：事务打算给数据行加行排他锁，事务在给一个数据行加排他锁前必须先取得该表的 IX 锁。（事务想要获得一张表中的某几行的排它锁）

**索引失效会导致行锁变表锁**。比如 vchar 查询不写单引号的情况。

##### 如何理解锁

![1640744957205](https://tprzfbucket.oss-cn-beijing.aliyuncs.com/hadoop/202112/29/102938-621205.png)

若将上锁看成如上的这颗树，那么对最下层对象的上锁，也就是最细粒度的上锁，首先需要对粗粒度进行上锁，如上图所示，如果我们需要对最底层的记录进行上X锁，那么需要对数据库，表，页上意向锁IX  Lock，最后对最底层的记录上X锁，若其中的任意一个部分导致等待，则该操作需要等待粗粒度锁的完成。

由于innodb的支持行级锁，所以意向锁不会阻塞全表扫描以外的任何请求，故表级意向锁和行级锁的兼容如下表所示：

![1640745041515](https://tprzfbucket.oss-cn-beijing.aliyuncs.com/hadoop/202112/31/090209-179585.png)

#### 加锁机制

**乐观锁与悲观锁是两种并发控制的思想，可用于解决丢失更新问题**

乐观锁会“乐观地”假定大概率不会发生并发更新冲突，访问、处理数据过程中不加锁，只在更新数据时再根据版本号或时间戳判断是否有冲突，有则处理，无则提交事务。用数据版本（Version）记录机制实现，这是乐观锁最常用的一种实现方式。

> 乐观锁的实现：
>
> 使用数据版本（Version）记录机制实现，这是乐观锁最常用的一种实现方式。何谓数据版本？即为数据增加一个版本标识，一般是通过为数据库表增加一个数字类型的 “version” 字段来实现。当读取数据时，将version字段的值一同读出，数据每更新一次，对此version值加一。当我们提交更新的时候，判断数据库表对应记录的当前版本信息与第一次取出来的version值进行比对，如果数据库表当前版本号与第一次取出来的version值相等，则予以更新，否则认为是过期数据

悲观锁会“悲观地”假定大概率会发生并发更新冲突，访问、处理数据前就加排他锁，在整个数据处理过程中锁定数据，事务提交或回滚后才释放锁。另外与乐观锁相对应的，**悲观锁是由数据库自己实现了的，要用的时候，我们直接调用数据库的相关语句就可以了。**

#### 锁模式(InnoDB有三种行锁的算法)

##### 记录锁

**记录锁(Record Locks)**： 单个行记录上的锁。对索引项加锁，锁定符合条件的行。其他事务不能修改和删除加锁项；

```java
SELECT * FROM table WHERE id = 1 FOR UPDATE;
```

它会在 id=1 的记录上加上记录锁，以阻止其他事务插入，更新，删除 id=1 这一行

在通过 主键索引 与 唯一索引 对数据行进行 UPDATE 操作时，也会对该行数据加记录锁：

```java
-- id 列为主键列或唯一索引列
UPDATE SET age = 50 WHERE id = 1;
```

##### 间隙锁

**间隙锁（Gap Locks）**： 当我们使用范围条件而不是相等条件检索数据，并请求共享或排他锁时，InnoDB会给符合条件的已有数据记录的索引项加锁。对于键值在条件范围内但并不存在的记录，叫做“间隙”。InnoDB 也会对这个“间隙”加锁，这种锁机制就是所谓的间隙锁。

对索引项之间的“间隙”加锁，锁定记录的范围（对第一条记录前的间隙或最后一条将记录后的间隙加锁），不包含索引项本身。其他事务不能在锁范围内插入数据，这样就防止了别的事务新增幻影行。

间隙锁基于非唯一索引，它锁定一段范围内的索引记录。间隙锁基于下面将会提到的`Next-Key Locking` 算法，请务必牢记：**使用间隙锁锁住的是一个区间，而不仅仅是这个区间中的每一条数据**。

```jV
SELECT * FROM table WHERE id BETWEN 1 AND 10 FOR UPDATE;
```

即所有在`（1，10）`区间内的记录行都会被锁住，所有id 为 2、3、4、5、6、7、8、9 的数据行的插入会被阻塞，但是 1 和 10 两条记录行并不会被锁住。

##### 临建锁

GAP锁的目的，**是为了防止同一事务的两次当前读，出现幻读的情况**

**临键锁(Next-key Locks)**： **临键锁**，是**记录锁与间隙锁的组合**，它的封锁范围，既包含索引记录，又包含索引区间。(临键锁的主要目的，也是为了避免**幻读**(Phantom Read)。如果把事务的隔离级别降级为RC，临键锁则也会失效。)

Next-Key 可以理解为一种特殊的**间隙锁**，也可以理解为一种特殊的**算法**。通过**临建锁**可以解决幻读的问题。 每个数据行上的非唯一索引列上都会存在一把临键锁，当某个事务持有该数据行的临键锁时，会锁住一段左开右闭区间的数据。需要强调的一点是，`InnoDB` 中行级锁是基于索引实现的，临键锁只与非唯一索引列有关，在唯一索引列（包括主键列）上不存在临键锁。

对于行的查询，都是采用该方法，主要目的是解决幻读的问题。

#### 其他实现

##### 唯一索引和主键索引的去呗？

1. 主键是一种约束，唯一索引是一种索引，两者在本质上是不同的。
2. 主键创建后一定包含一个唯一性索引，唯一性索引并不一定就是主键。
3. 唯一性索引列允许空值，而主键列不允许为空值。
4. 主键列在创建时，已经默认为空值 + 唯一索引了。
5. 主键可以被其他表引用为外键，而唯一索引不能。
6. 一个表最多只能创建一个主键，但可以创建多个唯一索引。
7. 主键更适合那些不容易更改的唯一标识，如自动递增列、身份证号等。

##### 记录锁

> 行锁在 InnoDB 中是基于`索引`实现的，所以一旦某个加锁操作没有使用索引，那么该锁就会退化为`表锁`。

顾名思义，记录锁就是为某行记录加锁，它`封锁该行的索引记录`：

```sql
-- id 列为主键列或唯一索引列
SELECT * FROM table WHERE id = 1 FOR UPDATE;　　
```

id 为 1 的记录行会被锁住。

需要注意的是：`id` 列必须为`唯一索引列`或`主键列`，否则上述语句加的锁就会变成`临键锁`。

同时查询语句必须为`精准匹配`（`=`），不能为 `>`、`<`、`like`等，否则也会退化成`临键锁`

在通过 `主键索引` 与 `唯一索引` 对数据行进行 UPDATE 操作时，也会对该行数据加`记录锁`：

```sql
`-- id 列为主键列或唯一索引列``UPDATE` `SET` `age = 50 ``WHERE` `id = 1;`
```

##### 间隙锁

> **记录锁、间隙锁、临键锁都是排它锁**
>
> 间隙锁基于`非唯一索引`，它`锁定一段范围内的索引记录`。间隙锁基于下面将会提到的`Next-Key Locking` 算法，请务必牢记：使用间隙锁锁住的是一个区间，而不仅仅是这个区间中的每一条数据。

**间隙锁是封锁索引记录中的间隔**，或者第一条索引记录之前的范围，又或者最后一条索引记录之后的范围。

**产生间隙锁的条件（RR事务隔离级别下；）：**

1. 使用普通索引锁定；
2. 使用多列唯一索引；
3. 使用唯一索引锁定多行记录。

以上情况，都会产生间隙锁，

> 对于使用**唯一索引**来搜索并给某一行记录加锁的语句，不会产生间隙锁。（这不包括搜索条件仅包括多列唯一索引的一些列的情况；在这种情况下，会产生间隙锁。）例如，如果id列具有唯一索引，则下面的语句仅对具有id值100的行使用记录锁，并不会产生间隙锁：

~~~sql
SELECT * FROM child WHERE id = 100 FOR UPDATE;
~~~

这条语句，就只会产生记录锁，不会产生间隙锁。

###### **唯一索引的间隙锁**

```sql
CREATE TABLE `test` (
  `id` int(1) NOT NULL AUTO_INCREMENT,
  `name` varchar(8) DEFAULT NULL,
  PRIMARY KEY (`id`)
) ENGINE=InnoDB DEFAULT CHARSET=utf8;

INSERT INTO `test` VALUES ('1', '小罗');
INSERT INTO `test` VALUES ('5', '小黄');
INSERT INTO `test` VALUES ('7', '小明');
INSERT INTO `test` VALUES ('11', '小红');

-- 隐藏的间隙
(-infinity, 1](1, 5](5, 7](7, 11](11, +infinity]
```

**只使用记录锁，不会产生间隙锁**

~~~sql
/* 开启事务1 */
BEGIN;
/* 查询 id = 5 的数据并加记录锁 */
SELECT * FROM `test` WHERE `id` = 5 FOR UPDATE;
/* 延迟30秒执行，防止锁释放 */
SELECT SLEEP(30);

# 注意：以下的语句不是放在一个事务中执行，而是分开多次执行，每次事务中只有一条添加语句

/* 事务2插入一条 name = '小张' 的数据 */
INSERT INTO `test` (`id`, `name`) VALUES (4, '小张'); # 正常执行

/* 事务3插入一条 name = '小张' 的数据 */
INSERT INTO `test` (`id`, `name`) VALUES (8, '小东'); # 正常执行

/* 提交事务1，释放事务1的锁 */
COMMIT;
~~~

上诉的案例，由于主键是唯一索引，而且是只使用一个索引查询，并且只锁定一条记录，所以以上的例子，只会对 id = 5 的数据加上记录锁，而不会产生间隙锁。

> 因为使用的是主键索引，并且只查询一条数据，所以使用的是行锁，没有产生间隙锁。

**产生间隙锁**

我们继续在 id 唯一索引列上做以下的测试：

~~~sql
/* 开启事务1 */
BEGIN;
/* 查询 id 在 7 - 11 范围的数据并加记录锁 */
SELECT * FROM `test` WHERE `id` BETWEEN 5 AND 7 FOR UPDATE;
/* 延迟30秒执行，防止锁释放 */
SELECT SLEEP(30);

# 注意：以下的语句不是放在一个事务中执行，而是分开多次执行，每次事务中只有一条添加语句

/* 事务2插入一条 id = 3，name = '小张1' 的数据 */
INSERT INTO `test` (`id`, `name`) VALUES (3, '小张1'); # 正常执行

/* 事务3插入一条 id = 4，name = '小白' 的数据 */
INSERT INTO `test` (`id`, `name`) VALUES (4, '小白'); # 正常执行

/* 事务4插入一条 id = 6，name = '小东' 的数据 */
INSERT INTO `test` (`id`, `name`) VALUES (6, '小东'); # 阻塞

/* 事务5插入一条 id = 8， name = '大罗' 的数据 */
INSERT INTO `test` (`id`, `name`) VALUES (8, '大罗'); # 阻塞

/* 事务6插入一条 id = 9， name = '大东' 的数据 */
INSERT INTO `test` (`id`, `name`) VALUES (9, '大东'); # 阻塞

/* 事务7插入一条 id = 11， name = '李西' 的数据 */
INSERT INTO `test` (`id`, `name`) VALUES (11, '李西'); # 阻塞

/* 事务8插入一条 id = 12， name = '张三' 的数据 */
INSERT INTO `test` (`id`, `name`) VALUES (12, '张三'); # 正常执行

/* 提交事务1，释放事务1的锁 */
COMMIT;
~~~

从上面我们可以看到，(5, 7]、(7, 11] 这两个区间，都不可插入数据，其它区间，都可以正常插入数据。所以我们可以得出结论：**当我们给 (5, 7] 这个区间加锁的时候，会锁住 (5, 7]、(7, 11] 这两个区间。**

因为我们的查询，是基于一个区间额查询，所以产生了间隙锁。

我们再来测试如果我们锁住不存在的数据时，会怎样：

~~~sql
/* 开启事务1 */
BEGIN;
/* 查询 id = 3 这一条不存在的数据并加记录锁 */
SELECT * FROM `test` WHERE `id` = 3 FOR UPDATE;
/* 延迟30秒执行，防止锁释放 */
SELECT SLEEP(30);

# 注意：以下的语句不是放在一个事务中执行，而是分开多次执行，每次事务中只有一条添加语句

/* 事务2插入一条 id = 3，name = '小张1' 的数据 */
INSERT INTO `test` (`id`, `name`) VALUES (2, '小张1'); # 阻塞

/* 事务3插入一条 id = 4，name = '小白' 的数据 */
INSERT INTO `test` (`id`, `name`) VALUES (4, '小白'); # 阻塞

/* 事务4插入一条 id = 6，name = '小东' 的数据 */
INSERT INTO `test` (`id`, `name`) VALUES (6, '小东'); # 正常执行

/* 事务5插入一条 id = 8， name = '大罗' 的数据 */
INSERT INTO `test` (`id`, `name`) VALUES (8, '大罗'); # 正常执行

/* 提交事务1，释放事务1的锁 */
COMMIT;
~~~

我们可以看出，指定查询某一条记录时，如果这条记录不存在，会产生间隙锁。

**结论**

1. 对于指定查询某一条记录的加锁语句，**如果该记录不存在，会产生记录锁和间隙锁，如果记录存在，则只会产生记录锁**，如：WHERE `id` = 5 FOR UPDATE;
2. 对于查找某一范围内的查询语句，会产生间隙锁，如：WHERE `id` BETWEEN 5 AND 7 FOR UPDATE;

###### **普通索引的间隙锁**

1. 在普通索引列上，**不管是何种查询，只要加锁，都会产生间隙锁，这跟唯一索引不一样；**
2. 在普通索引跟唯一索引中，数据间隙的分析，数据行是优先根据普通索引排序，再根据唯一索引排序。

##### **临键锁(Next-key Locks)**

**临键锁**，是**记录锁与间隙锁的组合**，它的封锁范围，既包含索引记录，又包含索引区间。

> **注：**临键锁的主要目的，也是为了避免**幻读**(Phantom Read)。如果把事务的隔离级别降级为RC，临键锁则也会失效。

##### 小结

1. 记录锁、间隙锁、临键锁，都属于排它锁；
2. **记录锁就是锁住一行记录**；
3. 间隙锁只有在事务隔离级别 RR 中才会产生；
4. **唯一索引只有锁住多条记录或者一条不存在的记录的时候，才会产生间隙锁**，指定给某条存在的记录加锁的时候，只会加记录锁，不会产生间隙锁；
5. **普通索引不管是锁住单条，还是多条记录，都会产生间隙锁**； 
6. **间隙锁会封锁该条记录相邻两个键之间的空白区域**，防止其它事务在这个区域内插入、修改、删除数据，这是为了防止出现 幻读 现象；
7. 普通索引的间隙，优先以普通索引排序，然后再根据主键索引排序（多普通索引情况还未研究）；
8. 事务级别是RC（读已提交）级别的话，间隙锁将会失效。

> 1. InnoDB 中的`行锁`的实现依赖于`索引`，一旦某个加锁操作没有使用到索引，那么该锁就会退化为`表锁`。
> 2. 记录锁存在于包括`主键索引`在内的`唯一索引`中，锁定单条索引记录。
> 3. 间隙锁存在于`非唯一索引`中，锁定`开区间`范围内的一段间隔，它是基于临键锁实现的。
> 4. 临键锁存在于`非唯一索引`中，该类型的每条记录的索引上都存在这种锁，它是一种特殊的间隙锁，锁定一段`左开右闭`的索引区间。

> select for update有什么含义，会锁表还是锁行还是其他

for update 仅适用于InnoDB，且必须在事务块(BEGIN/COMMIT)中才能生效。在进行事务操作时，通过“for update”语句，MySQL会对查询结果集中每行数据都添加排他锁，其他线程对该记录的更新与删除操作都会阻塞。排他锁包含行锁、表锁。

InnoDB这种行锁实现特点意味着：只有通过索引条件检索数据，InnoDB才使用行级锁，否则，InnoDB将使用表锁！ 假设有个表单 products ，里面有id跟name二个栏位，id是主键。

- 明确指定主键，并且有此笔资料，row lock

```
SELECT * FROM products WHERE id='3' FOR UPDATE;
SELECT * FROM products WHERE id='3' and type=1 FOR UPDATE;
```

- 明确指定主键，若查无此笔资料，无lock

```
SELECT * FROM products WHERE id='-1' FOR UPDATE;
```

- 无主键，table lock

```
SELECT * FROM products WHERE name='Mouse' FOR UPDATE;
```

- 主键不明确，table lock

```
SELECT * FROM products WHERE id<>'3' FOR UPDATE;
```

- 主键不明确，table lock

```
SELECT * FROM products WHERE id LIKE '3' FOR UPDATE;
```

**注1**: FOR UPDATE仅适用于InnoDB，且必须在交易区块(BEGIN/COMMIT)中才能生效。
**注2**: 要测试锁定的状况，可以利用MySQL的Command Mode ，开二个视窗来做测试。

> MySQL 遇到过死锁问题吗，你是如何解决的？

#### 死锁

##### **死锁产生**：

- 死锁是指两个或多个事务在同一资源上相互占用，并请求锁定对方占用的资源，从而导致恶性循环
- 当事务试图以不同的顺序锁定资源时，就可能产生死锁。多个事务同时锁定同一个资源时也可能会产生死锁
- 锁的行为和顺序和存储引擎相关。以同样的顺序执行语句，有些存储引擎会产生死锁有些不会——死锁有双重原因：真正的数据冲突；存储引擎的实现方式。

**检测死锁**：数据库系统实现了各种死锁检测和死锁超时的机制。**InnoDB存储引擎能检测到死锁的循环依赖并立即返回一个错误。**

**死锁恢复**：死锁发生以后，只有部分或完全回滚其中一个事务，才能打破死锁，InnoDB目前处理死锁的方法是，将持有最少行级排他锁的事务进行回滚。所以事务型应用程序在设计时必须考虑如何处理死锁，多数情况下只需要重新执行因死锁回滚的事务即可。

**外部锁的死锁检测**：发生死锁后，InnoDB 一般都能自动检测到，并使一个事务释放锁并回退，另一个事务获得锁，继续完成事务。但在涉及外部锁，或涉及表锁的情况下，InnoDB 并不能完全自动检测到死锁， **这需要通过设置锁等待超时参数 innodb_lock_wait_timeout 来解决**

**死锁影响性能**：死锁会影响性能而不是会产生严重错误，因为InnoDB会自动检测死锁状况并回滚其中一个受影响的事务。在高并发系统上，当许多线程等待同一个锁时，死锁检测可能导致速度变慢。 有时当发生死锁时，禁用死锁检测（使用innodb_deadlock_detect配置选项）可能会更有效，这时可以依赖`innodb_lock_wait_timeout`设置进行事务回滚。

##### **MyISAM避免死锁**：

- **在自动加锁的情况下，MyISAM 总是一次获得 SQL 语句所需要的全部锁，所以 MyISAM 表不会出现死锁。**

##### **InnoDB避免死锁**：

- 为了在单个InnoDB表上执行多个并发写入操作时避免死锁，可以在事务开始时通过为预期要修改的每个元祖（行）使用`SELECT ... FOR UPDATE`语句来获取必要的锁，即使这些行的更改语句是在之后才执行的。
- 在事务中，如果要更新记录，应该直接申请足够级别的锁，即排他锁，而不应先申请共享锁、更新时再申请排他锁，因为这时候当用户再申请排他锁时，其他事务可能又已经获得了相同记录的共享锁，从而造成锁冲突，甚至死锁
- 如果事务需要修改或锁定多个表，则应在每个事务中以相同的顺序使用加锁语句。 在应用中，如果不同的程序会并发存取多个表，应尽量约定以相同的顺序来访问表，这样可以大大降低产生死锁的机会
- 通过`SELECT ... LOCK IN SHARE MODE`获取行的读锁后，如果当前事务再需要对该记录进行更新操作，则很有可能造成死锁。
- 改变事务隔离级别

如果出现死锁，可以用 `show engine innodb status;`命令来确定最后一个死锁产生的原因。返回结果中包括死锁相关事务的详细信息，如引发死锁的 SQL 语句，事务已经获得的锁，正在等待什么锁，以及被回滚的事务等。据此可以分析死锁产生的原因和改进措施。

#### 数据库锁与隔离级别的关系

![1631760422588](https://tprzfbucket.oss-cn-beijing.aliyuncs.com/hadoop/202109/16/104705-556986.png)

#### 数据库锁类型有哪些？

按照锁的粒度可以将MySQL锁分为三种： 

![1631760479883](https://tprzfbucket.oss-cn-beijing.aliyuncs.com/hadoop/202109/16/104802-550350.png)

MyISAM默认采用**表级锁**，InnoDB默认采用**行级锁**。

#### 什么是数据库的乐观锁和悲观锁，如何实现？ 

- 乐观锁：系统假设数据的更新在大多数时候是不会产生冲突的，所以数据库只在更新操作提交的时候对数据检测冲突，如果存在冲突，则数据更新失败。
  - 乐观锁实现方式：一般通过版本号和CAS算法实现。
- 悲观锁：假定会发生并发冲突，屏蔽一切可能违反数据完整性的操作。通俗讲就是每次去拿数据的时候都认为别人会修改，所以每次在拿数据的时候都会上锁。
  - 悲观锁的实现方式：通过数据库的锁机制实现，对查询语句添加for updata。 

#### 什么是死锁？如何避免？ 

死锁是指两个或者两个以上进程在执行过程中，由于竞争资源或者由于彼此通信而造成的一种阻塞的现象。在MySQL中，MyISAM是一次获得所需的全部锁，要么全部满足，要么等待，所以不会出现死锁。在InnoDB存储引擎中，除了单个SQL组成的事务外，锁都是逐步获得的，所以存在死锁问题。

如何避免MySQL发生死锁或锁冲突： 

- 如果不同的程序并发存取多个表，尽量以相同的顺序访问表。
- 在程序以批量方式处理数据的时候，如果已经对数据排序，尽量保证每个线程按照固定的顺序来处理记录。 
- 在事务中，如果需要更新记录，应直接申请足够级别的排他锁，而不应该先申请共享锁，更新时在申请排他锁，因为在当前用户申请排他锁时，其他事务可能已经获得了相同记录的共享锁，从而造成锁冲突或者死锁。 
- 尽量使用较低的隔离级别。
- 尽量使用索引访问数据，使加锁更加准确，从而减少锁冲突的机会
- 合理选择事务的大小，小事务发生锁冲突的概率更低
- 尽量用相等的条件访问数据，可以避免Next-Key锁对并发插入的影响。
- 不要申请超过实际需要的锁级别，查询时尽量不要显示加锁
- 对于一些特定的事务，可以表锁来提高处理速度或减少死锁的概率。 

### Sql基础

#### SQL语句主要分为哪几类 

1. 数据据定义语言DDL（Data Definition Language）：主要有CREATE，DROP，ALTER等对逻辑结构有操作的，包括表结构、视图和索引。
2. 数据库查询语言DQL（Data Query Language）：主要以SELECT为主
3. 数据操纵语言DML（Data Manipulation Language）：主要包括INSERT，UPDATE，DELETE
4. 数据控制功能DCL（Data Control Language）：主要是权限控制能操作，包括GRANT，REVOKE，COMMIT，ROLLBACK等。 

#### SQL约束有哪些

- 主键约束：主键为在表中存在一列或者多列的组合，能唯一标识表中的每一行。一个表只有一个主键，并且主键约束的列不能为空。
- 外键约束：外键约束是指用于在两个表之间建立关系，需要指定引用主表的哪一列。只有主表的主键可以被从表用作外键，被约束的从表的列可以不是主键，所以创建外键约束需要先定义主表的主键，然后定义从表的外键。
- 唯一约束：确保表中的一列数据没有相同的值，一个表可以定义多个唯一约束。
- 默认约束：在插入新数据时，如果该行没有指定数据，系统将默认值赋给该行，如果没有设置没默认值，则为NULL。
- Check约束：Check会通过逻辑表达式来判断数据的有效性，用来限制输入一列或者多列的值的范围。在列更新数据时，输入的内容必须满足Check约束的条件 

#### 什么是子查询

子查询：把一个查询的结果在另一个查询中使用。

子查询可以分为以下几类： 

- 标量子查询：指子查询返回的是一个值，可以使用 =,>,<,>=,<=,<>等操作符对子查询标量结果进行比较，一般子查询会放在比较式的右侧。 

```sql
SELECT * FROM user WHERE age = (SELECT max(age) from user) //查询年纪最大的人
```

- 列子查询：指子查询的结果是n行一列，一般应用于对表的某个字段进行查询返回。可以使用IN、ANY、SOME和ALL等操作符，不能直接使用 

```sql 
SELECT num1 FROM table1 WHERE num1 > ANY (SELECT num2 FROM table2)
```

- 行子查询：指子查询返回的结果一行n列 

```sql 
SELECT * FROM user WHERE (age,sex) = (SELECT age,sex FROM user WHERE name="zhangsan")
```

- 表子查询：指子查询是n行n列的一个数据表 

```sql
SELECT * FROM student WHERE (name,age,sex) IN (SELECT name,age,sex FROM class1) --在学生表中找到班级在1班的学生
```

#### 了解MySQL的几种连接查询吗？ 

MySQl的连接查询主要可以分为外连接，内连接，交叉连接 

**外连接**

- 外连接主要分为左外连接(LEFT JOIN)、右外连接(RIGHT JOIN)、全外连接。
- 左外连接：显示左表中所有的数据及右表中符合条件的数据，右表中不符合条件的数据为null。 

![1631770721000](https://tprzfbucket.oss-cn-beijing.aliyuncs.com/hadoop/202109/16/133844-129480.png)

- 右外连接：显示左表中所有的数据及右表中符合条件的数据，右表中不符合条件的数据为null。

![1631770758813](https://tprzfbucket.oss-cn-beijing.aliyuncs.com/hadoop/202109/16/133921-621905.png)

> MySQL中不支持全外连接。 

- 内连接：只显示符合条件的数据 

![1631770802566](https://tprzfbucket.oss-cn-beijing.aliyuncs.com/hadoop/202109/16/134004-950015.png)

- 交叉连接：使用笛卡尔积的一种连接。

  笛卡尔积，百度百科的解释：两个集合X和Y的笛卡尔积表示为X × Y，第一个对象是X的成员而第二个对象是Y的所有可能有序对的其中一个成员 。例如：`A={a,b}，B={0,1,2}，A × B = {(a,0)，(a,1)，(a,2)，(b,0)，(b,1)，(b,2)} `

**举例如下：有两张表分为L表和R表。 **

![1631770886115](https://tprzfbucket.oss-cn-beijing.aliyuncs.com/hadoop/202109/16/134129-364648.png)

左外连接 ： select L.`*`,R.`*` from L left join R on L.b=R.b 

![1631770941267](https://tprzfbucket.oss-cn-beijing.aliyuncs.com/hadoop/202109/16/134237-74660.png)

右外连接： select L.`*`,R.`*` from L right join R on L.b=R.b 

![1631770987482](https://tprzfbucket.oss-cn-beijing.aliyuncs.com/hadoop/202109/16/134309-60073.png)

内连接： select L.`*`,R.`*` from L inner join R on L.b=R.b 

![1631771057312](https://tprzfbucket.oss-cn-beijing.aliyuncs.com/hadoop/202109/16/134420-270738.png)

交叉连接： select L.`*`,R.`*` from L,R 

![1631771090537](https://tprzfbucket.oss-cn-beijing.aliyuncs.com/hadoop/202109/16/134453-312816.png)

#### mysql中in和exists的区别？ 

in和exists一般用于子查询。

- 使用exists时会先进行外表查询，将查询到的每行数据带入到内表查询中看是否满足条件；使用in一般会先进行内表查询获取结果集，然后对外表查询匹配结果集，返回数据。
- in在内表查询或者外表查询过程中都会用到索引。
- exists仅在内表查询时会用到索引
- 一般来说，当子查询的结果集比较大，外表较小使用exist效率更高；当子查询寻得结果集较小，外表较大时，使用in效率更高。
- 对于not in和not exists，not exists效率比not in的效率高，与子查询的结果集无关，因为not in对于内外表都进行了全表扫描，没有使用到索引。not exists的子查询中可以用到表上的索引。 

#### varchar和char的区别？ 

- varchar表示变长，char表示长度固定。当所插入的字符超过他们的长度时，在严格模式下，会拒绝插入并提示错误信息，在一般模式下，会截取后插入。如char(5)，无论插入的字符长度是多少，长度都是5，插入字符长度小于5，则用空格补充。对于varchar(5)，如果插入的字符长度小于5，则存储的字符长度就是插入字符的长度，不会填充。 
- 存储容量不同，对于char来说，最多能存放的字符个数为255。对于varchar，最多能存放的字符个数是65532。
- 存储速度不同，char长度固定，存储速度会比varchar快一些，但在空间上会占用额外的空间，属于一种空间换时间的策略。而varchar空间利用率会高些，但存储速度慢，属于一种时间换空间的策略。 

#### MySQL中int(10)和char(10)和varchar(10)的区别？ 

int(10)中的10表示的是显示数据的长度，而char(10)和varchar(10)表示的是存储数据的大小。 

#### drop、delete和truncate的区别？  

![1631771405632](https://tprzfbucket.oss-cn-beijing.aliyuncs.com/hadoop/202109/16/135008-639495.png)

> 一般来讲，删除整个表，使用drop，删除表的部分数据使用delete，保留表结构删除表的全部数据使用truncate 

#### UNION和UNION ALL的区别？ 

union和union all的作用都是将两个结果集合并到一起。

- union会对结果去重并排序，union all直接直接返回合并后的结果，不去重也不进行排序。
- union all的性能比union性能好。 

#### 什么是临时表，什么时候会使用到临时表，什么时候删除临时表？ 

MySQL在执行SQL语句的时候会临时创建一些存储中间结果集的表，这种表被称为临时表，临时表只对当前连接可见，在连接关闭后，临时表会被删除并释放空间。

临时表主要分为内存临时表和磁盘临时表两种。内存临时表使用的是MEMORY存储引擎，磁盘临时表使用的是MyISAM存储引擎。

一般在以下几种情况中会使用到临时表：

1. FROM中的子查询
2. DISTINCT查询并加上ORDER BY
3. ORDER BY和GROUP BY的子句不一样时会产生临时表
4. 使用UNION查询会产生临时表 

#### 大表数据查询如何进行优化？ 

1. 索引优化
2. SQL语句优化
3. 水平拆分
4. 垂直拆分
5. 建立中间表 
6. 使用缓存技术
7. 固定长度的表访问起来更快
8. 越小的列访问越快 

#### 了解慢日志查询吗？统计过慢查询吗？对慢查询如何优化？ 

慢查询一般用于记录执行时间超过某个临界值的SQL语句的日志。

**相关参数：**

- slow_query_log：是否开启慢日志查询，1表示开启，0表示关闭。
- slow_query_log_file：MySQL数据库慢查询日志存储路径。
- long_query_time：慢查询阈值，当SQL语句查询时间大于阈值，会被记录在日志上。
- log_queries_not_using_indexes：未使用索引的查询会被记录到慢查询日志中。
- log_output：日志存储方式。“FILE”表示将日志存入文件。“TABLE”表示将日志存入数据库。

**如何对慢查询进行优化？**

- 分析语句的执行计划，查看SQL语句的索引是否命中
- 优化数据库的结构，将字段很多的表分解成多个表，或者考虑建立中间表。
- 优化LIMIT分页。 

#### 为什么要设置主键？

主键是唯一区分表中每一行的唯一标识，如果没有主键，更新或者删除表中特定的行会很困难，因为不能唯一准确地标识某一行。 

##### 主键一般用自增ID还是UUID？ 

**使用自增ID的好处：**

1. 字段长度较uuid会小很多。
2. 数据库自动编号，按顺序存放，利于检索
3. 无需担心主键重复问题 

**使用自增ID的缺点：**

1. 因为是自增，在某些业务场景下，容易被其他人查到业务量。
2. 发生数据迁移时，或者表合并时会非常麻烦
3. 在高并发的场景下，竞争自增锁会降低数据库的吞吐能力 

UUID：通用唯一标识码，UUID是基于当前时间、计数器和硬件标识等数据计算生成的。

**使用UUID的优点：**

1. 唯一标识，不会考虑重复问题，在数据拆分、合并时也能达到全局的唯一性。
2. 可以在应用层生成，提高数据库的吞吐能力。
3. 无需担心业务量泄露的问题。

**使用UUID的缺点：**

1. 因为UUID是随机生成的，所以会发生随机IO，影响插入速度，并且会造成硬盘的使用率较低。
2. UUID占用空间较大，建立的索引越多，造成的影响越大。
3. UUID之间比较大小较自增ID慢不少，影响查询速度。 

最后说下结论，一般情况MySQL推荐使用自增ID。因为在MySQL的InnoDB存储引擎中，主键索引是一种聚簇索引，主键索引的B+树的叶子节点按照顺

序存储了主键值及数据，如果主键索引是自增ID，只需要按顺序往后排列即可，如果是UUID，ID是随机生成的，在数据插入时会造成大量的数据移动，产生大量的内存碎片，造成插入性能的下降。 

#### 字段为什么要设置成not null? 

首先说一点，NULL和空值是不一样的，空值是不占用空间的，而NULL是占用空间的，所以字段设为NOT NULL后仍然可以插入空值。

字段设置成not null主要有以下几点原因： 

1. NULL值会影响一些函数的统计，如count，遇到NULL值，这条记录不会统计在内。 
2. B树不存储NULL，所以索引用不到NULL，会造成第一点中说的统计不到的问题 
3. NOT IN子查询在有NULL值的情况下返回的结果都是空值。 

例如user表如下 ：

![1631772205116](https://tprzfbucket.oss-cn-beijing.aliyuncs.com/hadoop/202109/16/140348-975886.png)

```sql
select * from `user` where username NOT IN (select username from `user` where id != 0) ，
--这条查询语句应该查到zhangsan这条数据，但是结果显示为null。
```

MySQL在进行比较的时候，NULL会参与字段的比较，因为NULL是一种比较特殊的数据类型，数据库在处理时需要进行特数处理，增加了数据库处理记录的复杂性。 

#### 如何优化查询过程中的数据访问？ 

从减少数据访问方面考虑：

- 正确使用索引，尽量做到索引覆盖
- 优化SQL执行计划

从返回更少的数据方面考虑：

- 数据分页处理
- 只返回需要的字段

从减少服务器CPU开销方面考虑：

- 合理使用排序
- 减少比较的操作
- 复杂运算在客户端处理

从增加资源方面考虑：

- 客户端多进程并行访问
- 数据库并行处理 

#### 如何优化长难的查询语句？ 

- 将一个大的查询分解为多个小的查询
- 分解关联查询，使缓存的效率更高 

#### 如何优化LIMIT分页？ 

- 在LIMIT偏移量较大的时候，查询效率会变低，可以记录每次取出的最大ID，下次查询时可以利用ID进行查询
- 建立复合索引 

#### 如何优化UNION查询 

- 如果不需要对结果集进行去重或者排序建议使用UNION ALL，会好一些。 

#### 如何优化WHERE子句 

1. 不要在where子句中使用!=和<>进行不等于判断，这样会导致放弃索引进行全表扫描。
2. 不要在where子句中使用null或空值判断，尽量设置字段为not null。
3. 尽量使用union all代替or
4. 在where和order by涉及的列建立索引
5. 尽量减少使用in或者not in，会进行全表扫描
6. 在where子句中使用参数会导致全表扫描
7. 避免在where子句中对字段及进行表达式或者函数操作会导致存储引擎放弃索引进而全表扫描 

#### SQL语句执行的很慢原因是什么？ 

1. 如果SQL语句只是偶尔执行很慢，可能是执行的时候遇到了锁，也可能是redo log日志写满了，要将redo log中的数据同步到磁盘中去。
2. 如果SQL语句一直都很慢，可能是字段上没有索引或者字段有索引但是没用上索引。 

#### SQL语句的执行顺序?  

```sql
SELECT DISTINCT
	select_list
FROM
	left_table
LEFT JOIN
	right_table ON join_condition
WHERE
	where_condition
GROUP BY
	group_by_list
HAVING
	having_condition
ORDER BY
	order_by_condition
```

执行顺序如下：

![1631772654483](https://tprzfbucket.oss-cn-beijing.aliyuncs.com/hadoop/202109/16/141057-986872.png)

1. FROM：对SQL语句执行查询时，首先对关键字两边的表以笛卡尔积的形式执行连接，并产生一个虚表V1。虚表就是视图，数据会来自多张表的执行结果。
2. ON：对FROM连接的结果进行ON过滤,并创建虚表V2
3. JOIN：将ON过滤后的左表添加进来，并创建新的虚拟表V3
4. WHERE：对虚拟表V3进行WHERE筛选，创建虚拟表V4
5. GROUP BY：对V4中的记录进行分组操作，创建虚拟表V5
6. HAVING：对V5进行过滤，创建虚拟表V6
7. SELECT：将V6中的结果按照SELECT进行筛选，创建虚拟表V7
8. DISTINCT：对V7表中的结果进行去重操作，创建虚拟表V8，如果使用了GROUP BY子句则无需使用DISTINCT，因为分组的时候是将列中唯一的值分成一组，并且每组只返回一行记录，所以所有的记录都h是不同的。
9. ORDER BY：对V8表中的结果进行排序。 

### Mysql调优

> 日常工作中你是怎么优化SQL的？
>
> SQL优化的一般步骤是什么，怎么看执行计划（explain），如何理解其中各个字段的含义？
>
> 如何写sql能够有效的使用到复合索引？
>
> 一条sql执行过长的时间，你如何优化，从哪些方面入手？
>
> 什么是最左前缀原则？什么是最左匹配原则？

#### MySQL常见性能分析手段

在优化MySQL时，通常需要对数据库进行分析，常见的分析手段有**慢查询日志**，**EXPLAIN 分析查询**，**profiling分析**以及**show命令查询系统状态及系统变量**，通过定位分析性能的瓶颈，才能更好的优化数据库系统的性能。

##### 性能瓶颈定位

我们可以通过 show 命令查看 MySQL 状态及变量，找到系统的瓶颈：

```sql
Mysql> show status ——显示状态信息（扩展show status like ‘XXX’）

Mysql> show variables ——显示系统变量（扩展show variables like ‘XXX’）

Mysql> show innodb status ——显示InnoDB存储引擎的状态

Mysql> show processlist ——查看当前SQL执行，包括执行状态、是否锁表等

Shell> mysqladmin variables -u username -p password——显示系统变量

Shell> mysqladmin extended-status -u username -p password——显示状态信息
```

##### Explain(执行计划)

是什么：使用 **Explain** 关键字可以模拟优化器执行SQL查询语句，从而知道 MySQL 是如何处理你的 SQL 语句的。分析你的查询语句或是表结构的性能瓶颈。

能干吗：

- 表的读取顺序
- 数据读取操作的操作类型
- 哪些索引可以使用
- 哪些索引被实际使用
- 表之间的引用
- 每张表有多少行被优化器查询

怎么玩：

- Explain + SQL语句
- 执行计划包含的信息（如果有分区表的话还会有**partitions**）

![1640691497772](https://tprzfbucket.oss-cn-beijing.aliyuncs.com/hadoop/202112/28/193819-745225.png)

各字段解释

- **id**（select 查询的序列号，包含一组数字，表示查询中执行select子句或操作表的顺序）

  - id相同，执行顺序从上往下
  - id全不同，如果是子查询，id的序号会递增，id值越大优先级越高，越先被执行
  - id部分相同，执行顺序是先按照数字大的先执行，然后数字相同的按照从上往下的顺序执行

-  **select_type**（查询类型，用于区别普通查询、联合查询、子查询等复杂查询）

  - **SIMPLE** ：简单的select查询，查询中不包含子查询或UNION
  - **PRIMARY**：查询中若包含任何复杂的子部分，最外层查询被标记为PRIMARY
  - **SUBQUERY**：在select或where列表中包含了子查询
  - **DERIVED**：在from列表中包含的子查询被标记为DERIVED，MySQL会递归执行这些子查询，把结果放在临时表里
  - **UNION**：若第二个select出现在UNION之后，则被标记为UNION，若UNION包含在from子句的子查询中，外层select将被标记为DERIVED
  - **UNION RESULT**：从UNION表获取结果的select

-  **table**（显示这一行的数据是关于哪张表的）

-  **type**（显示查询使用了那种类型，从最好到最差依次排列	**system > const > eq_ref > ref > fulltext > ref_or_null > index_merge > unique_subquery > index_subquery > range > index > ALL** ）

  - system：表只有一行记录（等于系统表），是 const 类型的特例，平时不会出现
  - const：表示通过索引一次就找到了，const 用于比较 primary key 或 unique 索引，因为只要匹配一行数据，所以很快，如将主键置于 where 列表中，mysql 就能将该查询转换为一个常量
  - eq_ref：唯一性索引扫描，对于每个索引键，表中只有一条记录与之匹配，常见于主键或唯一索引扫描
  - ref：非唯一性索引扫描，范围匹配某个单独值得所有行。本质上也是一种索引访问，他返回所有匹配某个单独值的行，然而，它可能也会找到多个符合条件的行，多以他应该属于查找和扫描的混合体
  - range：只检索给定范围的行，使用一个索引来选择行。key列显示使用了哪个索引，一般就是在你的where语句中出现了between、<、>、in等的查询，这种范围扫描索引比全表扫描要好，因为它只需开始于索引的某一点，而结束于另一点，不用扫描全部索引
  - index：Full Index Scan，index于ALL区别为index类型只遍历索引树。通常比ALL快，因为索引文件通常比数据文件小。（**也就是说虽然all和index都是读全表，但index是从索引中读取的，而all是从硬盘中读的**）
  - ALL：Full Table Scan，将遍历全表找到匹配的行

  tip: 一般来说，得保证查询至少达到range级别，最好到达ref

-  **possible_keys**（显示可能应用在这张表中的索引，一个或多个，查询涉及到的字段若存在索引，则该索引将被列出，但不一定被查询实际使用）

-  **key**

  - 实际使用的索引，如果为NULL，则没有使用索引
  - **查询中若使用了覆盖索引，则该索引和查询的 select 字段重叠，仅出现在key列表中**

![1640691629913](https://tprzfbucket.oss-cn-beijing.aliyuncs.com/hadoop/202112/28/194030-23573.png)

**key_len**

- 表示索引中使用的字节数，可通过该列计算查询中使用的索引的长度。在不损失精确性的情况下，长度越短越好
- key_len显示的值为索引字段的最大可能长度，并非实际使用长度，即key_len是根据表定义计算而得，不是通过表内检索出的

 **ref** （显示索引的哪一列被使用了，如果可能的话，是一个常数。哪些列或常量被用于查找索引列上的值）

 **rows** （根据表统计信息及索引选用情况，大致估算找到所需的记录所需要读取的行数）

 **Extra**（包含不适合在其他列中显示但十分重要的额外信息）

1. using filesort: 说明mysql会对数据使用一个外部的索引排序，不是按照表内的索引顺序进行读取。mysql中无法利用索引完成的排序操作称为“文件排序”。常见于order by和group by语句中
2. Using temporary：使用了临时表保存中间结果，mysql在对查询结果排序时使用临时表。常见于排序order by和分组查询group by。
3. using index：表示相应的select操作中使用了覆盖索引，避免访问了表的数据行，效率不错，如果同时出现using where，表明索引被用来执行索引键值的查找；否则索引被用来读取数据而非执行查找操作
4. using where：使用了where过滤
5. using join buffer：使用了连接缓存
6. impossible where：where子句的值总是false，不能用来获取任何元祖
7. select tables optimized away：在没有group by子句的情况下，基于索引优化操作或对于MyISAM存储引擎优化COUNT(*)操作，不必等到执行阶段再进行计算，查询执行计划生成的阶段即完成优化
8. distinct：优化distinct操作，在找到第一匹配的元祖后即停止找同样值的动作

![1640691675620](https://tprzfbucket.oss-cn-beijing.aliyuncs.com/hadoop/202112/28/194116-415929.png)

第一行（执行顺序4）：id列为1，表示是union里的第一个select，select_type列的primary表示该查询为外层查询，table列被标记为，表示查询结果来自一个衍生表，其中derived3中3代表该查询衍生自第三个select查询，即id为3的select。【select d1.name......】

第二行（执行顺序2）：id为3，是整个查询中第三个select的一部分。因查询包含在from中，所以为derived。【select id,name from t1 where other_column=''】

第三行（执行顺序3）：select列表中的子查询select_type为subquery，为整个查询中的第二个select。【select id from t3】

第四行（执行顺序1）：select_type为union，说明第四个select是union里的第二个select，最先执行【select name,id from t2】

第五行（执行顺序5）：代表从union的临时表中读取行的阶段，table列的<union1,4>表示用第一个和第四个select的结果进行union操作。【两个结果union操作】

##### 慢查询日志

MySQL 的慢查询日志是 MySQL 提供的一种日志记录，它用来记录在 MySQL 中响应时间超过阈值的语句，具体指运行时间超过 `long_query_time` 值的 SQL，则会被记录到慢查询日志中。

- `long_query_time` 的默认值为10，意思是运行10秒以上的语句
- 默认情况下，MySQL数据库没有开启慢查询日志，需要手动设置参数开启

**查看开启状态**

```
SHOW VARIABLES LIKE '%slow_query_log%'
```

**开启慢查询日志**

- 临时配置：

```sql
mysql> set global slow_query_log='ON';
mysql> set global slow_query_log_file='/var/lib/mysql/hostname-slow.log';
mysql> set global long_query_time=2;
复制代码
```

​	也可set文件位置，系统会默认给一个缺省文件host_name-slow.log

​	使用set操作开启慢查询日志只对当前数据库生效，如果MySQL重启则会失效。

- 永久配置

  修改配置文件my.cnf或my.ini，在[mysqld]一行下面加入两个配置参数

```
[mysqld]
slow_query_log = ON
slow_query_log_file = /var/lib/mysql/hostname-slow.log
long_query_time = 3
复制代码
```

注：log-slow-queries 参数为慢查询日志存放的位置，一般这个目录要有 MySQL 的运行帐号的可写权限，一般都将这个目录设置为 MySQL 的数据存放目录；long_query_time=2 中的 2 表示查询超过两秒才记录；在my.cnf或者 my.ini 中添加 log-queries-not-using-indexes 参数，表示记录下没有使用索引的查询。

可以用 `select sleep(4)` 验证是否成功开启。

在生产环境中，如果手工分析日志，查找、分析SQL，还是比较费劲的，所以MySQL提供了日志分析工具**mysqldumpslow**。

通过 mysqldumpslow --help 查看操作帮助信息

- 得到返回记录集最多的10个SQL

  `mysqldumpslow -s r -t 10 /var/lib/mysql/hostname-slow.log`

- 得到访问次数最多的10个SQL

  `mysqldumpslow -s c -t 10 /var/lib/mysql/hostname-slow.log`

- 得到按照时间排序的前10条里面含有左连接的查询语句

  `mysqldumpslow -s t -t 10 -g "left join" /var/lib/mysql/hostname-slow.log`

- 也可以和管道配合使用

  `mysqldumpslow -s r -t 10 /var/lib/mysql/hostname-slow.log | more`

**也可使用 pt-query-digest 分析 RDS MySQL 慢查询日志**

##### Show Profile 分析查询

通过慢日志查询可以知道哪些 SQL 语句执行效率低下，通过 explain 我们可以得知 SQL 语句的具体执行情况，索引使用等，还可以结合`Show Profile`命令查看执行状态。

- Show Profile 是 MySQL 提供可以用来分析当前会话中语句执行的资源消耗情况。可以用于SQL的调优的测量

- 默认情况下，参数处于关闭状态，并保存最近15次的运行结果

- 分析步骤

  1. 是否支持，看看当前的mysql版本是否支持

     ```sql
     mysql>Show  variables like 'profiling';  --默认是关闭，使用前需要开启
     ```

  2. 开启功能，默认是关闭，使用前需要开启

     ```sql
     mysql>set profiling=1;  
     ```

  3. 运行SQL

  4. 查看结果

  ![1640691837512](https://tprzfbucket.oss-cn-beijing.aliyuncs.com/hadoop/202112/28/194358-844106.png)

  5. 诊断SQL，show profile cpu,block io for query  id(上一步前面的问题SQL数字号码)

  6. 日常开发需要注意的结论

  - converting HEAP to MyISAM 查询结果太大，内存都不够用了往磁盘上搬了。
  - create tmp table 创建临时表，这个要注意
  - Copying to tmp table on disk   把内存临时表复制到磁盘
  - locked

> 查询中哪些情况不会使用索引？

### 性能优化

#### 索引优化

1. 全值匹配我最爱
2. 最佳左前缀法则，比如建立了一个联合索引(a,b,c)，那么其实我们可利用的索引就有(a), (a,b), (a,b,c)
3. 不在索引列上做任何操作（计算、函数、(自动or手动)类型转换），会导致索引失效而转向全表扫描
4. 存储引擎不能使用索引中范围条件右边的列
5. 尽量使用覆盖索引(只访问索引的查询(索引列和查询列一致))，减少select
6. is null ,is not null 也无法使用索引
7. like "xxxx%" 是可以用到索引的，like "%xxxx" 则不行(like "%xxx%" 同理)。like以通配符开头('%abc...')索引失效会变成全表扫描的操作，
8. 字符串不加单引号索引失效
9. 少用or，用它来连接时会索引失效
10. <，<=，=，>，>=，BETWEEN，IN 可用到索引，<>，not in ，!= 则不行，会导致全表扫描

**一般性建议**

- 对于单键索引，尽量选择针对当前query过滤性更好的索引
- 在选择组合索引的时候，当前Query中过滤性最好的字段在索引字段顺序中，位置越靠前越好。
- 在选择组合索引的时候，尽量选择可以能够包含当前query中的where字句中更多字段的索引
- 尽可能通过分析统计信息和调整query的写法来达到选择合适索引的目的
- 少用Hint强制索引

#### 查询优化

**永远小标驱动大表（小的数据集驱动大的数据集）**

```
slect * from A where id in (select id from B)`等价于
#等价于
select id from B
select * from A where A.id=B.id
```

当 B 表的数据集必须小于 A 表的数据集时，用 in 优于 exists

```
select * from A where exists (select 1 from B where B.id=A.id)
#等价于
select * from A
select * from B where B.id = A.id`
```

当 A 表的数据集小于B表的数据集时，用 exists优于用 in

注意：A表与B表的ID字段应建立索引。

**order by关键字优化**

- order by子句，尽量使用 Index 方式排序，避免使用 FileSort 方式排序
- MySQL 支持两种方式的排序，FileSort 和 Index，Index效率高，它指 MySQL 扫描索引本身完成排序，FileSort 效率较低；
- ORDER BY 满足两种情况，会使用Index方式排序；①ORDER BY语句使用索引最左前列 ②使用where子句与ORDER BY子句条件列组合满足索引最左前列
- 尽可能在索引列上完成排序操作，遵照索引建的最佳最前缀
- 如果不在索引列上，filesort 有两种算法，mysql就要启动双路排序和单路排序
  - 双路排序：MySQL 4.1之前是使用双路排序,字面意思就是两次扫描磁盘，最终得到数据
  - 单路排序：从磁盘读取查询需要的所有列，按照order by 列在 buffer对它们进行排序，然后扫描排序后的列表进行输出，效率高于双路排序
- 优化策略
  - 增大sort_buffer_size参数的设置
  - 增大max_lencth_for_sort_data参数的设置

**GROUP BY关键字优化**

- group by实质是先排序后进行分组，遵照索引建的最佳左前缀
- 当无法使用索引列，增大 `max_length_for_sort_data` 参数的设置，增大`sort_buffer_size`参数的设置
- where高于having，能写在where限定的条件就不要去having限定了

#### 数据类型优化

MySQL 支持的数据类型非常多，选择正确的数据类型对于获取高性能至关重要。不管存储哪种类型的数据，下面几个简单的原则都有助于做出更好的选择。

- 更小的通常更好：一般情况下，应该尽量使用可以正确存储数据的最小数据类型。

  简单就好：简单的数据类型通常需要更少的CPU周期。例如，整数比字符操作代价更低，因为字符集和校对规则（排序规则）使字符比较比整型比较复杂。

- 尽量避免NULL：通常情况下最好指定列为NOT NULL

### 分区，分库分表

#### Mysql分区

一般情况下我们创建的表对应一组存储文件，使用`MyISAM`存储引擎时是一个`.MYI`和`.MYD`文件，使用`Innodb`存储引擎时是一个`.ibd`和`.frm`（表结构）文件。

当数据量较大时（一般千万条记录级别以上），MySQL的性能就会开始下降，这时我们就需要将数据分散到多组存储文件，保证其单个文件的执行效率

**能干嘛**

- 逻辑数据分割
- 提高单一的写和读应用速度
- 提高分区范围读查询的速度
- 分割数据能够有多个不同的物理文件路径
- 高效的保存历史数据

**如何使用**

首先查看当前数据库是否支持分区

- MySQL5.6以及之前版本：

~~~ sql
SHOW VARIABLES LIKE '%partition%';
~~~

MySQL5.6：

```sql
show plugins;
```

**分区类型及操作**

- **RANGE分区**：基于属于一个给定连续区间的列值，把多行分配给分区。mysql将会根据指定的拆分策略，,把数据放在不同的表文件上。相当于在文件上,被拆成了小块.但是,对外给客户的感觉还是一张表，透明的。

  按照 range 来分，就是每个库一段连续的数据，这个一般是按比如**时间范围**来的，比如交易表啊，销售表啊等，可以根据年月来存放数据。可能会产生热点问题，大量的流量都打在最新的数据上了。

  range 来分，好处在于说，扩容的时候很简单。

- **LIST分区**：类似于按RANGE分区，每个分区必须明确定义。它们的主要区别在于，LIST分区中每个分区的定义和选择是基于某列的值从属于一个值列表集中的一个值，而RANGE分区是从属于一个连续区间值的集合。

- **HASH分区**：基于用户定义的表达式的返回值来进行选择的分区，该表达式使用将要插入到表中的这些行的列值进行计算。这个函数可以包含MySQL 中有效的、产生非负整数值的任何表达式。

  hash 分发，好处在于说，可以平均分配每个库的数据量和请求压力；坏处在于说扩容起来比较麻烦，会有一个数据迁移的过程，之前的数据需要重新计算 hash 值重新分配到不同的库或表

- **KEY分区**：类似于按HASH分区，区别在于KEY分区只支持计算一列或多列，且MySQL服务器提供其自身的哈希函数。必须有一列或多列包含整数值。

**看上去分区表很帅气，为什么大部分互联网还是更多的选择自己分库分表来水平扩展咧？**

- 分区表，分区键设计不太灵活，如果不走分区键，很容易出现全表锁
- 一旦数据并发量上来，如果在分区表实施关联，就是一个灾难
- 自己分库分表，自己掌控业务场景与访问模式，可控。分区表，研发写了一个sql，都不确定mysql是怎么玩的，不太可控

> 随着业务的发展，业务越来越复杂，应用的模块越来越多，总的数据量很大，高并发读写操作均超过单个数据库服务器的处理能力怎么办？

这个时候就出现了**数据分片**，数据分片指按照某个维度将存放在单一数据库中的数据分散地存放至多个数据库或表中。数据分片的有效手段就是对关系型数据库进行分库和分表。

区别于分区的是，分区一般都是放在单机里的，用的比较多的是时间范围分区，方便归档。只不过分库分表需要代码实现，分区则是mysql内部实现。分库分表和分区并不冲突，可以结合使用。

> 说说分库与分表的设计

#### MySQL分表

分表有两种分割方式，一种垂直拆分，另一种水平拆分。

- **垂直拆分**

  垂直分表，通常是按照业务功能的使用频次，把主要的、热门的字段放在一起做为主要表。然后把不常用的，按照各自的业务属性进行聚集，拆分到不同的次要表中；主要表和次要表的关系一般都是一对一的。

- **水平拆分(数据分片)**

  单表的容量不超过500W，否则建议水平拆分。是把一个表复制成同样表结构的不同表，然后把数据按照一定的规则划分，分别存储到这些表中，从而保证单表的容量不会太大，提升性能；当然这些结构一样的表，可以放在一个或多个数据库中。

  水平分割的几种方法：

  - 使用MD5哈希，做法是对UID进行md5加密，然后取前几位（我们这里取前两位），然后就可以将不同的UID哈希到不同的用户表（user_xx）中了。
  - 还可根据时间放入不同的表，比如：article_201601，article_201602。
  - 按热度拆分，高点击率的词条生成各自的一张表，低热度的词条都放在一张大表里，待低热度的词条达到一定的贴数后，再把低热度的表单独拆分成一张表。
  - 根据ID的值放入对应的表，第一个表user_0000，第二个100万的用户数据放在第二 个表user_0001中，随用户增加，直接添加用户表就行了。

![1640692146348](https://tprzfbucket.oss-cn-beijing.aliyuncs.com/hadoop/202112/28/194907-125544.png)

#### MySQL分库

> 为什么要分库?

数据库集群环境后都是多台 slave，基本满足了读取操作;  但是写入或者说大数据、频繁的写入操作对master性能影响就比较大，这个时候，单库并不能解决大规模并发写入的问题，所以就会考虑分库。

> 分库是什么？

一个库里表太多了，导致了海量数据，系统性能下降，把原本存储于一个库的表拆分存储到多个库上， 通常是将表按照功能模块、关系密切程度划分出来，部署到不同库上。

优点：

- 减少增量数据写入时的锁对查询的影响
- 由于单表数量下降，常见的查询操作由于减少了需要扫描的记录，使得单表单次查询所需的检索行数变少，减少了磁盘IO，时延变短，但是它无法解决单表数据量太大的问题

**分库分表后的难题**

分布式事务的问题，数据的完整性和一致性问题。

数据操作维度问题：用户、交易、订单各个不同的维度，用户查询维度、产品数据分析维度的不同对比分析角度。 跨库联合查询的问题，可能需要两次查询 跨节点的count、order by、group by以及聚合函数问题，可能需要分别在各个节点上得到结果后在应用程序端进行合并 额外的数据管理负担，如：访问数据表的导航定位 额外的数据运算压力，如：需要在多个节点执行，然后再合并计算程序编码开发难度提升，没有太好的框架解决，更多依赖业务看如何分，如何合，是个难题。

> 配主从，正经公司的话，也不会让 Javaer 去搞的，但还是要知道

### 主从复制

#### 复制的基本原理

- slave 会从 master 读取 binlog 来进行数据同步
- 三个步骤
  1. master将改变记录到二进制日志（binary log）。这些记录过程叫做二进制日志事件，binary log events；
  2. salve 将 master 的 binary log events 拷贝到它的中继日志（relay log）;
  3. slave 重做中继日志中的事件，将改变应用到自己的数据库中。MySQL 复制是异步且是串行化的。

![1640692219536](https://tprzfbucket.oss-cn-beijing.aliyuncs.com/hadoop/202112/28/195020-639711.png)

#### 复制的基本原则

- 每个 slave只有一个 master
- 每个 salve只能有一个唯一的服务器 ID
- 每个master可以有多个salve

#### 复制的最大问题

- 延时

### 百万级别或以上的数据如何删除

关于索引：由于索引需要额外的维护成本，因为索引文件是单独存在的文件,所以当我们对数据的增加,修改,删除,都会产生额外的对索引文件的操作,这些操作需要消耗额外的IO,会降低增/改/删的执行效率。所以，在我们删除数据库百万级别数据的时候，查询MySQL官方手册得知删除数据的速度和创建的索引数量是成正比的。

1. 所以我们想要删除百万数据的时候可以先删除索引（此时大概耗时三分多钟）
2. 然后删除其中无用数据（此过程需要不到两分钟）
3. 删除完成后重新创建索引(此时数据较少了)创建索引也非常快，约十分钟左右。
4. 与之前的直接删除绝对是要快速很多，更别说万一删除中断,一切删除会回滚。那更是坑了。

### 数据库优化

#### 大表如何优化？

1. 限定数据的范围：避免不带任何限制数据范围条件的查询语句。
2. 读写分离：主库负责写，从库负责读。
3. 垂直分表：将一个表按照字段分成多个表，每个表存储其中一部分字段。
4. 水平分表：在同一个数据库内，把一个表的数据按照一定规则拆分到多个表中。
5. 对单表进行优化：对表中的字段、索引、查询SQL进行优化。
6. 添加缓存 

#### 什么是垂直分表、垂直分库、水平分表、水平分库？ 

**垂直分表：**

将一个表按照字段分成多个表，每个表存储其中一部分字段。一般会将常用的字段放到一个表中，将不常用的字段放到另一个表中。

垂直分表的优势： 

- 避免IO竞争减少锁表的概率。因为大的字段效率更低，第一数据量大，需要的读取时间长。第二，大字段占用的空间更大，单页内存储的行数变少，会使得IO操作增多。
- 可以更好地提升热门数据的查询效率 

**垂直分库：**

按照业务对表进行分类，部署到不同的数据库上面，不同的数据库可以放到不同的服务器上面。

垂直分库的优势：

- 降低业务中的耦合，方便对不同的业务进行分级管理。
- 可以提升IO、数据库连接数、解决单机硬件资源的瓶颈问题 

**垂直拆分（分库、分表）的缺点：**

- 主键出现冗余，需要管理冗余列
- 事务的处理变得复杂
- 仍然存在单表数据量过大的问题 

**水平分表：**

- 在同一个数据库内，把同一个表的数据按照一定规则拆分到多个表中。

水平分表的优势：

- 解决了单表数据量过大的问题
- 避免IO竞争并减少锁表的概率

**水平分库：**

- 把同一个表的数据按照一定规则拆分到不同的数据库中，不同的数据库可以放到不同的服务器上 

**水平分库的优势：**

- 解决了单库大数据量的瓶颈问题
- IO冲突减少，锁的竞争减少，某个数据库出现问题不影响其他数据库（可用性），提高了系统的稳
  定性和可用性

**水平拆分（分表、分库）的缺点：**

- 分片事务一致性难以解决
- 跨节点JOIN性能差，逻辑会变得复杂
- 数据扩展难度大，不易维护 

在系统设计时应根据业务耦合来确定垂直分库和垂直分表的方案，在数据访问压力不是特别大时应考虑缓存、读写分离等方法，若数据量很大，或持续增长可考虑水平分库分表，水平拆分所涉及的逻辑比较复杂，常见的方案有客户端架构和恶代理架构。 

#### 分库分表后，ID键如何处理？ 

分库分表后不能每个表的ID都是从1开始，所以需要一个全局ID，设置全局ID主要有以下几种方法： 

- UUID：优点：本地生成ID，不需要远程调用；全局唯一不重复。缺点：占用空间大，不适合作为索引。
- 数据库自增ID：在分库分表表后使用数据库自增ID，需要一个专门用于生成主键的库，每次服务接收到请求，先向这个库中插入一条没有意义的数据，获取一个数据库自增的ID，利用这个ID去分库分表中写数据。优点：简单易实现。缺点：在高并发下存在瓶颈。系统结构如下图（图片来源于网络） 

![1631773359001](https://tprzfbucket.oss-cn-beijing.aliyuncs.com/hadoop/202109/16/142306-337629.png)

- Redis生成ID：优点：不依赖数据库，性能比较好。缺点：引入新的组件会使得系统复杂度增加 
- Twitter的snowflake算法：是一个64位的long型的ID，其中有1bit是不用的，41bit作为毫秒数，
  - 10bit作为工作机器ID，12bit作为序列号。
  - 1bit：第一个bit默认为0，因为二进制中第一个bit为1的话为负数，但是ID不能为负数.
  - 41bit：表示的是时间戳，单位是毫秒。
  - 10bit：记录工作机器ID，其中5个bit表示机房ID，5个bit表示机器ID。
  - 12bit：用来记录同一毫秒内产生的不同ID。 
- 美团的Leaf分布式ID生成系统 ：[美团点评分布式ID生成系统 ]([Leaf——美团点评分布式ID生成系统 - 美团技术团队 (meituan.com)](https://tech.meituan.com/2017/04/21/mt-leaf.html))

#### MySQL的复制原理及流程？如何实现主从复制？ 

MySQL复制：为保证主服务器和从服务器的数据一致性，在向主服务器插入数据后，从服务器会自动将主服务器中修改的数据同步过来。

主从复制的原理：

主从复制主要有三个线程：binlog线程，I/O线程，SQL线程。

- binlog线程：负责将主服务器上的数据更改写入到二进制日志（Binary log）中。
- I/O线程：负责从主服务器上读取二进制日志（Binary log），并写入从服务器的中继日志（Relaylog）中。
- SQL线程：负责读取中继日志，解析出主服务器中已经执行的数据更改并在从服务器中重放

复制过程如下（图片来源于网络）： 

![1631773590615](https://tprzfbucket.oss-cn-beijing.aliyuncs.com/hadoop/202109/16/142632-32820.png)

1. Master在每个事务更新数据完成之前，将操作记录写入到binlog中。
2. Slave从库连接Master主库，并且Master有多少个Slave就会创建多少个binlog dump线程。当Master节点的binlog发生变化时，binlog dump会通知所有的Slave，并将相应的binlog发送给Slave。
3. I/O线程接收到binlog内容后，将其写入到中继日志（Relay log）中。
4. SQL线程读取中继日志，并在从服务器中重放。 

**补充图**

![1631773727821](https://tprzfbucket.oss-cn-beijing.aliyuncs.com/hadoop/202109/16/142851-785544.png)

**主从复制的作用：**

1. 高可用和故障转移
2. 负载均衡
3. 数据备份
4. 升级测试 

#### 了解读写分离吗？ 

读写分离主要依赖于主从复制，主从复制为读写分离服务。

读写分离的优势：

- 主服务器负责写，从服务器负责读，缓解了锁的竞争
- 从服务器可以使用MyISAM，提升查询性能及节约系统开销
- 增加冗余，提高可用性 

### 常见面试题目

#### 一张表，里面有ID自增主键，当insert了17条记录之后，删除了第15,16,17条记录，再把Mysql重启，再insert一条记录，这条记录的ID是18还是15 ？

1. 如果表的类型是MyISAM，那么是18，因为MyISAM表会把自增主键的最大ID记录到数据文件里，重启MySQL自增主键的最大ID也不会丢失
2. 如果表的类型是InnoDB，那么是15，InnoDB表只是把自增主键的最大ID记录到内存中，所以重启数据库或者是对表进行OPTIMIZE操作，都会导致最大ID丢失

#### Mysql服务器默认端口是什么？

Mysql服务器的默认端口是3306。

#### 与Oracle相比，Mysql有什么优势？

1. Mysql是开源软件，随时可用，无需付费。
2. Mysql是便携式的
3. 带有命令提示符的GUI。
4. 使用Mysql查询浏览器支持管理

#### 如何区分FLOAT和DOUBLE？

以下是FLOAT和DOUBLE的区别：

- 浮点数以8位精度存储在FLOAT中，并且有四个字节。
- 浮点数存储在DOUBLE中，精度为18位，有八个字节。

#### 区分CHAR_LENGTH和LENGTH？

CHAR_LENGTH是字符数，而LENGTH是字节数。Latin字符的这两个数据是相同的，但是对于Unicode和其他编码，它们是不同的。

#### 请简洁描述Mysql中InnoDB支持的四种事务隔离级别名称，以及逐级之间的区别？

SQL标准定义的四个隔离级别为：

- read uncommited ：读到未提交数据,在该隔离级别，所有事务都可以看到其他未提交事务的执行结果。本隔离级别很少用于实际应用，因为它的性能也不比其他级别好多少。读取未提交的数据，也被称之为脏读（Dirty Read）。
- read committed：脏读，不可重复读，这是大多数数据库系统的默认隔离级别（但不是MySQL默认的）。它满足了隔离的简单定义：一个事务只能看见已经提交事务所做的改变。这种隔离级别也支持所谓的不可重复读（Nonrepeatable Read），因为同一事务的其他实例在该实例处理其间可能会有新的commit，所以同一select可能返回不同结果。
- repeatable read：可重读，这是MySQL的默认事务隔离级别，它确保同一事务的多个实例在并发读取数据时，会看到同样的数据行。不过理论上，这会导致另一个棘手的问题：幻读（PhantomRead）。简单的说，幻读指当用户读取某一范围的数据行时，另一个事务又在该范围内插入了新行，当用户再读取该范围的数据行时，会发现有新的“幻影” 行。InnoDB和Falcon存储引擎通过多版本并发控制（MVCC，Multiversion Concurrency Control 间隙锁）机制解决了该问题。注：其实多版本只是解决不可重复读问题，而加上间隙锁（也就是它这里所谓的并发控制）才解决了幻读问题。
- serializable ：串行事物，这是最高的隔离级别，它通过强制事务排序，使之不可能相互冲突，从而解决幻读问题。简言之，它是在每个读的数据行上加上共享锁。在这个级别，可能导致大量的超时现象和锁竞争。

#### CHAR和VARCHAR的区别？

以下是CHAR和VARCHAR的区别：

- CHAR和VARCHAR类型在存储和检索方面有所不同
- CHAR列长度固定为创建表时声明的长度，长度值范围是1到255
- 当CHAR值被存储时，它们被用空格填充到特定长度，检索CHAR值时需删除尾随空格。

#### 主键和候选键有什么区别？

- 超键(super key): 在关系中能唯一标识元组的属性集称为关系模式的超键
- 候选键(candidate key): 不含有多余属性的超键称为候选键。也就是在候选键中，若再删除属性，就不是键了！
- 主键(primary key): 用户选作元组标识的一个候选键程序主键
- 外键(foreign key)：如果关系模式R中属性K是其它模式的主键，那么k在模式R中称为外键。

> 学生信息（学号 身份证号 性别 年龄 身高 体重 宿舍号）和 宿舍信息（宿舍号 楼号）
>
> 超键：只要含有“学号”或者“身份证号”两个属性的集合就叫超键，例如R1（学号 性别）、R2（身份证号 身高）、R3（学号 身份证号）等等都可以称为超键！
>
> 候选键：不含有多余的属性的超键，比如（学号）、（身份证号）都是候选键，又比如R1中学号这一个属性就可以唯一标识元组了，而有没有性别这一属性对是否唯一标识元组没有任何的影响！
>
> 主键：就是用户从很多候选键选出来的一个键就是主键，比如你要求学号是主键，那么身份证号就不可以是主键了！
>
> 外键：宿舍号就是学生信息表的外键

#### BLOB 和 TEXT 有什么区别？

BLOB 是一个二进制对象，可以容纳可变数量的数据。有四种类型的 BLOB

- TINYBLOB
- BLOB
- MEDIUMBLOB 
- LONGBLOB

它们只能在所能容纳价值的最大长度上有所不同。

TEXT 是一个不区分大小写的 BLOB。四种 TEXT 类型

- TINYTEXT
- TEXT
- MEDIUMTEXT 
- LONGTEXT

它们对应于四种 BLOB 类型，并具有相同的最大长度和存储要求。

BLOB 和 TEXT 类型之间的唯一区别在于对 BLOB 值进行排序和比较时区分大小写，对 TEXT 值不区分大小写。

#### MySQL 的关键字

- 添加索引：alter table tableName add 索引（索引字段）
- 主键：primary key
- 唯一：unique
- 全局：fulltext
- 普通：index
- 多列： index index_name

#### 数据库备份

必须要在未登录状态下：

- 导出整个数据库：`mysqldump -u 用户名 -p 数据库名 > 导出的文件名`
- 导出一张表：`mysqldump -u 用户名 -p 数据库名 表名> 导出的文件名`
- d导出一个数据库结构：`mysqldump -u dbuser -p -d --add-drop-table dbname >d:/dbname_db.sql`，-d 没有数据 --add-drop-table 在每个 create 语句之前增加一个 drop table

